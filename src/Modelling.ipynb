{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "INTERM_DIR = '../compiled_data'\n",
    "TRAIN_DATA_PATH = os.path.join(INTERM_DIR, 'train_data.pkl')\n",
    "MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_tcn, build_lstm\n",
    "\n",
    "class PerformTraining:\n",
    "    \n",
    "    \"\"\"\n",
    "    This class performs the training of the desired model\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    seed : int\n",
    "        the integer of the seed utilised for reproducibility \n",
    "    TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "    INTERM_DATA_DIR : str\n",
    "        a string indicating the directory containing intermediate computed data\n",
    "    MODEL_DIR : str\n",
    "        a string indicating the directory containing created models\n",
    "    model_gs_params : dict\n",
    "        a dictionary of preprocessing parameters\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    reproducible_results()\n",
    "        Sets seed and ensures all deterministic operations are reproducible\n",
    "    retrieve_data()\n",
    "        Retrieves the data given the data directory and folders\n",
    "    prepare_data(preprocessing_params, tuning=True):\n",
    "        Combines the preprocessing methods and splits the data for training \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "        INTERM_DATA_DIR : str\n",
    "            a string indicating the directory containing intermediate computed data\n",
    "        MODEL_DIR : str\n",
    "            a string indicating the directory containing created models\n",
    "        model_gs_params : list of lists\n",
    "            a list of lists containing the parameters for model training\n",
    "        \"\"\"\n",
    "\n",
    "        self.seed = 7\n",
    "\n",
    "        self.TRAIN_DATA_PATH = TRAIN_DATA_PATH\n",
    "        self.INTERM_DATA_DIR = INTERM_DATA_DIR\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.model_gs_params = model_gs_params\n",
    "        self.max_epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.flush = flush\n",
    "        self.save_plot = save_plot\n",
    "        \n",
    "        with open(TRAIN_DATA_PATH, 'rb') as f:\n",
    "            self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = pkl.load(f)\n",
    "            \n",
    "        # random shuffle dataset\n",
    "        p = np.random.permutation(len(self.X_train))\n",
    "        self.X_train, self.y_train = self.X_train[p], self.y_train[p]\n",
    "            \n",
    "        print(f\"The class distributions in the training set are: {np.unique(self.y_train, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the validation set are: {np.unique(self.y_val, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the test set are: {np.unique(self.y_test, return_counts=True)}\")\n",
    "\n",
    "        self.y_train, self.y_val, self.y_test = keras.utils.to_categorical(self.y_train), keras.utils.to_categorical(self.y_val), keras.utils.to_categorical(self.y_test)\n",
    "        \n",
    "        self.reproducible_results()\n",
    "        self.X_train, self.X_val, self.X_test = self.X_train[:,8:,:], self.X_val[:,8:,:], self.X_test[:,8:,:]\n",
    "#         sample_mean = np.mean(self.X_train, axis=0)\n",
    "#         sample_std = np.mean(self.X_train, axis=0)\n",
    "#         self.X_train = (self.X_train - sample_mean) / sample_std\n",
    "#         self.X_val = (self.X_val - sample_mean) / sample_std\n",
    "#         self.X_test = (self.X_test - sample_mean) / sample_std\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "            self.perform_gs_training(build_tcn, os.path.join(self.MODEL_DIR, 'tcn'))\n",
    "            \n",
    "        if self.model_type == 'lstm':\n",
    "            self.perform_gs_training(build_lstm, os.path.join(self.MODEL_DIR, 'lstm'))\n",
    "\n",
    "    def reproducible_results(self):\n",
    "\n",
    "        \"\"\"Obtain reproducible results with keras, source: https://stackoverflow.com/a/52897216\"\"\"\n",
    "\n",
    "        # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "\n",
    "        # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "        tf.compat.v1.set_random_seed(self.seed)\n",
    "\n",
    "        # 5. Configure a new global `tensorflow` session\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "        K.set_session(sess)\n",
    "\n",
    "    def plot_confusion_matrix(self, confusion_matrix, title, save_plot_dir):\n",
    "        \"\"\"Plots a given confusion matrix and saves it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion_matrix : ndarray\n",
    "            a numpy array of the confusion matrix\n",
    "        title : str\n",
    "            a string of the title name\n",
    "        save_plot_dir : str\n",
    "            a string of where to save the plot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (ndarray, ndarray)\n",
    "            a tuple of the numpy arrays of the upsampled feature and label arrays\n",
    "        \"\"\"  \n",
    "        # Plot confusion matrix\n",
    "        labels = np.unique(self.y_train)\n",
    "        df_cm = pd.DataFrame(confusion_matrix, index = [i for i in np.unique(self.y_train)], columns = [i for i in np.unique(self.y_train)])\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title(title, ha=\"center\")\n",
    "        plt.xticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        plt.yticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        if save_plot_dir is not None: \n",
    "            plt.savefig(f'{save_plot_dir}.pdf', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def model_param_setup(self, params):\n",
    "        \"\"\"Retrieve from a given ordered list the correct parameters depending on model type\"\"\"\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'cnn_dropout_p' : params[1], \n",
    "                            'dense_dropout_p' : params[2], \n",
    "                            'activation' : params[3], \n",
    "                            'n_dense_layers' : params[4], \n",
    "                            'n_dense_neurons' : params[5], \n",
    "                            'batch_normalization' : params[6], \n",
    "                            'batch_size' : params[7],\n",
    "                            'optimizer' : params[8]}\n",
    "\n",
    "        if self.model_type == 'lstm':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'batch_size' : params[1],\n",
    "                            'lstm_neurons' : params[2], \n",
    "                            'n_dense_neurons' : params[3], \n",
    "                            'dropout' : params[4], \n",
    "                            'optimizer' : params[5]}\n",
    "\n",
    "        return model_params    \n",
    "    \n",
    "    \n",
    "    def perform_gs_training(self, model_fn, checkpoint_filepath):\n",
    "\n",
    "        \"\"\"Performs cross-validated grid search training for selected model function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_fn : function\n",
    "            a function which creates a keras compiled model\n",
    "        checkpoint_filepath : str\n",
    "            a string indicating where to save the plots and grid search results \n",
    "            of the cross-validated grid search\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            a pandas dataframe containing the results of the grid search, \n",
    "            specifically average performance for given hyperparameters\n",
    "        \"\"\"  \n",
    "\n",
    "        pkl_name = os.path.join(checkpoint_filepath, 'gs_res.pkl')\n",
    "        if os.path.isfile(pkl_name) and self.flush==False:\n",
    "            with open(pkl_name, 'rb') as f:\n",
    "                gs_res = pkl.load(f)\n",
    "        else: \n",
    "            gs_res = []\n",
    "\n",
    "        for idx, params in enumerate(self.model_gs_params): \n",
    "\n",
    "            print(\"=================================================\")\n",
    "            print(\"Presenting Results for: %s/%s Hyperparameter Combination\" % (idx+1, len(self.model_gs_params)))\n",
    "\n",
    "            model_params = self.model_param_setup(params)\n",
    "            print(model_params)\n",
    "\n",
    "            batch_size = model_params['batch_size']\n",
    "\n",
    "            # Create backlog for accuracy in each fold\n",
    "            val_fold_accuracy = []\n",
    "            test_fold_accuracy = []\n",
    "\n",
    "            try:     \n",
    "\n",
    "                # Prepare the training dataset\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "                # Prepare the validation dataset\n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((self.X_val, self.y_val))\n",
    "                val_dataset = val_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "                \n",
    "                if self.model_type == 'lstm':\n",
    "                    # In stateful lstm, need to have full batches, i.e. a dataset size divisible by batch_size\n",
    "                    rem_last_n_train = (self.X_train.shape[0] % batch_size)\n",
    "                    if rem_last_n_train > 0:\n",
    "                        self.X_train, self.y_train = self.X_train[:-rem_last_n_train], self.y_train[:-rem_last_n_train]\n",
    "\n",
    "                    rem_last_n_val = (self.X_val.shape[0] % batch_size)\n",
    "                    if rem_last_n_val > 0:\n",
    "                        self.X_val, self.y_val = self.X_val[:-rem_last_n_val], self.y_val[:-rem_last_n_val]\n",
    "                    \n",
    "                    rem_last_n_test = (self.X_test.shape[0] % batch_size)\n",
    "                    if rem_last_n_test > 0:\n",
    "                        self.X_test, self.y_test = self.X_test[:-rem_last_n_test], self.y_test[:-rem_last_n_test]\n",
    "                    \n",
    "                model = model_fn(self.X_train, **model_params)\n",
    "\n",
    "                # Create Tensorboard\n",
    "                logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch', profile_batch=0)\n",
    "                # Model Checkpoint Callback\n",
    "                checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_filepath,'checkpoint'), save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "                # Early Stopping Callback\n",
    "                early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 50)\n",
    "\n",
    "                # Train the model\n",
    "                training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_val, self.y_val),\n",
    "                                             steps_per_epoch = self.X_train.shape[0] // batch_size if self.model_type == 'lstm' else None, \n",
    "                                             callbacks = [tensorboard_callback,\n",
    "                                                          #early_stopping_callback,\n",
    "                                                          checkpoint_callback],\n",
    "                                             epochs=self.max_epochs, verbose=1)\n",
    "                \n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "            try: \n",
    "\n",
    "                # Compute confusion matrix across validation folds, and the test set\n",
    "                def compute_confusion_matrix(set_to_predict, true_values, model):\n",
    "                    y_predicted = model.predict(set_to_predict)\n",
    "                    class_pred = np.argmax(y_predicted,axis = 1)\n",
    "                    class_true = np.argmax(true_values,axis = 1)\n",
    "                    res = metrics.confusion_matrix(class_true, class_pred)\n",
    "                    perc_acc = res / res.sum(axis=0)\n",
    "                    return perc_acc\n",
    "\n",
    "                test_accuracy = compute_confusion_matrix(self.X_test, self.y_test, model)\n",
    "                val_accuracy = compute_confusion_matrix(self.X_val, self.y_val, model)\n",
    "                \n",
    "                if self.save_plot == True: \n",
    "                    string_model_params = model_params\n",
    "                    del string_model_params['optimizer']\n",
    "                    string_model_params['learning_rate'] = K.eval(model.optimizer.lr)\n",
    "\n",
    "                    string_model_params = [str(x) for x in [*string_model_params.values()]]\n",
    "                    save_plot_dir = os.path.join(checkpoint_filepath, 'plots')\n",
    "                    save_plot_val_dir = os.path.join(save_plot_dir, 'Val CM ' + ' '.join(string_model_params))\n",
    "                    save_plot_test_dir = os.path.join(save_plot_dir, 'Test CM ' + ' '.join(string_model_params))\n",
    "                else: \n",
    "                    save_plot_val_dir = None\n",
    "                    save_plot_test_dir = None\n",
    "\n",
    "                self.plot_confusion_matrix(test_accuracy, 'Validation Dataset Accuracy', save_plot_val_dir)    \n",
    "                self.plot_confusion_matrix(val_accuracy, 'Test Validation Dataset Accuracy', save_plot_test_dir)    \n",
    "\n",
    "                curr_gs_res = [model_params, self.model_type, test_accuracy.diagonal(), val_accuracy.diagonal()]\n",
    "                gs_res.append(curr_gs_res)\n",
    "                with open(pkl_name, 'wb') as f:\n",
    "                    pkl.dump(gs_res, f)\n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "        return gs_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([510, 620]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([112, 207]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([81, 79]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 1, 'cnn_dropout_p': 0.5, 'dense_dropout_p': None, 'activation': 'tanh', 'n_dense_layers': 1, 'n_dense_neurons': 100, 'batch_normalization': True, 'batch_size': 16, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7f0282e23a90>}\n",
      "Epoch 1/2000\n",
      "71/71 [==============================] - 1s 5ms/step - loss: 0.7156 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - val_loss: 0.6610 - val_accuracy: 0.6489 - val_precision: 0.6489 - val_recall: 0.6489\n",
      "Epoch 2/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5204 - precision: 0.5204 - recall: 0.5204 - val_loss: 0.6793 - val_accuracy: 0.6238 - val_precision: 0.6238 - val_recall: 0.6238\n",
      "Epoch 3/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5257 - precision: 0.5257 - recall: 0.5257 - val_loss: 0.6631 - val_accuracy: 0.6426 - val_precision: 0.6426 - val_recall: 0.6426\n",
      "Epoch 4/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5221 - precision: 0.5221 - recall: 0.5221 - val_loss: 0.6730 - val_accuracy: 0.6301 - val_precision: 0.6301 - val_recall: 0.6301\n",
      "Epoch 5/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5159 - precision: 0.5159 - recall: 0.5159 - val_loss: 0.6769 - val_accuracy: 0.6332 - val_precision: 0.6332 - val_recall: 0.6332\n",
      "Epoch 6/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.5487 - precision: 0.5487 - recall: 0.5487 - val_loss: 0.6827 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 7/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5558 - precision: 0.5558 - recall: 0.5558 - val_loss: 0.6700 - val_accuracy: 0.6332 - val_precision: 0.6332 - val_recall: 0.6332\n",
      "Epoch 8/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6899 - accuracy: 0.5584 - precision: 0.5584 - recall: 0.5584 - val_loss: 0.6731 - val_accuracy: 0.6552 - val_precision: 0.6552 - val_recall: 0.6552\n",
      "Epoch 9/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6807 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.6612 - val_accuracy: 0.6458 - val_precision: 0.6458 - val_recall: 0.6458\n",
      "Epoch 10/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - val_loss: 0.6741 - val_accuracy: 0.6207 - val_precision: 0.6207 - val_recall: 0.6207\n",
      "Epoch 11/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6800 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 12/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5717 - precision: 0.5717 - recall: 0.5717 - val_loss: 0.6793 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 13/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6861 - accuracy: 0.5611 - precision: 0.5611 - recall: 0.5611 - val_loss: 0.6767 - val_accuracy: 0.6176 - val_precision: 0.6176 - val_recall: 0.6176\n",
      "Epoch 14/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5637 - precision: 0.5637 - recall: 0.5637 - val_loss: 0.6847 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 15/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.5434 - precision: 0.5434 - recall: 0.5434 - val_loss: 0.6661 - val_accuracy: 0.6489 - val_precision: 0.6489 - val_recall: 0.6489\n",
      "Epoch 16/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.5558 - precision: 0.5558 - recall: 0.5558 - val_loss: 0.6758 - val_accuracy: 0.6207 - val_precision: 0.6207 - val_recall: 0.6207\n",
      "Epoch 17/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.5752 - precision: 0.5752 - recall: 0.5752 - val_loss: 0.6912 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 18/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6840 - accuracy: 0.5611 - precision: 0.5611 - recall: 0.5611 - val_loss: 0.6706 - val_accuracy: 0.6238 - val_precision: 0.6238 - val_recall: 0.6238\n",
      "Epoch 19/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.5708 - precision: 0.5708 - recall: 0.5708 - val_loss: 0.6963 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 20/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5646 - precision: 0.5646 - recall: 0.5646 - val_loss: 0.6725 - val_accuracy: 0.6113 - val_precision: 0.6113 - val_recall: 0.6113\n",
      "Epoch 21/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.5805 - precision: 0.5805 - recall: 0.5805 - val_loss: 0.6880 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 22/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6818 - accuracy: 0.5664 - precision: 0.5664 - recall: 0.5664 - val_loss: 0.6883 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 23/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - val_loss: 0.6690 - val_accuracy: 0.6113 - val_precision: 0.6113 - val_recall: 0.6113\n",
      "Epoch 24/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6734 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6922 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 25/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.5690 - precision: 0.5690 - recall: 0.5690 - val_loss: 0.6933 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 26/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5549 - precision: 0.5549 - recall: 0.5549 - val_loss: 0.6931 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 27/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5743 - precision: 0.5743 - recall: 0.5743 - val_loss: 0.6968 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 28/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.5743 - precision: 0.5743 - recall: 0.5743 - val_loss: 0.6791 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 29/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.5619 - precision: 0.5619 - recall: 0.5619 - val_loss: 0.6699 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 30/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5779 - precision: 0.5779 - recall: 0.5779 - val_loss: 0.6835 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 31/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6852 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 32/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.5602 - precision: 0.5602 - recall: 0.5602 - val_loss: 0.6911 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 33/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5690 - precision: 0.5690 - recall: 0.5690 - val_loss: 0.6765 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 34/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5841 - precision: 0.5841 - recall: 0.5841 - val_loss: 0.6847 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 35/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.5735 - precision: 0.5735 - recall: 0.5735 - val_loss: 0.6682 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 36/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.5770 - precision: 0.5770 - recall: 0.5770 - val_loss: 0.6745 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 37/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6793 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 38/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6875 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 39/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.5735 - precision: 0.5735 - recall: 0.5735 - val_loss: 0.6673 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 40/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.5681 - precision: 0.5681 - recall: 0.5681 - val_loss: 0.6736 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 41/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6733 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 42/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5717 - precision: 0.5717 - recall: 0.5717 - val_loss: 0.6766 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 43/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6768 - accuracy: 0.5628 - precision: 0.5628 - recall: 0.5628 - val_loss: 0.6899 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 44/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.6756 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 45/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6803 - accuracy: 0.5735 - precision: 0.5735 - recall: 0.5735 - val_loss: 0.6790 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 46/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5681 - precision: 0.5681 - recall: 0.5681 - val_loss: 0.6694 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 47/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6925 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 48/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5637 - precision: 0.5637 - recall: 0.5637 - val_loss: 0.6762 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 49/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6991 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 50/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6733 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 51/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.5779 - precision: 0.5779 - recall: 0.5779 - val_loss: 0.6843 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 52/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6768 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 53/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6816 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 54/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6810 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 55/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6755 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 56/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6700 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 57/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6834 - accuracy: 0.5655 - precision: 0.5655 - recall: 0.5655 - val_loss: 0.6761 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 58/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6698 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 59/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6777 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 60/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6822 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 61/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6820 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 62/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6687 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 63/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6744 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6694 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 64/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6739 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 65/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6593 - val_accuracy: 0.6270 - val_precision: 0.6270 - val_recall: 0.6270\n",
      "Epoch 66/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6706 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 67/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6714 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 68/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5664 - precision: 0.5664 - recall: 0.5664 - val_loss: 0.6900 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 69/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6722 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.6681 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 70/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5708 - precision: 0.5708 - recall: 0.5708 - val_loss: 0.6692 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 71/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5699 - precision: 0.5699 - recall: 0.5699 - val_loss: 0.6644 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 72/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.5779 - precision: 0.5779 - recall: 0.5779 - val_loss: 0.6883 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 73/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6762 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6646 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 74/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6634 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 75/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6721 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 76/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6782 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 77/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.5690 - precision: 0.5690 - recall: 0.5690 - val_loss: 0.6667 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 78/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5779 - precision: 0.5779 - recall: 0.5779 - val_loss: 0.6709 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 79/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6670 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 80/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6649 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 81/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6678 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 82/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.5664 - precision: 0.5664 - recall: 0.5664 - val_loss: 0.6685 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 83/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6725 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 84/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6860 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 85/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6757 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 86/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6891 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 87/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6884 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 88/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6769 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 89/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6729 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 90/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6795 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 91/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6683 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 92/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6693 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 93/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6853 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 94/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6824 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 95/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5841 - precision: 0.5841 - recall: 0.5841 - val_loss: 0.6849 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 96/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6736 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6803 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 97/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5841 - precision: 0.5841 - recall: 0.5841 - val_loss: 0.6685 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 98/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.5673 - precision: 0.5673 - recall: 0.5673 - val_loss: 0.6943 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 99/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7044 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 100/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6720 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 101/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6760 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 102/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5761 - precision: 0.5761 - recall: 0.5761 - val_loss: 0.6929 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 103/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6690 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 104/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6634 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 105/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6692 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 106/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6695 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 107/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6685 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 108/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6681 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6673 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 109/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.5726 - precision: 0.5726 - recall: 0.5726 - val_loss: 0.6761 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 110/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6778 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 111/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6668 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 112/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6695 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 113/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6755 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 114/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6722 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 115/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6817 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 116/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6594 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 117/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6724 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6720 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 118/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6676 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 119/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6784 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 120/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6640 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 121/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.6758 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 122/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6601 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 123/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5726 - precision: 0.5726 - recall: 0.5726 - val_loss: 0.6660 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 124/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.6767 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 125/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6761 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 126/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6697 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 127/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6671 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 128/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6742 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 129/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6801 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 130/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.5832 - precision: 0.5832 - recall: 0.5832 - val_loss: 0.6556 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 131/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6765 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 132/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.5832 - precision: 0.5832 - recall: 0.5832 - val_loss: 0.6704 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 133/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6723 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 134/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6689 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 135/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6664 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 136/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6619 - val_accuracy: 0.6270 - val_precision: 0.6270 - val_recall: 0.6270\n",
      "Epoch 137/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6769 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 138/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6744 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 139/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6640 - val_accuracy: 0.6207 - val_precision: 0.6207 - val_recall: 0.6207\n",
      "Epoch 140/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5885 - precision: 0.5885 - recall: 0.5885 - val_loss: 0.6694 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 141/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6687 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 142/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6697 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 143/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6696 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 144/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6777 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 145/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6626 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 146/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6682 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 147/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6661 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 148/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6606 - val_accuracy: 0.6301 - val_precision: 0.6301 - val_recall: 0.6301\n",
      "Epoch 149/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.5885 - precision: 0.5885 - recall: 0.5885 - val_loss: 0.6688 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 150/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6887 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 151/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6724 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 152/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6755 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.6593 - val_accuracy: 0.6207 - val_precision: 0.6207 - val_recall: 0.6207\n",
      "Epoch 153/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.5761 - precision: 0.5761 - recall: 0.5761 - val_loss: 0.6831 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 154/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6723 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 155/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6660 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6867 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 156/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6731 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 157/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6708 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 158/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.6736 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 159/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6817 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 160/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6877 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 161/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6688 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6951 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 162/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6859 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 163/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6683 - val_accuracy: 0.6050 - val_precision: 0.6050 - val_recall: 0.6050\n",
      "Epoch 164/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6727 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6508 - val_accuracy: 0.6301 - val_precision: 0.6301 - val_recall: 0.6301\n",
      "Epoch 165/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6626 - val_accuracy: 0.6113 - val_precision: 0.6113 - val_recall: 0.6113\n",
      "Epoch 166/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6707 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6793 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 167/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6833 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 168/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6672 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 169/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6749 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6779 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 170/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.6923 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 171/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6715 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.6783 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 172/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6774 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 173/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6815 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 174/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6736 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 175/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.6625 - val_accuracy: 0.6113 - val_precision: 0.6113 - val_recall: 0.6113\n",
      "Epoch 176/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6725 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6672 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 177/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6763 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 178/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6777 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 179/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6893 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 180/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6687 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 181/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6737 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 182/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6773 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 183/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6786 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 184/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6794 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 185/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6813 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 186/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6797 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 187/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6746 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 188/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6707 - val_accuracy: 0.6050 - val_precision: 0.6050 - val_recall: 0.6050\n",
      "Epoch 189/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6746 - val_accuracy: 0.6050 - val_precision: 0.6050 - val_recall: 0.6050\n",
      "Epoch 190/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6735 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 191/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6757 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 192/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5788 - precision: 0.5788 - recall: 0.5788 - val_loss: 0.6760 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 193/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6874 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 194/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7161 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 195/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6693 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 196/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6726 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6746 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 197/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6712 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 198/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6712 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 199/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6887 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 200/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6926 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 201/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6850 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 202/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6699 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 203/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.5761 - precision: 0.5761 - recall: 0.5761 - val_loss: 0.6698 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 204/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6782 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 205/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6849 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 206/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6775 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 207/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6795 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 208/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6793 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 209/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6876 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 210/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6823 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 211/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6865 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 212/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6920 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 213/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6920 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 214/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6797 - accuracy: 0.5805 - precision: 0.5805 - recall: 0.5805 - val_loss: 0.6764 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 215/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6954 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 216/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6920 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 217/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6869 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 218/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6777 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 219/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6774 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 220/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6867 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 221/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6875 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 222/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6842 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 223/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6886 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 224/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6800 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 225/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6900 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 226/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6828 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 227/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5832 - precision: 0.5832 - recall: 0.5832 - val_loss: 0.6766 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 228/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6839 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 229/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6936 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 230/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6773 - val_accuracy: 0.6050 - val_precision: 0.6050 - val_recall: 0.6050\n",
      "Epoch 231/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6939 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 232/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6958 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 233/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6906 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 234/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6899 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 235/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6845 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 236/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6877 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 237/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6892 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 238/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6785 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 239/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5867 - precision: 0.5867 - recall: 0.5867 - val_loss: 0.6910 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 240/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6884 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 241/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6786 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 242/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6888 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 243/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6789 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 244/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6766 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 245/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6956 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 246/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6875 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 247/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.6970 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 248/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6926 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 249/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6755 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 250/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6955 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 251/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6976 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 252/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6891 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 253/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6956 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 254/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6903 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 255/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6933 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 256/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6857 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 257/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6956 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 258/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6774 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 259/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6827 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 260/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - val_loss: 0.7049 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 261/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6918 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 262/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6953 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 263/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6769 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 264/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6810 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 265/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7109 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 266/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6972 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 267/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7000 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 268/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6955 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 269/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.7167 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 270/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6926 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 271/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7077 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 272/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7178 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 273/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6877 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 274/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7119 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 275/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6793 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 276/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7221 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 277/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6929 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 278/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7080 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 279/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.6825 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 280/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.5805 - precision: 0.5805 - recall: 0.5805 - val_loss: 0.6837 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 281/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5805 - precision: 0.5805 - recall: 0.5805 - val_loss: 0.6917 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 282/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6970 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 283/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7055 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 284/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7036 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 285/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7009 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 286/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7018 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 287/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.5885 - precision: 0.5885 - recall: 0.5885 - val_loss: 0.6900 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 288/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6801 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 289/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6960 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 290/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6982 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 291/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6950 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 292/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6721 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6862 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 293/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6923 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 294/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6848 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 295/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7102 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 296/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7022 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 297/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6902 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 298/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6845 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 299/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7082 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 300/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6659 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6939 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 301/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7139 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 302/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7096 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 303/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6915 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 304/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.6841 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 305/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5841 - precision: 0.5841 - recall: 0.5841 - val_loss: 0.6751 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 306/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6950 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 307/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6833 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 308/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6836 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 309/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6837 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 310/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7163 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 311/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6857 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 312/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7025 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 313/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6850 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 314/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6894 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 315/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6804 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 316/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6812 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 317/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6872 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 318/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7029 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 319/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6696 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6831 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 320/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7069 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 321/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6931 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 322/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7028 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 323/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6932 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 324/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6967 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 325/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6866 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 326/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.6893 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 327/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6657 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6892 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 328/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6917 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 329/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7032 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 330/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6901 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 331/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6799 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 332/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6916 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 333/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6929 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 334/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6989 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 335/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7045 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 336/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7222 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 337/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6827 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 338/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6967 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 339/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.6837 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 340/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6740 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 341/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6891 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 342/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.5885 - precision: 0.5885 - recall: 0.5885 - val_loss: 0.6868 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 343/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6844 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 344/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6860 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 345/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6871 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 346/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6809 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 347/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6981 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 348/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7046 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 349/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6911 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 350/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.5841 - precision: 0.5841 - recall: 0.5841 - val_loss: 0.6914 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 351/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.5743 - precision: 0.5743 - recall: 0.5743 - val_loss: 0.6793 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 352/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6932 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 353/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6966 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 354/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6901 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 355/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7005 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 356/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6798 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 357/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6816 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 358/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6923 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 359/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6963 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 360/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6903 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 361/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7042 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 362/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6892 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 363/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6952 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 364/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6990 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 365/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6805 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 366/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6777 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 367/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6832 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 368/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7016 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 369/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6442 - precision: 0.6442 - recall: 0.6442 - val_loss: 0.7032 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 370/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6942 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 371/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6912 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 372/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6963 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 373/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7058 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 374/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6956 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 375/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6948 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 376/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6850 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 377/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7166 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 378/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7140 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 379/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7065 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 380/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6998 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 381/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6916 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 382/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7081 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 383/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7050 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 384/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7030 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 385/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7128 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 386/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6907 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 387/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7019 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 388/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6781 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 389/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7180 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 390/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6955 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 391/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6858 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 392/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6912 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 393/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6991 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 394/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6899 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 395/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7001 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 396/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7344 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 397/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6989 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 398/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6930 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 399/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6670 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 400/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6889 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 401/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6912 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 402/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6793 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 403/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7053 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 404/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6965 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 405/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7042 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 406/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6996 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 407/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7067 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 408/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.7061 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 409/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7011 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 410/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6904 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 411/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7030 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 412/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6993 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 413/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6964 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 414/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6946 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 415/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6812 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 416/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6639 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6953 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 417/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6947 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 418/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6972 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 419/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6963 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 420/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6905 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 421/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7008 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 422/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7015 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 423/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6917 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 424/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7027 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 425/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7107 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 426/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.6987 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 427/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6661 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.6935 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 428/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7072 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 429/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6996 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 430/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7083 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 431/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7032 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 432/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6982 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 433/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7111 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 434/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.6995 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 435/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7013 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 436/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6900 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 437/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6989 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 438/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6912 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 439/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7026 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 440/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7123 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 441/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6984 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 442/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6862 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 443/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7078 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 444/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6962 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 445/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6816 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 446/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6904 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 447/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6841 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 448/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7032 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 449/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.6912 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 450/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6856 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 451/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7038 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 452/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7074 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 453/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7142 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 454/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.6762 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 455/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7132 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 456/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7019 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 457/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7018 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 458/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6822 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 459/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6928 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 460/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7155 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 461/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7117 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 462/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6930 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 463/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6913 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 464/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6834 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 465/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7010 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 466/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7076 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 467/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6929 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 468/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6975 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 469/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6874 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 470/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6895 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 471/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6930 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 472/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6923 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 473/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7034 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 474/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6944 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 475/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6812 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 476/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6945 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 477/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6824 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 478/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7033 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 479/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7084 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 480/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6928 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 481/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7082 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 482/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7187 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 483/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6934 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 484/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.6908 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 485/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7141 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 486/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6679 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.7014 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 487/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7046 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 488/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6926 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 489/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6961 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 490/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7126 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 491/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6943 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 492/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7124 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 493/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7123 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 494/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6910 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 495/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6986 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 496/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6731 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 497/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6948 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 498/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6945 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 499/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6873 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 500/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6791 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 501/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7121 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 502/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6980 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 503/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6902 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 504/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7109 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 505/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7000 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 506/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6993 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 507/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7118 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 508/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7045 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 509/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7047 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 510/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7020 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 511/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7015 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 512/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6877 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 513/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7068 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 514/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7293 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 515/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6998 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 516/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7014 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 517/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7011 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 518/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6970 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 519/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6964 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 520/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7089 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 521/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.7185 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 522/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7435 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 523/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7100 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 524/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7049 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 525/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6968 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 526/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7031 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 527/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7101 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 528/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6973 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 529/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7025 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 530/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6997 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 531/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6958 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 532/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7193 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 533/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7117 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 534/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7007 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 535/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6995 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 536/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6945 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 537/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7122 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 538/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6970 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 539/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7140 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 540/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6979 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 541/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7216 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 542/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7241 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 543/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7169 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 544/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7044 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 545/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6933 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 546/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7016 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 547/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6935 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 548/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7080 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 549/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6996 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 550/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6996 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 551/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7362 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 552/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7156 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 553/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7026 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 554/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6931 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 555/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7123 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 556/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7128 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 557/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7111 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 558/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7111 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 559/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6676 - accuracy: 0.5814 - precision: 0.5814 - recall: 0.5814 - val_loss: 0.7304 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 560/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6869 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 561/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7169 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 562/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7025 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 563/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6989 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 564/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7093 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 565/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6952 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 566/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6650 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7022 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 567/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6910 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 568/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7017 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 569/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6966 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 570/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6927 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 571/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7191 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 572/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6990 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 573/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.6892 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 574/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6957 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 575/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7277 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 576/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7059 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 577/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6664 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6899 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 578/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6946 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 579/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6948 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 580/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7093 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 581/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7169 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 582/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7089 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 583/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6827 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 584/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7204 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 585/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6952 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 586/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7067 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 587/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7070 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 588/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6998 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 589/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.6919 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 590/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7163 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 591/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6810 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 592/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6900 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 593/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7022 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 594/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7269 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 595/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7077 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 596/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6968 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 597/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7061 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 598/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6767 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 599/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7152 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 600/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6944 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 601/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7028 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 602/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7045 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 603/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7021 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 604/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6936 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 605/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7053 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 606/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7031 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 607/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7010 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 608/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6972 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 609/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.6902 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 610/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6950 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 611/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7053 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 612/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6908 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 613/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6953 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 614/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7030 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 615/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6632 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6870 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 616/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7033 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 617/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6919 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 618/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7042 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 619/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7028 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 620/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6871 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 621/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6937 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 622/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7027 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 623/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7003 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 624/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6596 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7186 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 625/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7031 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 626/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7015 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 627/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7408 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 628/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7335 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 629/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6903 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 630/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7105 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 631/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7023 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 632/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7033 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 633/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6920 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 634/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - val_loss: 0.7032 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 635/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6835 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 636/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6953 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 637/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6889 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 638/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6938 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 639/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6960 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 640/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7167 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 641/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7221 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 642/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7331 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 643/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6725 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 644/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7060 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 645/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6917 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 646/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.6914 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 647/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7019 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 648/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7121 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 649/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7062 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 650/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7018 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 651/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7109 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 652/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7002 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 653/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6628 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6969 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 654/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7074 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 655/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7144 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 656/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7239 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 657/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7119 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 658/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7223 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 659/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6904 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 660/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6958 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 661/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7127 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 662/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7049 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 663/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7004 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 664/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6915 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 665/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6827 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 666/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7004 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 667/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7132 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 668/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6893 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 669/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7091 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 670/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6994 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 671/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6992 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 672/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6849 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 673/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7048 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 674/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7072 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 675/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7007 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 676/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7105 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 677/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7216 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 678/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7037 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 679/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7047 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 680/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7053 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 681/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7161 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 682/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6954 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 683/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7058 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 684/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7008 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 685/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7284 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 686/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7056 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 687/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6968 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 688/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7017 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 689/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6913 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 690/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7065 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 691/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6752 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 692/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6398 - precision: 0.6398 - recall: 0.6398 - val_loss: 0.7260 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 693/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7330 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 694/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7019 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 695/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6964 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 696/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6862 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 697/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7105 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 698/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6983 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 699/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7411 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 700/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7011 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 701/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7114 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 702/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6728 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 703/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7051 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 704/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6794 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 705/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7064 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 706/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6779 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 707/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6927 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 708/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.6981 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 709/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7056 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 710/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7125 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 711/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7033 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 712/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6859 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 713/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7037 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 714/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6968 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 715/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6733 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 716/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7238 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 717/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6885 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 718/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6460 - precision: 0.6460 - recall: 0.6460 - val_loss: 0.7064 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 719/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7016 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 720/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7371 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 721/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7176 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 722/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7034 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 723/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7006 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 724/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6881 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 725/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - val_loss: 0.7093 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 726/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7176 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 727/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7163 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 728/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7171 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 729/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7042 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 730/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6916 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 731/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7120 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 732/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7041 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 733/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7135 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 734/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7041 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 735/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7153 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 736/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7143 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 737/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6950 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 738/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7350 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 739/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.6871 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 740/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7175 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 741/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7400 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 742/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7128 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 743/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6973 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 744/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7159 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 745/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7530 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 746/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.7081 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 747/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6927 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 748/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7240 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 749/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7066 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 750/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7271 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 751/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7026 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 752/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7027 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 753/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7005 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 754/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7103 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 755/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7263 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 756/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7164 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 757/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7032 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 758/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7058 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 759/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7140 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 760/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6959 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 761/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6916 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 762/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6999 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 763/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7115 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 764/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7085 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 765/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7023 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 766/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7149 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 767/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.5832 - precision: 0.5832 - recall: 0.5832 - val_loss: 0.7009 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 768/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7244 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 769/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7022 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 770/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6818 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 771/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.7223 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 772/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7011 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 773/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7128 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 774/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7102 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 775/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7299 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 776/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6957 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 777/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7098 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 778/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7162 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 779/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7016 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 780/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6835 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 781/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.6983 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 782/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.6965 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 783/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7072 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 784/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.7018 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 785/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.6993 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 786/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7113 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 787/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6933 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 788/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7267 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 789/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7023 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 790/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7049 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 791/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6811 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 792/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.6932 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 793/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6958 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 794/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7054 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 795/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6931 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 796/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7098 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 797/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6811 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 798/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7248 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 799/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7136 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 800/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6961 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 801/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6914 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 802/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7016 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 803/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7120 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 804/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6929 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 805/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6398 - precision: 0.6398 - recall: 0.6398 - val_loss: 0.7054 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 806/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7173 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 807/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7163 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 808/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6941 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 809/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7013 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 810/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6822 - val_accuracy: 0.6113 - val_precision: 0.6113 - val_recall: 0.6113\n",
      "Epoch 811/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6907 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 812/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7304 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 813/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6986 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 814/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6968 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 815/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7126 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 816/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6831 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 817/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7048 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 818/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6978 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 819/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6939 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 820/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7023 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 821/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7201 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 822/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6917 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 823/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7038 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 824/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7241 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 825/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7084 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 826/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7081 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 827/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7266 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 828/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6913 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 829/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7469 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 830/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7155 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 831/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7266 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 832/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7265 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 833/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7189 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 834/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7212 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 835/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7143 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 836/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7077 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 837/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6980 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 838/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7072 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 839/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7026 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 840/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7046 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 841/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7109 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 842/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7246 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 843/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7065 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 844/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7119 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 845/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7058 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 846/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7361 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 847/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7287 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 848/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7103 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 849/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7306 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 850/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7036 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 851/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7103 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 852/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7085 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 853/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7257 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 854/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7141 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 855/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6912 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 856/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7189 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 857/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7126 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 858/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7013 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 859/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7090 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 860/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7200 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 861/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7309 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 862/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7178 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 863/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7160 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 864/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7072 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 865/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7285 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 866/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7120 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 867/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - val_loss: 0.7176 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 868/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6791 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 869/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6953 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 870/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7047 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 871/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7009 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 872/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - val_loss: 0.6957 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 873/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.7193 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 874/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6411 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7211 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 875/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7113 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 876/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7298 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 877/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.5832 - precision: 0.5832 - recall: 0.5832 - val_loss: 0.6984 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 878/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7321 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 879/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7248 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 880/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7393 - val_accuracy: 0.4671 - val_precision: 0.4671 - val_recall: 0.4671\n",
      "Epoch 881/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7127 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 882/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7212 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 883/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7006 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 884/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7096 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 885/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6967 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 886/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7144 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 887/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7119 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 888/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6977 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 889/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6949 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 890/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7101 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 891/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7043 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 892/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7062 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 893/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7175 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 894/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7268 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 895/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7058 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 896/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7095 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 897/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6899 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 898/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7094 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 899/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7126 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 900/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7060 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 901/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7048 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 902/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - val_loss: 0.7061 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 903/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7121 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 904/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7021 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 905/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7358 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 906/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7236 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 907/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7055 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 908/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7199 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 909/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7137 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 910/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6946 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 911/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7376 - val_accuracy: 0.4734 - val_precision: 0.4734 - val_recall: 0.4734\n",
      "Epoch 912/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6635 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7128 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 913/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7069 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 914/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7094 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 915/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7029 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 916/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7042 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 917/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7251 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 918/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6966 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 919/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7063 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 920/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7190 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 921/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7224 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 922/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7413 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 923/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7005 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 924/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7085 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 925/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7083 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 926/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7363 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 927/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7161 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 928/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7166 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 929/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6981 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 930/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7100 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 931/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7142 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 932/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7335 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 933/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7100 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 934/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7104 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 935/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7140 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 936/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7090 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 937/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7223 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 938/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7084 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 939/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7189 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 940/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7136 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 941/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7084 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 942/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7267 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 943/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7216 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 944/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7246 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 945/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7004 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 946/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7293 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 947/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6739 - val_accuracy: 0.6082 - val_precision: 0.6082 - val_recall: 0.6082\n",
      "Epoch 948/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7105 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 949/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7029 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 950/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7052 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 951/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7081 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 952/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6829 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 953/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7167 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 954/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7056 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 955/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7260 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 956/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7032 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 957/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7261 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 958/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7198 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 959/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7089 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 960/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7087 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 961/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7083 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 962/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6983 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 963/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7217 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 964/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7050 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 965/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7006 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 966/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7108 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 967/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7179 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 968/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7111 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 969/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7204 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 970/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7095 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 971/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7182 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 972/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7081 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 973/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7025 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 974/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6961 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 975/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7348 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 976/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6960 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 977/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7120 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 978/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7115 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 979/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7038 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 980/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6945 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 981/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6999 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 982/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7369 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 983/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7258 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 984/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7143 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 985/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7262 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 986/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7086 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 987/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - val_loss: 0.7460 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 988/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7075 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 989/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7193 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 990/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7218 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 991/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7097 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 992/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7265 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 993/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6924 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 994/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.7280 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 995/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7102 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 996/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.5876 - precision: 0.5876 - recall: 0.5876 - val_loss: 0.7031 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 997/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7132 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 998/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7079 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 999/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7119 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1000/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.7078 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1001/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7085 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1002/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7439 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1003/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7392 - val_accuracy: 0.4608 - val_precision: 0.4608 - val_recall: 0.4608\n",
      "Epoch 1004/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7232 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1005/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7224 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1006/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7125 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1007/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7077 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1008/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7240 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1009/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7061 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1010/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7209 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1011/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7209 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1012/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6705 - accuracy: 0.5673 - precision: 0.5673 - recall: 0.5673 - val_loss: 0.7129 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1013/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7196 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1014/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7038 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1015/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7106 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1016/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7239 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1017/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6398 - precision: 0.6398 - recall: 0.6398 - val_loss: 0.7312 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1018/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7191 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1019/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6954 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1020/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7179 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1021/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6932 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1022/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7092 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1023/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6907 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1024/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7029 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 1025/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6938 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1026/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7115 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1027/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7139 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1028/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7237 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1029/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7102 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1030/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7076 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1031/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6903 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1032/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7273 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1033/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7217 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1034/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7330 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1035/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7000 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1036/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7246 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1037/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7043 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1038/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7335 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1039/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6997 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1040/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7311 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1041/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7172 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1042/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7055 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1043/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7147 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1044/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6909 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1045/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5850 - precision: 0.5850 - recall: 0.5850 - val_loss: 0.7065 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1046/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7353 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1047/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7146 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1048/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7230 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1049/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.7075 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1050/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7268 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1051/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7506 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1052/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7080 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1053/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7251 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1054/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7243 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1055/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6792 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 1056/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6953 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1057/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.5858 - precision: 0.5858 - recall: 0.5858 - val_loss: 0.7275 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1058/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7181 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1059/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7289 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1060/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6921 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1061/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7056 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1062/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7050 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1063/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7427 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1064/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7161 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1065/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6887 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1066/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7120 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1067/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7272 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1068/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7297 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1069/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7005 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1070/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7096 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1071/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7209 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1072/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6969 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1073/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7086 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1074/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6944 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1075/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6846 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1076/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6954 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1077/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6993 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1078/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7057 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1079/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - val_loss: 0.7073 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1080/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7132 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1081/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7253 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1082/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7289 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1083/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7055 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1084/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7156 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1085/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7164 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1086/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7224 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1087/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7027 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1088/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7200 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1089/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.6993 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1090/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6850 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1091/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7013 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1092/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7203 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1093/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6982 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1094/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7016 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1095/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7039 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1096/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6904 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1097/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.6983 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1098/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7013 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1099/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6993 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1100/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7137 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1101/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7044 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1102/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6867 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1103/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7180 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1104/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7059 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1105/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7044 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1106/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7025 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1107/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.6789 - val_accuracy: 0.6050 - val_precision: 0.6050 - val_recall: 0.6050\n",
      "Epoch 1108/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7151 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1109/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7137 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1110/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7131 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1111/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7111 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1112/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7144 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1113/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7015 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1114/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7224 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1115/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7169 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1116/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7263 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1117/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7253 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1118/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7086 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1119/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6981 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1120/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7126 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1121/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7004 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1122/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6945 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1123/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7001 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1124/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6487 - precision: 0.6487 - recall: 0.6487 - val_loss: 0.7129 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1125/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7038 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1126/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7193 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1127/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7243 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1128/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7054 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1129/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7283 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1130/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7256 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1131/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7043 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1132/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7240 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1133/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7153 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1134/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7047 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1135/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6988 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1136/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7024 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1137/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7146 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1138/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7258 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1139/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7025 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1140/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6894 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1141/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7156 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1142/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7102 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1143/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7388 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1144/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7365 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1145/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7212 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1146/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5912 - precision: 0.5912 - recall: 0.5912 - val_loss: 0.6940 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1147/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7158 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1148/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7356 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1149/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7328 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1150/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7448 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1151/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7542 - val_accuracy: 0.4671 - val_precision: 0.4671 - val_recall: 0.4671\n",
      "Epoch 1152/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7210 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1153/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7080 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1154/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7266 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1155/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7185 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1156/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7248 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1157/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7292 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1158/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7249 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1159/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7198 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1160/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7162 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1161/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7216 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1162/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6987 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1163/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7236 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1164/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7116 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1165/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6928 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1166/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7005 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1167/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7219 - val_accuracy: 0.4796 - val_precision: 0.4796 - val_recall: 0.4796\n",
      "Epoch 1168/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6619 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.7070 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1169/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6867 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1170/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6837 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 1171/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6952 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1172/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6989 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1173/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7066 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1174/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7095 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1175/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6979 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1176/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7051 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1177/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7330 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1178/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7265 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1179/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7111 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1180/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7053 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1181/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7114 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1182/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6658 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7128 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1183/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6950 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1184/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7093 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1185/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7159 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1186/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6933 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1187/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7139 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1188/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7038 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1189/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7091 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1190/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7164 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1191/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7019 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1192/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.5805 - precision: 0.5805 - recall: 0.5805 - val_loss: 0.6967 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1193/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7069 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1194/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6979 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1195/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7079 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1196/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - val_loss: 0.7094 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1197/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7062 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1198/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7234 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1199/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7392 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1200/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7369 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1201/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7143 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1202/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7619 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1203/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7508 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1204/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7256 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1205/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7097 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1206/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6909 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1207/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7165 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1208/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7145 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1209/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6915 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1210/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7170 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1211/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6969 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1212/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7003 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1213/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7279 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1214/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7013 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1215/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7059 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1216/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7101 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1217/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6831 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1218/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6968 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1219/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - val_loss: 0.7253 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1220/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7230 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1221/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7067 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1222/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7206 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1223/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7182 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1224/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7354 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1225/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7020 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1226/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7242 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1227/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7193 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1228/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - val_loss: 0.7412 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1229/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7069 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1230/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7457 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1231/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6504 - precision: 0.6504 - recall: 0.6504 - val_loss: 0.7380 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1232/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7427 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1233/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7182 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1234/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7341 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1235/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7519 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1236/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7166 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1237/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7144 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1238/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7421 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1239/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7117 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1240/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7259 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1241/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7283 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1242/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7160 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1243/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7307 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1244/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7120 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1245/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7260 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1246/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7105 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1247/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7098 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1248/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7303 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1249/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7262 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1250/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7041 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1251/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7285 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1252/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7089 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1253/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7180 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1254/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7293 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1255/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7305 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1256/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7251 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1257/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7098 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1258/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7117 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1259/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6991 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1260/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7253 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1261/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7209 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1262/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.6988 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1263/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7080 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1264/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6815 - val_accuracy: 0.6176 - val_precision: 0.6176 - val_recall: 0.6176\n",
      "Epoch 1265/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6789 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1266/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6407 - precision: 0.6407 - recall: 0.6407 - val_loss: 0.7052 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1267/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - val_loss: 0.7077 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1268/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7445 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1269/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7274 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1270/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7162 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1271/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7175 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1272/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.6913 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 1273/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7069 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1274/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.6995 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 1275/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.6991 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1276/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6966 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 1277/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7303 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1278/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.6975 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1279/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7035 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1280/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7211 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1281/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7250 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1282/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7134 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1283/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.6969 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1284/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.6951 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 1285/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7203 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1286/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.6988 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1287/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6531 - precision: 0.6531 - recall: 0.6531 - val_loss: 0.7220 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1288/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6972 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1289/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7109 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1290/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7076 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1291/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7013 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1292/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7413 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1293/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7269 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1294/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7264 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1295/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6913 - val_accuracy: 0.5956 - val_precision: 0.5956 - val_recall: 0.5956\n",
      "Epoch 1296/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7002 - val_accuracy: 0.5831 - val_precision: 0.5831 - val_recall: 0.5831\n",
      "Epoch 1297/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7293 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1298/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7289 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1299/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7026 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1300/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7142 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1301/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7043 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1302/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7165 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1303/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7331 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1304/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7280 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1305/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7159 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1306/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7397 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1307/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7202 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1308/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7252 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1309/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7529 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1310/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7253 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1311/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6496 - precision: 0.6496 - recall: 0.6496 - val_loss: 0.7318 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1312/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7631 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1313/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7223 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1314/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7139 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1315/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7017 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1316/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7041 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1317/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7094 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1318/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7104 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1319/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7066 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1320/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7073 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1321/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6991 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1322/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7117 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1323/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7309 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1324/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7023 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1325/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7162 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1326/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6899 - val_accuracy: 0.6019 - val_precision: 0.6019 - val_recall: 0.6019\n",
      "Epoch 1327/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7125 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1328/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7281 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1329/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7217 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1330/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7039 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1331/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7053 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1332/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7209 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1333/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7111 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1334/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7081 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1335/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7170 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1336/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.6949 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1337/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7293 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1338/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6957 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1339/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7089 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1340/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6887 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1341/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6823 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 1342/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7001 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1343/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.6935 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1344/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6407 - precision: 0.6407 - recall: 0.6407 - val_loss: 0.6986 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1345/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6943 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1346/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7107 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1347/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7028 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1348/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7171 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1349/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.6487 - precision: 0.6487 - recall: 0.6487 - val_loss: 0.7079 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1350/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6923 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1351/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.6898 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1352/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7028 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1353/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.6975 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1354/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7139 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1355/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6433 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7178 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1356/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7206 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1357/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7131 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1358/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.6937 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1359/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7062 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1360/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7151 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1361/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6469 - precision: 0.6469 - recall: 0.6469 - val_loss: 0.7035 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1362/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7025 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1363/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6982 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1364/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7405 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1365/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6937 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1366/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.6944 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1367/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7166 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1368/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6843 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 1369/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7240 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1370/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7247 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1371/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7137 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1372/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7219 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1373/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7189 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1374/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6912 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1375/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7176 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1376/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7192 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1377/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.6982 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1378/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7099 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1379/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7538 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1380/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7263 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1381/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7168 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1382/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7162 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1383/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7419 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1384/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7150 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1385/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6886 - val_accuracy: 0.5987 - val_precision: 0.5987 - val_recall: 0.5987\n",
      "Epoch 1386/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7137 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1387/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7096 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1388/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7089 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1389/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7058 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1390/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7247 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1391/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6979 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1392/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6958 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1393/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7137 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1394/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7091 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1395/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7036 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1396/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7247 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1397/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7236 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1398/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6978 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1399/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7338 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1400/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7276 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1401/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7087 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1402/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7087 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1403/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7047 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1404/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7091 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1405/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7205 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1406/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7136 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1407/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7147 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1408/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7183 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1409/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7179 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1410/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7026 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1411/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7247 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1412/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7018 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1413/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7271 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1414/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7160 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1415/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6953 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1416/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7091 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1417/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6953 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1418/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7043 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1419/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7047 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1420/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7198 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1421/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7130 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1422/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7257 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1423/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6944 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1424/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7207 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1425/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7311 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1426/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7337 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1427/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7160 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1428/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7054 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1429/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7186 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1430/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7272 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1431/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7616 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1432/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7080 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1433/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6987 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1434/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7072 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1435/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7095 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1436/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7038 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1437/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7143 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1438/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7116 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1439/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7096 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1440/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7175 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1441/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7135 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1442/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7015 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1443/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7234 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1444/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7124 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1445/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7120 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1446/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7144 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1447/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7058 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1448/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7162 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1449/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7214 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1450/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7116 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1451/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7143 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1452/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7120 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1453/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7524 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1454/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7396 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1455/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7359 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1456/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7309 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1457/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.6407 - precision: 0.6407 - recall: 0.6407 - val_loss: 0.7338 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1458/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7130 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1459/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.5938 - precision: 0.5938 - recall: 0.5938 - val_loss: 0.7034 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1460/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7352 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1461/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7028 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1462/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7160 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1463/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7251 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1464/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7051 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1465/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7098 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1466/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7256 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1467/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7062 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1468/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7375 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1469/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6967 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1470/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7200 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1471/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7286 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1472/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7033 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1473/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7026 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1474/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6971 - val_accuracy: 0.5893 - val_precision: 0.5893 - val_recall: 0.5893\n",
      "Epoch 1475/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7162 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1476/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7093 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1477/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7062 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1478/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6976 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1479/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7272 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1480/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7145 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1481/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7313 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1482/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7098 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1483/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7320 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1484/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7000 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1485/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7032 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1486/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7227 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1487/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7469 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1488/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7111 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1489/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7241 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1490/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7294 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1491/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.6940 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1492/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6980 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 1493/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6975 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1494/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7075 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1495/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6981 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1496/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.6919 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1497/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6954 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1498/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7085 - val_accuracy: 0.5799 - val_precision: 0.5799 - val_recall: 0.5799\n",
      "Epoch 1499/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7356 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1500/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7362 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1501/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7081 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1502/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7243 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1503/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7272 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1504/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7362 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1505/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7435 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1506/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7041 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1507/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7315 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1508/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7191 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1509/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7316 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1510/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7178 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1511/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7122 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1512/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7040 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1513/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7329 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1514/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6469 - precision: 0.6469 - recall: 0.6469 - val_loss: 0.7250 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1515/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7162 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1516/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7327 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1517/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7276 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1518/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.6983 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1519/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.6969 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1520/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7156 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1521/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7086 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1522/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7288 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1523/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7024 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1524/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7134 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1525/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7045 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1526/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7145 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1527/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6979 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1528/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7073 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1529/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7247 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1530/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7215 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1531/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7267 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1532/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7394 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1533/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7181 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1534/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7078 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1535/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7211 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1536/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7099 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1537/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7032 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1538/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7073 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1539/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7360 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1540/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7017 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1541/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7455 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1542/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7250 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1543/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7229 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1544/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7592 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1545/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7011 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1546/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7184 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1547/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7436 - val_accuracy: 0.4796 - val_precision: 0.4796 - val_recall: 0.4796\n",
      "Epoch 1548/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7363 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1549/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7206 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1550/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7067 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1551/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7149 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1552/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7107 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1553/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7144 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1554/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7126 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1555/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7392 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1556/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7428 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1557/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7315 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1558/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7277 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1559/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6487 - precision: 0.6487 - recall: 0.6487 - val_loss: 0.7465 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1560/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7141 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1561/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7051 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1562/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7251 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1563/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7149 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1564/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7203 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1565/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6460 - precision: 0.6460 - recall: 0.6460 - val_loss: 0.7521 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1566/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7216 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1567/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7269 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1568/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6940 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1569/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7459 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1570/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7209 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1571/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7140 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1572/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7171 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1573/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7164 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1574/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7135 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1575/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7206 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1576/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7079 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1577/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7190 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1578/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6974 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1579/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.6983 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1580/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7062 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1581/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7120 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1582/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7191 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1583/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7206 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1584/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7119 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1585/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7081 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1586/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7132 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1587/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7104 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1588/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7161 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1589/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7178 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1590/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6997 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1591/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6945 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1592/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7096 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1593/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7009 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1594/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7007 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1595/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7113 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1596/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7138 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1597/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7048 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1598/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5823 - precision: 0.5823 - recall: 0.5823 - val_loss: 0.6887 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1599/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6979 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1600/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7064 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1601/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7061 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1602/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7127 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1603/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7055 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1604/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.6981 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1605/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6937 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1606/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7015 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1607/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7213 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1608/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7015 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1609/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - val_loss: 0.6979 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1610/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7302 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1611/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7157 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1612/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5885 - precision: 0.5885 - recall: 0.5885 - val_loss: 0.6944 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1613/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7191 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1614/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7177 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1615/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7122 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1616/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7062 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1617/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7090 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1618/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6930 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1619/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7040 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1620/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6994 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1621/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7094 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1622/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.6964 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1623/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7074 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1624/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.6899 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1625/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7072 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1626/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7526 - val_accuracy: 0.4639 - val_precision: 0.4639 - val_recall: 0.4639\n",
      "Epoch 1627/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7379 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1628/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7166 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1629/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7316 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1630/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7188 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1631/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7128 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1632/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7150 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1633/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7550 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1634/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7186 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1635/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6531 - precision: 0.6531 - recall: 0.6531 - val_loss: 0.7324 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1636/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7287 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1637/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7476 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1638/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7421 - val_accuracy: 0.4671 - val_precision: 0.4671 - val_recall: 0.4671\n",
      "Epoch 1639/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7188 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1640/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7279 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1641/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7235 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1642/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7128 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1643/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7156 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1644/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7161 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1645/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7022 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1646/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7361 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1647/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7062 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1648/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7117 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1649/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7297 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1650/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7174 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1651/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7115 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1652/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6969 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1653/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7059 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1654/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7270 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1655/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7160 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1656/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7072 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1657/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.5894 - precision: 0.5894 - recall: 0.5894 - val_loss: 0.7163 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1658/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7226 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1659/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7288 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1660/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7138 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1661/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7132 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1662/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7182 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1663/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7186 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1664/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7348 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1665/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7006 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1666/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7127 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1667/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7072 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1668/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7277 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1669/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7197 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1670/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7293 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1671/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7346 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1672/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7321 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1673/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7518 - val_accuracy: 0.4702 - val_precision: 0.4702 - val_recall: 0.4702\n",
      "Epoch 1674/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6460 - precision: 0.6460 - recall: 0.6460 - val_loss: 0.7352 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1675/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7229 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1676/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6454 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7247 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1677/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7224 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1678/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7107 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1679/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7533 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1680/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6409 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7026 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1681/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7011 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1682/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7318 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1683/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7162 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1684/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7005 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1685/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.6860 - val_accuracy: 0.5925 - val_precision: 0.5925 - val_recall: 0.5925\n",
      "Epoch 1686/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7224 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1687/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7377 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1688/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7155 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1689/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7206 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1690/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7218 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1691/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7065 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1692/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7370 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1693/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6409 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7005 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1694/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7149 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1695/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7545 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1696/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7127 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1697/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6407 - precision: 0.6407 - recall: 0.6407 - val_loss: 0.7172 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1698/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7213 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1699/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - val_loss: 0.7329 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1700/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7196 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1701/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7146 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1702/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7106 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1703/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7117 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1704/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7239 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1705/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7111 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1706/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6970 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1707/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7149 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1708/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7356 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1709/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7169 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1710/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6414 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7182 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1711/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.7133 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1712/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7049 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1713/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7241 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1714/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7335 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1715/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7213 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1716/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7097 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1717/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.6995 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1718/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.6911 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1719/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.5929 - precision: 0.5929 - recall: 0.5929 - val_loss: 0.7053 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1720/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7117 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1721/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7101 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1722/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7257 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1723/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7173 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 1724/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7049 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1725/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7315 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1726/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7165 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1727/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7758 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1728/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7375 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1729/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7406 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1730/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7259 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1731/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7073 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1732/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7926 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1733/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6452 - accuracy: 0.6363 - precision: 0.6363 - recall: 0.6363 - val_loss: 0.7041 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1734/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7365 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1735/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7026 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1736/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7046 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1737/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7065 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1738/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.6984 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1739/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7392 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1740/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7208 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1741/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7139 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1742/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7079 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1743/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7375 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1744/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7043 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1745/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7149 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1746/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7333 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1747/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6000 - precision: 0.6000 - recall: 0.6000 - val_loss: 0.7372 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1748/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7540 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1749/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7092 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1750/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7380 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1751/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6009 - precision: 0.6009 - recall: 0.6009 - val_loss: 0.7427 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1752/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7239 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1753/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7263 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1754/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7114 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1755/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7172 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1756/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7095 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1757/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7315 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1758/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7251 - val_accuracy: 0.4796 - val_precision: 0.4796 - val_recall: 0.4796\n",
      "Epoch 1759/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7537 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1760/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7431 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1761/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7523 - val_accuracy: 0.4671 - val_precision: 0.4671 - val_recall: 0.4671\n",
      "Epoch 1762/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7104 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1763/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.6460 - precision: 0.6460 - recall: 0.6460 - val_loss: 0.7213 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1764/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7273 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1765/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6463 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7260 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1766/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7148 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1767/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.5973 - precision: 0.5973 - recall: 0.5973 - val_loss: 0.7082 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1768/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7396 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1769/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7452 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1770/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7086 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1771/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - val_loss: 0.7479 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1772/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7155 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1773/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7034 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1774/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7192 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1775/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7102 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1776/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7198 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1777/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7087 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1778/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7195 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1779/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6440 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7308 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1780/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7297 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1781/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.7271 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1782/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7136 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1783/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6984 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1784/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.5965 - precision: 0.5965 - recall: 0.5965 - val_loss: 0.7104 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1785/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.6995 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1786/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7052 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1787/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6911 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1788/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7301 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1789/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7326 - val_accuracy: 0.4859 - val_precision: 0.4859 - val_recall: 0.4859\n",
      "Epoch 1790/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7167 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1791/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7255 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1792/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7275 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1793/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7176 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1794/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7222 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1795/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7207 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1796/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7086 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1797/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6496 - precision: 0.6496 - recall: 0.6496 - val_loss: 0.7283 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1798/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7199 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1799/2000\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7221 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1800/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7084 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1801/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7136 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1802/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7234 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1803/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7224 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1804/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7382 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1805/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7334 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1806/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7150 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1807/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6381 - precision: 0.6381 - recall: 0.6381 - val_loss: 0.7267 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1808/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7159 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1809/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5956 - precision: 0.5956 - recall: 0.5956 - val_loss: 0.7173 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1810/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7100 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1811/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7004 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1812/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7102 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1813/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7046 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1814/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7144 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1815/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7174 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1816/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7348 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1817/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7084 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1818/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7167 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1819/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7174 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1820/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7452 - val_accuracy: 0.4765 - val_precision: 0.4765 - val_recall: 0.4765\n",
      "Epoch 1821/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7010 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1822/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6978 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1823/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7218 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1824/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.6895 - val_accuracy: 0.5862 - val_precision: 0.5862 - val_recall: 0.5862\n",
      "Epoch 1825/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7098 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1826/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7361 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1827/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7108 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1828/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6988 - val_accuracy: 0.5737 - val_precision: 0.5737 - val_recall: 0.5737\n",
      "Epoch 1829/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7023 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1830/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7101 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1831/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7158 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1832/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6584 - precision: 0.6584 - recall: 0.6584 - val_loss: 0.7225 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1833/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6981 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1834/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.6852 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1835/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.7399 - val_accuracy: 0.4922 - val_precision: 0.4922 - val_recall: 0.4922\n",
      "Epoch 1836/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.6874 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1837/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7026 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1838/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7187 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1839/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6044 - precision: 0.6044 - recall: 0.6044 - val_loss: 0.7135 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1840/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6434 - precision: 0.6434 - recall: 0.6434 - val_loss: 0.7559 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1841/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7308 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1842/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7125 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1843/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7111 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1844/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7083 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1845/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6416 - precision: 0.6416 - recall: 0.6416 - val_loss: 0.7256 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1846/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6974 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1847/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7035 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1848/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.7194 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1849/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7170 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1850/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7015 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1851/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7113 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1852/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7465 - val_accuracy: 0.4828 - val_precision: 0.4828 - val_recall: 0.4828\n",
      "Epoch 1853/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7083 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1854/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7170 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1855/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7088 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1856/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7080 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1857/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7158 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1858/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6443 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.6999 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1859/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7064 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1860/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7253 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1861/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7255 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1862/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7176 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1863/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.6890 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1864/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7045 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1865/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7047 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1866/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.6911 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1867/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7020 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1868/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7263 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016\n",
      "Epoch 1869/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.6996 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1870/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7158 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1871/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7127 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1872/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7042 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1873/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.6354 - precision: 0.6354 - recall: 0.6354 - val_loss: 0.7328 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1874/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7043 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1875/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7031 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1876/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6487 - precision: 0.6487 - recall: 0.6487 - val_loss: 0.7385 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1877/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7122 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1878/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6018 - precision: 0.6018 - recall: 0.6018 - val_loss: 0.7173 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1879/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7318 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1880/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7255 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1881/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7137 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1882/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7320 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1883/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7292 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1884/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7297 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1885/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7009 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1886/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7070 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1887/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7208 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1888/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.6968 - val_accuracy: 0.5674 - val_precision: 0.5674 - val_recall: 0.5674\n",
      "Epoch 1889/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5991 - precision: 0.5991 - recall: 0.5991 - val_loss: 0.7136 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1890/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5796 - precision: 0.5796 - recall: 0.5796 - val_loss: 0.7076 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1891/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.7113 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1892/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.6970 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1893/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6274 - precision: 0.6274 - recall: 0.6274 - val_loss: 0.6971 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1894/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.5903 - precision: 0.5903 - recall: 0.5903 - val_loss: 0.7137 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1895/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7142 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1896/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7185 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1897/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6115 - precision: 0.6115 - recall: 0.6115 - val_loss: 0.6969 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1898/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7027 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1899/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6961 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1900/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7147 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1901/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7016 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1902/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7036 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1903/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7185 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1904/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.7058 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1905/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7389 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1906/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7379 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1907/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7078 - val_accuracy: 0.5705 - val_precision: 0.5705 - val_recall: 0.5705\n",
      "Epoch 1908/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7292 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1909/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7096 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1910/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7158 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1911/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6567 - accuracy: 0.6053 - precision: 0.6053 - recall: 0.6053 - val_loss: 0.7190 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1912/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7185 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1913/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7198 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1914/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7212 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1915/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6062 - precision: 0.6062 - recall: 0.6062 - val_loss: 0.7366 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1916/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6563 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7161 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078\n",
      "Epoch 1917/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7087 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1918/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6292 - precision: 0.6292 - recall: 0.6292 - val_loss: 0.7161 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1919/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7296 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1920/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.7350 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1921/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7099 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1922/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7402 - val_accuracy: 0.4953 - val_precision: 0.4953 - val_recall: 0.4953\n",
      "Epoch 1923/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.7056 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1924/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6336 - precision: 0.6336 - recall: 0.6336 - val_loss: 0.7334 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1925/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7266 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1926/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6967 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1927/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7259 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110\n",
      "Epoch 1928/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.6921 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1929/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7114 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1930/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7405 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1931/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7223 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1932/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7205 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1933/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7018 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1934/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5920 - precision: 0.5920 - recall: 0.5920 - val_loss: 0.7132 - val_accuracy: 0.4984 - val_precision: 0.4984 - val_recall: 0.4984\n",
      "Epoch 1935/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.7006 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1936/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7411 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1937/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6035 - precision: 0.6035 - recall: 0.6035 - val_loss: 0.7033 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1938/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6467 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.7135 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1939/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7033 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1940/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6088 - precision: 0.6088 - recall: 0.6088 - val_loss: 0.7062 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1941/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7154 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1942/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7202 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1943/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6195 - precision: 0.6195 - recall: 0.6195 - val_loss: 0.7060 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1944/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7344 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1945/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6448 - accuracy: 0.6310 - precision: 0.6310 - recall: 0.6310 - val_loss: 0.7240 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1946/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.7455 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1947/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6916 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1948/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6265 - precision: 0.6265 - recall: 0.6265 - val_loss: 0.7037 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1949/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.6221 - precision: 0.6221 - recall: 0.6221 - val_loss: 0.6872 - val_accuracy: 0.5517 - val_precision: 0.5517 - val_recall: 0.5517\n",
      "Epoch 1950/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.6965 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1951/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - val_loss: 0.7574 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047\n",
      "Epoch 1952/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6451 - precision: 0.6451 - recall: 0.6451 - val_loss: 0.7042 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1953/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - val_loss: 0.6890 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1954/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6257 - precision: 0.6257 - recall: 0.6257 - val_loss: 0.7176 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1955/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6230 - precision: 0.6230 - recall: 0.6230 - val_loss: 0.7163 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1956/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7070 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1957/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.6933 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1958/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6345 - precision: 0.6345 - recall: 0.6345 - val_loss: 0.6950 - val_accuracy: 0.5768 - val_precision: 0.5768 - val_recall: 0.5768\n",
      "Epoch 1959/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6890 - val_accuracy: 0.5611 - val_precision: 0.5611 - val_recall: 0.5611\n",
      "Epoch 1960/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6407 - precision: 0.6407 - recall: 0.6407 - val_loss: 0.6933 - val_accuracy: 0.5643 - val_precision: 0.5643 - val_recall: 0.5643\n",
      "Epoch 1961/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.7084 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1962/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6531 - precision: 0.6531 - recall: 0.6531 - val_loss: 0.7041 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1963/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7179 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1964/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7105 - val_accuracy: 0.5141 - val_precision: 0.5141 - val_recall: 0.5141\n",
      "Epoch 1965/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.5947 - precision: 0.5947 - recall: 0.5947 - val_loss: 0.7083 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1966/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.7049 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1967/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6283 - precision: 0.6283 - recall: 0.6283 - val_loss: 0.6895 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1968/2000\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.6124 - precision: 0.6124 - recall: 0.6124 - val_loss: 0.6879 - val_accuracy: 0.5455 - val_precision: 0.5455 - val_recall: 0.5455\n",
      "Epoch 1969/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6967 - val_accuracy: 0.5298 - val_precision: 0.5298 - val_recall: 0.5298\n",
      "Epoch 1970/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.6912 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1971/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.7077 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1972/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.6891 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1973/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6372 - precision: 0.6372 - recall: 0.6372 - val_loss: 0.6953 - val_accuracy: 0.5580 - val_precision: 0.5580 - val_recall: 0.5580\n",
      "Epoch 1974/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.6389 - precision: 0.6389 - recall: 0.6389 - val_loss: 0.6997 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1975/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7206 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1976/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6647 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7047 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1977/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6425 - precision: 0.6425 - recall: 0.6425 - val_loss: 0.6963 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1978/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7140 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1979/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6168 - precision: 0.6168 - recall: 0.6168 - val_loss: 0.7487 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1980/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7155 - val_accuracy: 0.5361 - val_precision: 0.5361 - val_recall: 0.5361\n",
      "Epoch 1981/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6212 - precision: 0.6212 - recall: 0.6212 - val_loss: 0.7120 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1982/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7363 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1983/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6319 - precision: 0.6319 - recall: 0.6319 - val_loss: 0.7097 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1984/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.7024 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1985/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6248 - precision: 0.6248 - recall: 0.6248 - val_loss: 0.6876 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1986/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6027 - precision: 0.6027 - recall: 0.6027 - val_loss: 0.6956 - val_accuracy: 0.5392 - val_precision: 0.5392 - val_recall: 0.5392\n",
      "Epoch 1987/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6301 - precision: 0.6301 - recall: 0.6301 - val_loss: 0.7108 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n",
      "Epoch 1988/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.6142 - precision: 0.6142 - recall: 0.6142 - val_loss: 0.7007 - val_accuracy: 0.5266 - val_precision: 0.5266 - val_recall: 0.5266\n",
      "Epoch 1989/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6239 - precision: 0.6239 - recall: 0.6239 - val_loss: 0.6902 - val_accuracy: 0.5423 - val_precision: 0.5423 - val_recall: 0.5423\n",
      "Epoch 1990/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6487 - precision: 0.6487 - recall: 0.6487 - val_loss: 0.6913 - val_accuracy: 0.5549 - val_precision: 0.5549 - val_recall: 0.5549\n",
      "Epoch 1991/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6106 - precision: 0.6106 - recall: 0.6106 - val_loss: 0.6990 - val_accuracy: 0.5235 - val_precision: 0.5235 - val_recall: 0.5235\n",
      "Epoch 1992/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.5982 - precision: 0.5982 - recall: 0.5982 - val_loss: 0.6972 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1993/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6080 - precision: 0.6080 - recall: 0.6080 - val_loss: 0.7162 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1994/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6542 - accuracy: 0.6159 - precision: 0.6159 - recall: 0.6159 - val_loss: 0.7156 - val_accuracy: 0.5486 - val_precision: 0.5486 - val_recall: 0.5486\n",
      "Epoch 1995/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6133 - precision: 0.6133 - recall: 0.6133 - val_loss: 0.7223 - val_accuracy: 0.5329 - val_precision: 0.5329 - val_recall: 0.5329\n",
      "Epoch 1996/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6177 - precision: 0.6177 - recall: 0.6177 - val_loss: 0.7453 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1997/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6150 - precision: 0.6150 - recall: 0.6150 - val_loss: 0.7035 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1998/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6445 - accuracy: 0.6186 - precision: 0.6186 - recall: 0.6186 - val_loss: 0.7225 - val_accuracy: 0.5172 - val_precision: 0.5172 - val_recall: 0.5172\n",
      "Epoch 1999/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.6097 - precision: 0.6097 - recall: 0.6097 - val_loss: 0.7423 - val_accuracy: 0.4890 - val_precision: 0.4890 - val_recall: 0.4890\n",
      "Epoch 2000/2000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.6327 - precision: 0.6327 - recall: 0.6327 - val_loss: 0.7331 - val_accuracy: 0.5204 - val_precision: 0.5204 - val_recall: 0.5204\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epochs = 2000\n",
    "n_random_search = 1\n",
    "\n",
    "batch_size = [16]\n",
    "n_layers = [1] \n",
    "cnn_dropout_p = [None, 0.2, 0.5]\n",
    "dense_dropout_p = [None, 0.2, 0.5]\n",
    "activation = ['tanh']\n",
    "n_dense_layers = [1]\n",
    "n_dense_neurons = [100]\n",
    "batch_normalization = [True]\n",
    "optimizer = [Adam(learning_rate=0.005, clipvalue=0.5)]\n",
    "#optimizer = [SGD(0.001)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, cnn_dropout_p, dense_dropout_p, activation, n_dense_layers, n_dense_neurons, batch_normalization, batch_size, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'tcn', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([508, 622]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([113, 206]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([80, 80]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 2, 'batch_size': 32, 'lstm_neurons': 500, 'n_dense_neurons': 1000, 'dropout': None, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7efd0cd56bd0>}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 31, 500)             1018000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, 500)                 2002000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 1000)                501000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, 2)                   2002      \n",
      "=================================================================\n",
      "Total params: 3,523,002\n",
      "Trainable params: 3,523,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "35/35 [==============================] - 15s 366ms/step - loss: 0.8825 - accuracy: 0.5384 - precision_1: 0.5384 - recall_1: 0.5384 - val_loss: 0.6895 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 12s 334ms/step - loss: 0.6920 - accuracy: 0.5223 - precision_1: 0.5223 - recall_1: 0.5223 - val_loss: 0.6872 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 11s 326ms/step - loss: 0.6891 - accuracy: 0.5518 - precision_1: 0.5518 - recall_1: 0.5518 - val_loss: 0.6861 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 11s 328ms/step - loss: 0.6886 - accuracy: 0.5491 - precision_1: 0.5491 - recall_1: 0.5491 - val_loss: 0.6852 - val_accuracy: 0.5536 - val_precision_1: 0.5536 - val_recall_1: 0.5536\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 12s 340ms/step - loss: 0.6920 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6878 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 12s 342ms/step - loss: 0.6859 - accuracy: 0.5500 - precision_1: 0.5500 - recall_1: 0.5500 - val_loss: 0.6799 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 11s 303ms/step - loss: 0.6887 - accuracy: 0.5420 - precision_1: 0.5420 - recall_1: 0.5420 - val_loss: 0.6863 - val_accuracy: 0.5527 - val_precision_1: 0.5527 - val_recall_1: 0.5527\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 10s 293ms/step - loss: 0.6943 - accuracy: 0.5562 - precision_1: 0.5562 - recall_1: 0.5562 - val_loss: 0.6869 - val_accuracy: 0.5616 - val_precision_1: 0.5616 - val_recall_1: 0.5616\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 10s 292ms/step - loss: 0.6885 - accuracy: 0.5402 - precision_1: 0.5402 - recall_1: 0.5402 - val_loss: 0.6789 - val_accuracy: 0.5670 - val_precision_1: 0.5670 - val_recall_1: 0.5670\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 10s 298ms/step - loss: 0.6859 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6802 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 11s 308ms/step - loss: 0.6861 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6693 - val_accuracy: 0.5804 - val_precision_1: 0.5804 - val_recall_1: 0.5804\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 11s 302ms/step - loss: 0.6808 - accuracy: 0.5607 - precision_1: 0.5607 - recall_1: 0.5607 - val_loss: 0.6824 - val_accuracy: 0.5589 - val_precision_1: 0.5589 - val_recall_1: 0.5589\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 10s 294ms/step - loss: 0.6851 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6770 - val_accuracy: 0.5598 - val_precision_1: 0.5598 - val_recall_1: 0.5598\n",
      "Epoch 14/500\n",
      "16/35 [============>.................] - ETA: 4s - loss: 0.6842 - accuracy: 0.5586 - precision_1: 0.5586 - recall_1: 0.5586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-191f5e051644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n\u001b[0;32m---> 17\u001b[0;31m                            model_randomgs_params, 'lstm', flush=True, save_plot=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_gs_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreproducible_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36mperform_gs_training\u001b[0;34m(self, model_fn, checkpoint_filepath)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                                           \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                                                           checkpoint_callback],\n\u001b[0;32m--> 247\u001b[0;31m                                              epochs=self.max_epochs, verbose=1)\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 500\n",
    "n_random_search = 1\n",
    "\n",
    "n_layers = [2]\n",
    "batch_size = [32]\n",
    "lstm_neurons = [100, 500, 1000]\n",
    "n_dense_neurons = [100, 500, 1000]\n",
    "dropout = [None, 0.2, 0.5, 0.8]\n",
    "optimizer = [Adam(learning_rate=0.01, clipvalue=0.5)]\n",
    "#optimizer = [SGD(learning_rate=0.01)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, batch_size, lstm_neurons, n_dense_neurons, dropout, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'lstm', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
