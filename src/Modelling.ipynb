{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "INTERM_DIR = '../compiled_data'\n",
    "TRAIN_DATA_PATH = os.path.join(INTERM_DIR, 'train_data.pkl')\n",
    "MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_tcn, build_lstm\n",
    "\n",
    "class PerformTraining:\n",
    "    \n",
    "    \"\"\"\n",
    "    This class performs the training of the desired model\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    seed : int\n",
    "        the integer of the seed utilised for reproducibility \n",
    "    TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "    INTERM_DATA_DIR : str\n",
    "        a string indicating the directory containing intermediate computed data\n",
    "    MODEL_DIR : str\n",
    "        a string indicating the directory containing created models\n",
    "    model_gs_params : dict\n",
    "        a dictionary of preprocessing parameters\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    reproducible_results()\n",
    "        Sets seed and ensures all deterministic operations are reproducible\n",
    "    retrieve_data()\n",
    "        Retrieves the data given the data directory and folders\n",
    "    prepare_data(preprocessing_params, tuning=True):\n",
    "        Combines the preprocessing methods and splits the data for training \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "        INTERM_DATA_DIR : str\n",
    "            a string indicating the directory containing intermediate computed data\n",
    "        MODEL_DIR : str\n",
    "            a string indicating the directory containing created models\n",
    "        model_gs_params : list of lists\n",
    "            a list of lists containing the parameters for model training\n",
    "        \"\"\"\n",
    "\n",
    "        self.seed = 7\n",
    "\n",
    "        self.TRAIN_DATA_PATH = TRAIN_DATA_PATH\n",
    "        self.INTERM_DATA_DIR = INTERM_DATA_DIR\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.model_gs_params = model_gs_params\n",
    "        self.max_epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.flush = flush\n",
    "        self.save_plot = save_plot\n",
    "        \n",
    "        with open(TRAIN_DATA_PATH, 'rb') as f:\n",
    "            self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = pkl.load(f)\n",
    "            \n",
    "        # random shuffle dataset\n",
    "        p = np.random.permutation(len(self.X_train))\n",
    "        self.X_train, self.y_train = self.X_train[p], self.y_train[p]\n",
    "            \n",
    "        print(f\"The class distributions in the training set are: {np.unique(self.y_train, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the validation set are: {np.unique(self.y_val, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the test set are: {np.unique(self.y_test, return_counts=True)}\")\n",
    "\n",
    "        self.y_train, self.y_val, self.y_test = keras.utils.to_categorical(self.y_train), keras.utils.to_categorical(self.y_val), keras.utils.to_categorical(self.y_test)\n",
    "        \n",
    "        self.reproducible_results()\n",
    "#         self.X_train, self.X_val, self.X_test = self.X_train[:,:,:12], self.X_val[:,:,:12], self.X_test[:,:,:12]\n",
    "#         sample_mean = np.mean(self.X_train, axis=0)\n",
    "#         sample_std = np.mean(self.X_train, axis=0)\n",
    "#         self.X_train = (self.X_train - sample_mean) / sample_std\n",
    "#         self.X_val = (self.X_val - sample_mean) / sample_std\n",
    "#         self.X_test = (self.X_test - sample_mean) / sample_std\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "            self.perform_gs_training(build_tcn, os.path.join(self.MODEL_DIR, 'tcn'))\n",
    "            \n",
    "        if self.model_type == 'lstm':\n",
    "            self.perform_gs_training(build_lstm, os.path.join(self.MODEL_DIR, 'lstm'))\n",
    "\n",
    "    def reproducible_results(self):\n",
    "\n",
    "        \"\"\"Obtain reproducible results with keras, source: https://stackoverflow.com/a/52897216\"\"\"\n",
    "\n",
    "        # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "\n",
    "        # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "        tf.compat.v1.set_random_seed(self.seed)\n",
    "\n",
    "        # 5. Configure a new global `tensorflow` session\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "        K.set_session(sess)\n",
    "\n",
    "    def plot_confusion_matrix(self, confusion_matrix, title, save_plot_dir):\n",
    "        \"\"\"Plots a given confusion matrix and saves it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion_matrix : ndarray\n",
    "            a numpy array of the confusion matrix\n",
    "        title : str\n",
    "            a string of the title name\n",
    "        save_plot_dir : str\n",
    "            a string of where to save the plot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (ndarray, ndarray)\n",
    "            a tuple of the numpy arrays of the upsampled feature and label arrays\n",
    "        \"\"\"  \n",
    "        # Plot confusion matrix\n",
    "        labels = np.unique(self.y_train)\n",
    "        df_cm = pd.DataFrame(confusion_matrix, index = [i for i in np.unique(self.y_train)], columns = [i for i in np.unique(self.y_train)])\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title(title, ha=\"center\")\n",
    "        plt.xticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        plt.yticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        if save_plot_dir is not None: \n",
    "            plt.savefig(f'{save_plot_dir}.pdf', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def model_param_setup(self, params):\n",
    "        \"\"\"Retrieve from a given ordered list the correct parameters depending on model type\"\"\"\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'cnn_dropout_p' : params[1], \n",
    "                            'dense_dropout_p' : params[2], \n",
    "                            'activation' : params[3], \n",
    "                            'n_dense_layers' : params[4], \n",
    "                            'n_dense_neurons' : params[5], \n",
    "                            'batch_normalization' : params[6], \n",
    "                            'batch_size' : params[7],\n",
    "                            'optimizer' : params[8]}\n",
    "\n",
    "        if self.model_type == 'lstm':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'batch_size' : params[1],\n",
    "                            'lstm_neurons' : params[2], \n",
    "                            'n_dense_neurons' : params[3], \n",
    "                            'dropout' : params[4], \n",
    "                            'optimizer' : params[5]}\n",
    "\n",
    "        return model_params    \n",
    "    \n",
    "    \n",
    "    def perform_gs_training(self, model_fn, checkpoint_filepath):\n",
    "\n",
    "        \"\"\"Performs cross-validated grid search training for selected model function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_fn : function\n",
    "            a function which creates a keras compiled model\n",
    "        checkpoint_filepath : str\n",
    "            a string indicating where to save the plots and grid search results \n",
    "            of the cross-validated grid search\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            a pandas dataframe containing the results of the grid search, \n",
    "            specifically average performance for given hyperparameters\n",
    "        \"\"\"  \n",
    "\n",
    "        pkl_name = os.path.join(checkpoint_filepath, 'gs_res.pkl')\n",
    "        if os.path.isfile(pkl_name) and self.flush==False:\n",
    "            with open(pkl_name, 'rb') as f:\n",
    "                gs_res = pkl.load(f)\n",
    "        else: \n",
    "            gs_res = []\n",
    "\n",
    "        for idx, params in enumerate(self.model_gs_params): \n",
    "\n",
    "            print(\"=================================================\")\n",
    "            print(\"Presenting Results for: %s/%s Hyperparameter Combination\" % (idx+1, len(self.model_gs_params)))\n",
    "\n",
    "            model_params = self.model_param_setup(params)\n",
    "            print(model_params)\n",
    "\n",
    "            batch_size = model_params['batch_size']\n",
    "\n",
    "            # Create backlog for accuracy in each fold\n",
    "            val_fold_accuracy = []\n",
    "            test_fold_accuracy = []\n",
    "\n",
    "            try:     \n",
    "\n",
    "                # Prepare the training dataset\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "                # Prepare the validation dataset\n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((self.X_val, self.y_val))\n",
    "                val_dataset = val_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "                \n",
    "                if self.model_type == 'lstm':\n",
    "                    # In stateful lstm, need to have full batches, i.e. a dataset size divisible by batch_size\n",
    "                    rem_last_n_train = (self.X_train.shape[0] % batch_size)\n",
    "                    if rem_last_n_train > 0:\n",
    "                        self.X_train, self.y_train = self.X_train[:-rem_last_n_train], self.y_train[:-rem_last_n_train]\n",
    "\n",
    "                    rem_last_n_val = (self.X_val.shape[0] % batch_size)\n",
    "                    if rem_last_n_val > 0:\n",
    "                        self.X_val, self.y_val = self.X_val[:-rem_last_n_val], self.y_val[:-rem_last_n_val]\n",
    "                    \n",
    "                    rem_last_n_test = (self.X_test.shape[0] % batch_size)\n",
    "                    if rem_last_n_test > 0:\n",
    "                        self.X_test, self.y_test = self.X_test[:-rem_last_n_test], self.y_test[:-rem_last_n_test]\n",
    "                    \n",
    "                model = model_fn(self.X_train, **model_params)\n",
    "\n",
    "                # Create Tensorboard\n",
    "                logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch', profile_batch=0)\n",
    "                # Model Checkpoint Callback\n",
    "                checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_filepath,'checkpoint'), save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "                # Early Stopping Callback\n",
    "                early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 50)\n",
    "\n",
    "                # Train the model\n",
    "                training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_val, self.y_val),\n",
    "                                             steps_per_epoch = self.X_train.shape[0] // batch_size if self.model_type == 'lstm' else None, \n",
    "                                             callbacks = [tensorboard_callback,\n",
    "                                                          early_stopping_callback,\n",
    "                                                          checkpoint_callback],\n",
    "                                             epochs=self.max_epochs, verbose=1)\n",
    "                \n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "            try: \n",
    "\n",
    "                # Compute confusion matrix across validation folds, and the test set\n",
    "                def compute_confusion_matrix(set_to_predict, true_values, model):\n",
    "                    y_predicted = model.predict(set_to_predict)\n",
    "                    class_pred = np.argmax(y_predicted,axis = 1)\n",
    "                    class_true = np.argmax(true_values,axis = 1)\n",
    "                    res = metrics.confusion_matrix(class_true, class_pred)\n",
    "                    perc_acc = res / res.sum(axis=0)\n",
    "                    return perc_acc\n",
    "\n",
    "                test_accuracy = compute_confusion_matrix(self.X_test, self.y_test, model)\n",
    "                val_accuracy = compute_confusion_matrix(self.X_val, self.y_val, model)\n",
    "                \n",
    "                if self.save_plot == True: \n",
    "                    string_model_params = model_params\n",
    "                    del string_model_params['optimizer']\n",
    "                    string_model_params['learning_rate'] = K.eval(model.optimizer.lr)\n",
    "\n",
    "                    string_model_params = [str(x) for x in [*string_model_params.values()]]\n",
    "                    save_plot_dir = os.path.join(checkpoint_filepath, 'plots')\n",
    "                    save_plot_val_dir = os.path.join(save_plot_dir, 'Val CM ' + ' '.join(string_model_params))\n",
    "                    save_plot_test_dir = os.path.join(save_plot_dir, 'Test CM ' + ' '.join(string_model_params))\n",
    "                else: \n",
    "                    save_plot_val_dir = None\n",
    "                    save_plot_test_dir = None\n",
    "\n",
    "                self.plot_confusion_matrix(test_accuracy, 'Validation Dataset Accuracy', save_plot_val_dir)    \n",
    "                self.plot_confusion_matrix(val_accuracy, 'Test Validation Dataset Accuracy', save_plot_test_dir)    \n",
    "\n",
    "                curr_gs_res = [model_params, self.model_type, test_accuracy.diagonal(), val_accuracy.diagonal()]\n",
    "                gs_res.append(curr_gs_res)\n",
    "                with open(pkl_name, 'wb') as f:\n",
    "                    pkl.dump(gs_res, f)\n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "        return gs_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([510, 620]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([112, 207]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([81, 79]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 1, 'cnn_dropout_p': 0.2, 'dense_dropout_p': None, 'activation': 'tanh', 'n_dense_layers': 2, 'n_dense_neurons': 100, 'batch_normalization': True, 'batch_size': 128, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7fd55055fb50>}\n",
      "Epoch 1/2000\n",
      "9/9 [==============================] - 1s 38ms/step - loss: 0.7072 - accuracy: 0.5204 - precision_3: 0.5204 - recall_3: 0.5204 - val_loss: 0.6856 - val_accuracy: 0.5522 - val_precision_3: 0.5522 - val_recall_3: 0.5522\n",
      "Epoch 2/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5381 - precision_3: 0.5381 - recall_3: 0.5381 - val_loss: 0.6846 - val_accuracy: 0.5575 - val_precision_3: 0.5575 - val_recall_3: 0.5575\n",
      "Epoch 3/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5398 - precision_3: 0.5398 - recall_3: 0.5398 - val_loss: 0.6853 - val_accuracy: 0.5451 - val_precision_3: 0.5451 - val_recall_3: 0.5451\n",
      "Epoch 4/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5469 - precision_3: 0.5469 - recall_3: 0.5469 - val_loss: 0.6860 - val_accuracy: 0.5487 - val_precision_3: 0.5487 - val_recall_3: 0.5487\n",
      "Epoch 5/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5381 - precision_3: 0.5381 - recall_3: 0.5381 - val_loss: 0.6840 - val_accuracy: 0.5522 - val_precision_3: 0.5522 - val_recall_3: 0.5522\n",
      "Epoch 6/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5504 - precision_3: 0.5504 - recall_3: 0.5504 - val_loss: 0.6812 - val_accuracy: 0.5602 - val_precision_3: 0.5602 - val_recall_3: 0.5602\n",
      "Epoch 7/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6807 - accuracy: 0.5628 - precision_3: 0.5628 - recall_3: 0.5628 - val_loss: 0.6811 - val_accuracy: 0.5699 - val_precision_3: 0.5699 - val_recall_3: 0.5699\n",
      "Epoch 8/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.5558 - precision_3: 0.5558 - recall_3: 0.5558 - val_loss: 0.6796 - val_accuracy: 0.5602 - val_precision_3: 0.5602 - val_recall_3: 0.5602\n",
      "Epoch 9/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.5611 - precision_3: 0.5611 - recall_3: 0.5611 - val_loss: 0.6791 - val_accuracy: 0.5593 - val_precision_3: 0.5593 - val_recall_3: 0.5593\n",
      "Epoch 10/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.5681 - precision_3: 0.5681 - recall_3: 0.5681 - val_loss: 0.6785 - val_accuracy: 0.5664 - val_precision_3: 0.5664 - val_recall_3: 0.5664\n",
      "Epoch 11/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6801 - accuracy: 0.5558 - precision_3: 0.5558 - recall_3: 0.5558 - val_loss: 0.6765 - val_accuracy: 0.5584 - val_precision_3: 0.5584 - val_recall_3: 0.5584\n",
      "Epoch 12/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.5381 - precision_3: 0.5381 - recall_3: 0.5381 - val_loss: 0.6769 - val_accuracy: 0.5637 - val_precision_3: 0.5637 - val_recall_3: 0.5637\n",
      "Epoch 13/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6729 - accuracy: 0.5735 - precision_3: 0.5735 - recall_3: 0.5735 - val_loss: 0.6755 - val_accuracy: 0.5690 - val_precision_3: 0.5690 - val_recall_3: 0.5690\n",
      "Epoch 14/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6773 - accuracy: 0.5673 - precision_3: 0.5673 - recall_3: 0.5673 - val_loss: 0.6733 - val_accuracy: 0.5770 - val_precision_3: 0.5770 - val_recall_3: 0.5770\n",
      "Epoch 15/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5611 - precision_3: 0.5611 - recall_3: 0.5611 - val_loss: 0.6726 - val_accuracy: 0.5726 - val_precision_3: 0.5726 - val_recall_3: 0.5726\n",
      "Epoch 16/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6744 - accuracy: 0.5796 - precision_3: 0.5796 - recall_3: 0.5796 - val_loss: 0.6720 - val_accuracy: 0.5912 - val_precision_3: 0.5912 - val_recall_3: 0.5912\n",
      "Epoch 17/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.5832 - precision_3: 0.5832 - recall_3: 0.5832 - val_loss: 0.6667 - val_accuracy: 0.5876 - val_precision_3: 0.5876 - val_recall_3: 0.5876\n",
      "Epoch 18/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.5779 - precision_3: 0.5779 - recall_3: 0.5779 - val_loss: 0.6662 - val_accuracy: 0.5885 - val_precision_3: 0.5885 - val_recall_3: 0.5885\n",
      "Epoch 19/2000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6755 - accuracy: 0.5717 - precision_3: 0.5717 - recall_3: 0.5717 - val_loss: 0.6677 - val_accuracy: 0.5805 - val_precision_3: 0.5805 - val_recall_3: 0.5805\n",
      "Epoch 20/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.5708 - precision_3: 0.5708 - recall_3: 0.5708 - val_loss: 0.6668 - val_accuracy: 0.5947 - val_precision_3: 0.5947 - val_recall_3: 0.5947\n",
      "Epoch 21/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.5805 - precision_3: 0.5805 - recall_3: 0.5805 - val_loss: 0.6656 - val_accuracy: 0.5956 - val_precision_3: 0.5956 - val_recall_3: 0.5956\n",
      "Epoch 22/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.5628 - precision_3: 0.5628 - recall_3: 0.5628 - val_loss: 0.6632 - val_accuracy: 0.5903 - val_precision_3: 0.5903 - val_recall_3: 0.5903\n",
      "Epoch 23/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6735 - accuracy: 0.5735 - precision_3: 0.5735 - recall_3: 0.5735 - val_loss: 0.6639 - val_accuracy: 0.6044 - val_precision_3: 0.6044 - val_recall_3: 0.6044\n",
      "Epoch 24/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.5699 - precision_3: 0.5699 - recall_3: 0.5699 - val_loss: 0.6600 - val_accuracy: 0.5973 - val_precision_3: 0.5973 - val_recall_3: 0.5973\n",
      "Epoch 25/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6619 - accuracy: 0.6044 - precision_3: 0.6044 - recall_3: 0.6044 - val_loss: 0.6551 - val_accuracy: 0.6097 - val_precision_3: 0.6097 - val_recall_3: 0.6097\n",
      "Epoch 26/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6615 - accuracy: 0.6035 - precision_3: 0.6035 - recall_3: 0.6035 - val_loss: 0.6523 - val_accuracy: 0.6133 - val_precision_3: 0.6133 - val_recall_3: 0.6133\n",
      "Epoch 27/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.5770 - precision_3: 0.5770 - recall_3: 0.5770 - val_loss: 0.6560 - val_accuracy: 0.6177 - val_precision_3: 0.6177 - val_recall_3: 0.6177\n",
      "Epoch 28/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.5956 - precision_3: 0.5956 - recall_3: 0.5956 - val_loss: 0.6599 - val_accuracy: 0.6053 - val_precision_3: 0.6053 - val_recall_3: 0.6053\n",
      "Epoch 29/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6668 - accuracy: 0.5956 - precision_3: 0.5956 - recall_3: 0.5956 - val_loss: 0.6544 - val_accuracy: 0.6027 - val_precision_3: 0.6027 - val_recall_3: 0.6027\n",
      "Epoch 30/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.5850 - precision_3: 0.5850 - recall_3: 0.5850 - val_loss: 0.6504 - val_accuracy: 0.6248 - val_precision_3: 0.6248 - val_recall_3: 0.6248\n",
      "Epoch 31/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6569 - accuracy: 0.5991 - precision_3: 0.5991 - recall_3: 0.5991 - val_loss: 0.6454 - val_accuracy: 0.6177 - val_precision_3: 0.6177 - val_recall_3: 0.6177\n",
      "Epoch 32/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6632 - accuracy: 0.6088 - precision_3: 0.6088 - recall_3: 0.6088 - val_loss: 0.6501 - val_accuracy: 0.6186 - val_precision_3: 0.6186 - val_recall_3: 0.6186\n",
      "Epoch 33/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6612 - accuracy: 0.6044 - precision_3: 0.6044 - recall_3: 0.6044 - val_loss: 0.6501 - val_accuracy: 0.6265 - val_precision_3: 0.6265 - val_recall_3: 0.6265\n",
      "Epoch 34/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.5982 - precision_3: 0.5982 - recall_3: 0.5982 - val_loss: 0.6466 - val_accuracy: 0.6274 - val_precision_3: 0.6274 - val_recall_3: 0.6274\n",
      "Epoch 35/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6568 - accuracy: 0.6159 - precision_3: 0.6159 - recall_3: 0.6159 - val_loss: 0.6429 - val_accuracy: 0.6301 - val_precision_3: 0.6301 - val_recall_3: 0.6301\n",
      "Epoch 36/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6625 - accuracy: 0.5894 - precision_3: 0.5894 - recall_3: 0.5894 - val_loss: 0.6404 - val_accuracy: 0.6292 - val_precision_3: 0.6292 - val_recall_3: 0.6292\n",
      "Epoch 37/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6461 - accuracy: 0.6274 - precision_3: 0.6274 - recall_3: 0.6274 - val_loss: 0.6377 - val_accuracy: 0.6248 - val_precision_3: 0.6248 - val_recall_3: 0.6248\n",
      "Epoch 38/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6562 - accuracy: 0.6097 - precision_3: 0.6097 - recall_3: 0.6097 - val_loss: 0.6364 - val_accuracy: 0.6381 - val_precision_3: 0.6381 - val_recall_3: 0.6381\n",
      "Epoch 39/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6591 - accuracy: 0.6044 - precision_3: 0.6044 - recall_3: 0.6044 - val_loss: 0.6405 - val_accuracy: 0.6283 - val_precision_3: 0.6283 - val_recall_3: 0.6283\n",
      "Epoch 40/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6573 - accuracy: 0.6062 - precision_3: 0.6062 - recall_3: 0.6062 - val_loss: 0.6375 - val_accuracy: 0.6230 - val_precision_3: 0.6230 - val_recall_3: 0.6230\n",
      "Epoch 41/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6587 - accuracy: 0.6080 - precision_3: 0.6080 - recall_3: 0.6080 - val_loss: 0.6335 - val_accuracy: 0.6319 - val_precision_3: 0.6319 - val_recall_3: 0.6319\n",
      "Epoch 42/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6511 - accuracy: 0.6142 - precision_3: 0.6142 - recall_3: 0.6142 - val_loss: 0.6320 - val_accuracy: 0.6389 - val_precision_3: 0.6389 - val_recall_3: 0.6389\n",
      "Epoch 43/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6573 - accuracy: 0.6044 - precision_3: 0.6044 - recall_3: 0.6044 - val_loss: 0.6319 - val_accuracy: 0.6354 - val_precision_3: 0.6354 - val_recall_3: 0.6354\n",
      "Epoch 44/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6601 - accuracy: 0.6106 - precision_3: 0.6106 - recall_3: 0.6106 - val_loss: 0.6379 - val_accuracy: 0.6345 - val_precision_3: 0.6345 - val_recall_3: 0.6345\n",
      "Epoch 45/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.6159 - precision_3: 0.6159 - recall_3: 0.6159 - val_loss: 0.6385 - val_accuracy: 0.6363 - val_precision_3: 0.6363 - val_recall_3: 0.6363\n",
      "Epoch 46/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.6097 - precision_3: 0.6097 - recall_3: 0.6097 - val_loss: 0.6417 - val_accuracy: 0.6168 - val_precision_3: 0.6168 - val_recall_3: 0.6168\n",
      "Epoch 47/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.5991 - precision_3: 0.5991 - recall_3: 0.5991 - val_loss: 0.6406 - val_accuracy: 0.6469 - val_precision_3: 0.6469 - val_recall_3: 0.6469\n",
      "Epoch 48/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.6088 - precision_3: 0.6088 - recall_3: 0.6088 - val_loss: 0.6320 - val_accuracy: 0.6425 - val_precision_3: 0.6425 - val_recall_3: 0.6425\n",
      "Epoch 49/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6455 - accuracy: 0.6186 - precision_3: 0.6186 - recall_3: 0.6186 - val_loss: 0.6267 - val_accuracy: 0.6425 - val_precision_3: 0.6425 - val_recall_3: 0.6425\n",
      "Epoch 50/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6549 - accuracy: 0.6133 - precision_3: 0.6133 - recall_3: 0.6133 - val_loss: 0.6302 - val_accuracy: 0.6389 - val_precision_3: 0.6389 - val_recall_3: 0.6389\n",
      "Epoch 51/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.6018 - precision_3: 0.6018 - recall_3: 0.6018 - val_loss: 0.6302 - val_accuracy: 0.6487 - val_precision_3: 0.6487 - val_recall_3: 0.6487\n",
      "Epoch 52/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6512 - accuracy: 0.6080 - precision_3: 0.6080 - recall_3: 0.6080 - val_loss: 0.6239 - val_accuracy: 0.6566 - val_precision_3: 0.6566 - val_recall_3: 0.6566\n",
      "Epoch 53/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6450 - accuracy: 0.6212 - precision_3: 0.6212 - recall_3: 0.6212 - val_loss: 0.6230 - val_accuracy: 0.6460 - val_precision_3: 0.6460 - val_recall_3: 0.6460\n",
      "Epoch 54/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.6204 - precision_3: 0.6204 - recall_3: 0.6204 - val_loss: 0.6300 - val_accuracy: 0.6354 - val_precision_3: 0.6354 - val_recall_3: 0.6354\n",
      "Epoch 55/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.6301 - precision_3: 0.6301 - recall_3: 0.6301 - val_loss: 0.6203 - val_accuracy: 0.6637 - val_precision_3: 0.6637 - val_recall_3: 0.6637\n",
      "Epoch 56/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6361 - accuracy: 0.6265 - precision_3: 0.6265 - recall_3: 0.6265 - val_loss: 0.6188 - val_accuracy: 0.6664 - val_precision_3: 0.6664 - val_recall_3: 0.6664\n",
      "Epoch 57/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6592 - accuracy: 0.5947 - precision_3: 0.5947 - recall_3: 0.5947 - val_loss: 0.6197 - val_accuracy: 0.6558 - val_precision_3: 0.6558 - val_recall_3: 0.6558\n",
      "Epoch 58/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.6142 - precision_3: 0.6142 - recall_3: 0.6142 - val_loss: 0.6248 - val_accuracy: 0.6549 - val_precision_3: 0.6549 - val_recall_3: 0.6549\n",
      "Epoch 59/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.6354 - precision_3: 0.6354 - recall_3: 0.6354 - val_loss: 0.6155 - val_accuracy: 0.6602 - val_precision_3: 0.6602 - val_recall_3: 0.6602\n",
      "Epoch 60/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6434 - accuracy: 0.6283 - precision_3: 0.6283 - recall_3: 0.6283 - val_loss: 0.6124 - val_accuracy: 0.6664 - val_precision_3: 0.6664 - val_recall_3: 0.6664\n",
      "Epoch 61/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6410 - accuracy: 0.6221 - precision_3: 0.6221 - recall_3: 0.6221 - val_loss: 0.6162 - val_accuracy: 0.6664 - val_precision_3: 0.6664 - val_recall_3: 0.6664\n",
      "Epoch 62/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.6274 - precision_3: 0.6274 - recall_3: 0.6274 - val_loss: 0.6215 - val_accuracy: 0.6549 - val_precision_3: 0.6549 - val_recall_3: 0.6549\n",
      "Epoch 63/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6489 - accuracy: 0.6150 - precision_3: 0.6150 - recall_3: 0.6150 - val_loss: 0.6121 - val_accuracy: 0.6796 - val_precision_3: 0.6796 - val_recall_3: 0.6796\n",
      "Epoch 64/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.6106 - precision_3: 0.6106 - recall_3: 0.6106 - val_loss: 0.6092 - val_accuracy: 0.6823 - val_precision_3: 0.6823 - val_recall_3: 0.6823\n",
      "Epoch 65/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6429 - accuracy: 0.6248 - precision_3: 0.6248 - recall_3: 0.6248 - val_loss: 0.6095 - val_accuracy: 0.6708 - val_precision_3: 0.6708 - val_recall_3: 0.6708\n",
      "Epoch 66/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6451 - accuracy: 0.6195 - precision_3: 0.6195 - recall_3: 0.6195 - val_loss: 0.6205 - val_accuracy: 0.6726 - val_precision_3: 0.6726 - val_recall_3: 0.6726\n",
      "Epoch 67/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6283 - precision_3: 0.6283 - recall_3: 0.6283 - val_loss: 0.6091 - val_accuracy: 0.6832 - val_precision_3: 0.6832 - val_recall_3: 0.6832\n",
      "Epoch 68/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.6478 - precision_3: 0.6478 - recall_3: 0.6478 - val_loss: 0.6076 - val_accuracy: 0.6770 - val_precision_3: 0.6770 - val_recall_3: 0.6770\n",
      "Epoch 69/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6470 - accuracy: 0.6124 - precision_3: 0.6124 - recall_3: 0.6124 - val_loss: 0.6100 - val_accuracy: 0.6513 - val_precision_3: 0.6513 - val_recall_3: 0.6513\n",
      "Epoch 70/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6522 - accuracy: 0.6150 - precision_3: 0.6150 - recall_3: 0.6150 - val_loss: 0.6045 - val_accuracy: 0.6929 - val_precision_3: 0.6929 - val_recall_3: 0.6929\n",
      "Epoch 71/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.6389 - precision_3: 0.6389 - recall_3: 0.6389 - val_loss: 0.5975 - val_accuracy: 0.6885 - val_precision_3: 0.6885 - val_recall_3: 0.6885\n",
      "Epoch 72/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6449 - accuracy: 0.6018 - precision_3: 0.6018 - recall_3: 0.6018 - val_loss: 0.5982 - val_accuracy: 0.6796 - val_precision_3: 0.6796 - val_recall_3: 0.6796\n",
      "Epoch 73/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.6469 - precision_3: 0.6469 - recall_3: 0.6469 - val_loss: 0.5969 - val_accuracy: 0.6885 - val_precision_3: 0.6885 - val_recall_3: 0.6885\n",
      "Epoch 74/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6310 - accuracy: 0.6327 - precision_3: 0.6327 - recall_3: 0.6327 - val_loss: 0.5886 - val_accuracy: 0.7097 - val_precision_3: 0.7097 - val_recall_3: 0.7097\n",
      "Epoch 75/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6310 - accuracy: 0.6460 - precision_3: 0.6460 - recall_3: 0.6460 - val_loss: 0.5917 - val_accuracy: 0.6965 - val_precision_3: 0.6965 - val_recall_3: 0.6965\n",
      "Epoch 76/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6439 - accuracy: 0.6336 - precision_3: 0.6336 - recall_3: 0.6336 - val_loss: 0.5899 - val_accuracy: 0.6956 - val_precision_3: 0.6956 - val_recall_3: 0.6956\n",
      "Epoch 77/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6260 - accuracy: 0.6336 - precision_3: 0.6336 - recall_3: 0.6336 - val_loss: 0.5857 - val_accuracy: 0.6894 - val_precision_3: 0.6894 - val_recall_3: 0.6894\n",
      "Epoch 78/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6349 - accuracy: 0.6336 - precision_3: 0.6336 - recall_3: 0.6336 - val_loss: 0.5824 - val_accuracy: 0.7062 - val_precision_3: 0.7062 - val_recall_3: 0.7062\n",
      "Epoch 79/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6174 - accuracy: 0.6681 - precision_3: 0.6681 - recall_3: 0.6681 - val_loss: 0.5903 - val_accuracy: 0.6885 - val_precision_3: 0.6885 - val_recall_3: 0.6885\n",
      "Epoch 80/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.6212 - precision_3: 0.6212 - recall_3: 0.6212 - val_loss: 0.5831 - val_accuracy: 0.7035 - val_precision_3: 0.7035 - val_recall_3: 0.7035\n",
      "Epoch 81/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6540 - precision_3: 0.6540 - recall_3: 0.6540 - val_loss: 0.5861 - val_accuracy: 0.6929 - val_precision_3: 0.6929 - val_recall_3: 0.6929\n",
      "Epoch 82/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.6478 - precision_3: 0.6478 - recall_3: 0.6478 - val_loss: 0.5795 - val_accuracy: 0.7088 - val_precision_3: 0.7088 - val_recall_3: 0.7088\n",
      "Epoch 83/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.6442 - precision_3: 0.6442 - recall_3: 0.6442 - val_loss: 0.5790 - val_accuracy: 0.7124 - val_precision_3: 0.7124 - val_recall_3: 0.7124\n",
      "Epoch 84/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.6451 - precision_3: 0.6451 - recall_3: 0.6451 - val_loss: 0.5697 - val_accuracy: 0.7195 - val_precision_3: 0.7195 - val_recall_3: 0.7195\n",
      "Epoch 85/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.6504 - precision_3: 0.6504 - recall_3: 0.6504 - val_loss: 0.5807 - val_accuracy: 0.6965 - val_precision_3: 0.6965 - val_recall_3: 0.6965\n",
      "Epoch 86/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6301 - accuracy: 0.6407 - precision_3: 0.6407 - recall_3: 0.6407 - val_loss: 0.5723 - val_accuracy: 0.7115 - val_precision_3: 0.7115 - val_recall_3: 0.7115\n",
      "Epoch 87/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6575 - precision_3: 0.6575 - recall_3: 0.6575 - val_loss: 0.5751 - val_accuracy: 0.7115 - val_precision_3: 0.7115 - val_recall_3: 0.7115\n",
      "Epoch 88/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.6416 - precision_3: 0.6416 - recall_3: 0.6416 - val_loss: 0.5835 - val_accuracy: 0.6920 - val_precision_3: 0.6920 - val_recall_3: 0.6920\n",
      "Epoch 89/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6407 - precision_3: 0.6407 - recall_3: 0.6407 - val_loss: 0.5756 - val_accuracy: 0.7018 - val_precision_3: 0.7018 - val_recall_3: 0.7018\n",
      "Epoch 90/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6291 - accuracy: 0.6531 - precision_3: 0.6531 - recall_3: 0.6531 - val_loss: 0.5709 - val_accuracy: 0.7159 - val_precision_3: 0.7159 - val_recall_3: 0.7159\n",
      "Epoch 91/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.6611 - precision_3: 0.6611 - recall_3: 0.6611 - val_loss: 0.5667 - val_accuracy: 0.7124 - val_precision_3: 0.7124 - val_recall_3: 0.7124\n",
      "Epoch 92/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.6566 - precision_3: 0.6566 - recall_3: 0.6566 - val_loss: 0.5712 - val_accuracy: 0.7186 - val_precision_3: 0.7186 - val_recall_3: 0.7186\n",
      "Epoch 93/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6191 - accuracy: 0.6593 - precision_3: 0.6593 - recall_3: 0.6593 - val_loss: 0.5647 - val_accuracy: 0.7097 - val_precision_3: 0.7097 - val_recall_3: 0.7097\n",
      "Epoch 94/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6171 - accuracy: 0.6796 - precision_3: 0.6796 - recall_3: 0.6796 - val_loss: 0.5576 - val_accuracy: 0.7221 - val_precision_3: 0.7221 - val_recall_3: 0.7221\n",
      "Epoch 95/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.6496 - precision_3: 0.6496 - recall_3: 0.6496 - val_loss: 0.5646 - val_accuracy: 0.7009 - val_precision_3: 0.7009 - val_recall_3: 0.7009\n",
      "Epoch 96/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.6522 - precision_3: 0.6522 - recall_3: 0.6522 - val_loss: 0.5728 - val_accuracy: 0.7080 - val_precision_3: 0.7080 - val_recall_3: 0.7080\n",
      "Epoch 97/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6690 - precision_3: 0.6690 - recall_3: 0.6690 - val_loss: 0.5655 - val_accuracy: 0.7239 - val_precision_3: 0.7239 - val_recall_3: 0.7239\n",
      "Epoch 98/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.6584 - precision_3: 0.6584 - recall_3: 0.6584 - val_loss: 0.5688 - val_accuracy: 0.7106 - val_precision_3: 0.7106 - val_recall_3: 0.7106\n",
      "Epoch 99/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6300 - accuracy: 0.6558 - precision_3: 0.6558 - recall_3: 0.6558 - val_loss: 0.5732 - val_accuracy: 0.7009 - val_precision_3: 0.7009 - val_recall_3: 0.7009\n",
      "Epoch 100/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.6575 - precision_3: 0.6575 - recall_3: 0.6575 - val_loss: 0.5641 - val_accuracy: 0.7221 - val_precision_3: 0.7221 - val_recall_3: 0.7221\n",
      "Epoch 101/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6211 - accuracy: 0.6407 - precision_3: 0.6407 - recall_3: 0.6407 - val_loss: 0.5654 - val_accuracy: 0.7080 - val_precision_3: 0.7080 - val_recall_3: 0.7080\n",
      "Epoch 102/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.6531 - precision_3: 0.6531 - recall_3: 0.6531 - val_loss: 0.5569 - val_accuracy: 0.7310 - val_precision_3: 0.7310 - val_recall_3: 0.7310\n",
      "Epoch 103/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.6593 - precision_3: 0.6593 - recall_3: 0.6593 - val_loss: 0.5570 - val_accuracy: 0.7292 - val_precision_3: 0.7292 - val_recall_3: 0.7292\n",
      "Epoch 104/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.6673 - precision_3: 0.6673 - recall_3: 0.6673 - val_loss: 0.5644 - val_accuracy: 0.7115 - val_precision_3: 0.7115 - val_recall_3: 0.7115\n",
      "Epoch 105/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6184 - accuracy: 0.6451 - precision_3: 0.6451 - recall_3: 0.6451 - val_loss: 0.5543 - val_accuracy: 0.7283 - val_precision_3: 0.7283 - val_recall_3: 0.7283\n",
      "Epoch 106/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.6770 - precision_3: 0.6770 - recall_3: 0.6770 - val_loss: 0.5472 - val_accuracy: 0.7239 - val_precision_3: 0.7239 - val_recall_3: 0.7239\n",
      "Epoch 107/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.6743 - precision_3: 0.6743 - recall_3: 0.6743 - val_loss: 0.5478 - val_accuracy: 0.7310 - val_precision_3: 0.7310 - val_recall_3: 0.7310\n",
      "Epoch 108/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.6779 - precision_3: 0.6779 - recall_3: 0.6779 - val_loss: 0.5534 - val_accuracy: 0.7142 - val_precision_3: 0.7142 - val_recall_3: 0.7142\n",
      "Epoch 109/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.6823 - precision_3: 0.6823 - recall_3: 0.6823 - val_loss: 0.5448 - val_accuracy: 0.7292 - val_precision_3: 0.7292 - val_recall_3: 0.7292\n",
      "Epoch 110/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6169 - accuracy: 0.6584 - precision_3: 0.6584 - recall_3: 0.6584 - val_loss: 0.5501 - val_accuracy: 0.7310 - val_precision_3: 0.7310 - val_recall_3: 0.7310\n",
      "Epoch 111/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6163 - accuracy: 0.6690 - precision_3: 0.6690 - recall_3: 0.6690 - val_loss: 0.5522 - val_accuracy: 0.7425 - val_precision_3: 0.7425 - val_recall_3: 0.7425\n",
      "Epoch 112/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.6558 - precision_3: 0.6558 - recall_3: 0.6558 - val_loss: 0.5532 - val_accuracy: 0.7336 - val_precision_3: 0.7336 - val_recall_3: 0.7336\n",
      "Epoch 113/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6038 - accuracy: 0.6850 - precision_3: 0.6850 - recall_3: 0.6850 - val_loss: 0.5494 - val_accuracy: 0.7425 - val_precision_3: 0.7425 - val_recall_3: 0.7425\n",
      "Epoch 114/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6779 - precision_3: 0.6779 - recall_3: 0.6779 - val_loss: 0.5400 - val_accuracy: 0.7354 - val_precision_3: 0.7354 - val_recall_3: 0.7354\n",
      "Epoch 115/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6075 - accuracy: 0.6513 - precision_3: 0.6513 - recall_3: 0.6513 - val_loss: 0.5382 - val_accuracy: 0.7416 - val_precision_3: 0.7416 - val_recall_3: 0.7416\n",
      "Epoch 116/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6175 - accuracy: 0.6540 - precision_3: 0.6540 - recall_3: 0.6540 - val_loss: 0.5408 - val_accuracy: 0.7531 - val_precision_3: 0.7531 - val_recall_3: 0.7531\n",
      "Epoch 117/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.6708 - precision_3: 0.6708 - recall_3: 0.6708 - val_loss: 0.5341 - val_accuracy: 0.7372 - val_precision_3: 0.7372 - val_recall_3: 0.7372\n",
      "Epoch 118/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6050 - accuracy: 0.6770 - precision_3: 0.6770 - recall_3: 0.6770 - val_loss: 0.5417 - val_accuracy: 0.7398 - val_precision_3: 0.7398 - val_recall_3: 0.7398\n",
      "Epoch 119/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6025 - accuracy: 0.6690 - precision_3: 0.6690 - recall_3: 0.6690 - val_loss: 0.5483 - val_accuracy: 0.7310 - val_precision_3: 0.7310 - val_recall_3: 0.7310\n",
      "Epoch 120/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.6540 - precision_3: 0.6540 - recall_3: 0.6540 - val_loss: 0.5415 - val_accuracy: 0.7336 - val_precision_3: 0.7336 - val_recall_3: 0.7336\n",
      "Epoch 121/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6244 - accuracy: 0.6531 - precision_3: 0.6531 - recall_3: 0.6531 - val_loss: 0.5506 - val_accuracy: 0.7354 - val_precision_3: 0.7354 - val_recall_3: 0.7354\n",
      "Epoch 122/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6003 - accuracy: 0.6770 - precision_3: 0.6770 - recall_3: 0.6770 - val_loss: 0.5330 - val_accuracy: 0.7407 - val_precision_3: 0.7407 - val_recall_3: 0.7407\n",
      "Epoch 123/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5946 - accuracy: 0.6814 - precision_3: 0.6814 - recall_3: 0.6814 - val_loss: 0.5290 - val_accuracy: 0.7549 - val_precision_3: 0.7549 - val_recall_3: 0.7549\n",
      "Epoch 124/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.6903 - precision_3: 0.6903 - recall_3: 0.6903 - val_loss: 0.5238 - val_accuracy: 0.7407 - val_precision_3: 0.7407 - val_recall_3: 0.7407\n",
      "Epoch 125/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.6788 - precision_3: 0.6788 - recall_3: 0.6788 - val_loss: 0.5274 - val_accuracy: 0.7469 - val_precision_3: 0.7469 - val_recall_3: 0.7469\n",
      "Epoch 126/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6673 - precision_3: 0.6673 - recall_3: 0.6673 - val_loss: 0.5367 - val_accuracy: 0.7460 - val_precision_3: 0.7460 - val_recall_3: 0.7460\n",
      "Epoch 127/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.6646 - precision_3: 0.6646 - recall_3: 0.6646 - val_loss: 0.5374 - val_accuracy: 0.7451 - val_precision_3: 0.7451 - val_recall_3: 0.7451\n",
      "Epoch 128/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.6708 - precision_3: 0.6708 - recall_3: 0.6708 - val_loss: 0.5354 - val_accuracy: 0.7345 - val_precision_3: 0.7345 - val_recall_3: 0.7345\n",
      "Epoch 129/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6033 - accuracy: 0.6593 - precision_3: 0.6593 - recall_3: 0.6593 - val_loss: 0.5396 - val_accuracy: 0.7496 - val_precision_3: 0.7496 - val_recall_3: 0.7496\n",
      "Epoch 130/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5951 - accuracy: 0.6743 - precision_3: 0.6743 - recall_3: 0.6743 - val_loss: 0.5495 - val_accuracy: 0.7221 - val_precision_3: 0.7221 - val_recall_3: 0.7221\n",
      "Epoch 131/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.6699 - precision_3: 0.6699 - recall_3: 0.6699 - val_loss: 0.5242 - val_accuracy: 0.7442 - val_precision_3: 0.7442 - val_recall_3: 0.7442\n",
      "Epoch 132/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6007 - accuracy: 0.6637 - precision_3: 0.6637 - recall_3: 0.6637 - val_loss: 0.5255 - val_accuracy: 0.7487 - val_precision_3: 0.7487 - val_recall_3: 0.7487\n",
      "Epoch 133/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6814 - precision_3: 0.6814 - recall_3: 0.6814 - val_loss: 0.5191 - val_accuracy: 0.7628 - val_precision_3: 0.7628 - val_recall_3: 0.7628\n",
      "Epoch 134/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5963 - accuracy: 0.6690 - precision_3: 0.6690 - recall_3: 0.6690 - val_loss: 0.5243 - val_accuracy: 0.7416 - val_precision_3: 0.7416 - val_recall_3: 0.7416\n",
      "Epoch 135/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.6841 - precision_3: 0.6841 - recall_3: 0.6841 - val_loss: 0.5252 - val_accuracy: 0.7513 - val_precision_3: 0.7513 - val_recall_3: 0.7513\n",
      "Epoch 136/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5958 - accuracy: 0.6752 - precision_3: 0.6752 - recall_3: 0.6752 - val_loss: 0.5116 - val_accuracy: 0.7575 - val_precision_3: 0.7575 - val_recall_3: 0.7575\n",
      "Epoch 137/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.6637 - precision_3: 0.6637 - recall_3: 0.6637 - val_loss: 0.5141 - val_accuracy: 0.7664 - val_precision_3: 0.7664 - val_recall_3: 0.7664\n",
      "Epoch 138/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.6779 - precision_3: 0.6779 - recall_3: 0.6779 - val_loss: 0.5173 - val_accuracy: 0.7531 - val_precision_3: 0.7531 - val_recall_3: 0.7531\n",
      "Epoch 139/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5860 - accuracy: 0.6761 - precision_3: 0.6761 - recall_3: 0.6761 - val_loss: 0.5116 - val_accuracy: 0.7637 - val_precision_3: 0.7637 - val_recall_3: 0.7637\n",
      "Epoch 140/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6145 - accuracy: 0.6602 - precision_3: 0.6602 - recall_3: 0.6602 - val_loss: 0.5249 - val_accuracy: 0.7513 - val_precision_3: 0.7513 - val_recall_3: 0.7513\n",
      "Epoch 141/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.6814 - precision_3: 0.6814 - recall_3: 0.6814 - val_loss: 0.5195 - val_accuracy: 0.7664 - val_precision_3: 0.7664 - val_recall_3: 0.7664\n",
      "Epoch 142/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.6947 - precision_3: 0.6947 - recall_3: 0.6947 - val_loss: 0.5090 - val_accuracy: 0.7681 - val_precision_3: 0.7681 - val_recall_3: 0.7681\n",
      "Epoch 143/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.6832 - precision_3: 0.6832 - recall_3: 0.6832 - val_loss: 0.5089 - val_accuracy: 0.7566 - val_precision_3: 0.7566 - val_recall_3: 0.7566\n",
      "Epoch 144/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6929 - precision_3: 0.6929 - recall_3: 0.6929 - val_loss: 0.4998 - val_accuracy: 0.7841 - val_precision_3: 0.7841 - val_recall_3: 0.7841\n",
      "Epoch 145/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.6496 - precision_3: 0.6496 - recall_3: 0.6496 - val_loss: 0.5120 - val_accuracy: 0.7717 - val_precision_3: 0.7717 - val_recall_3: 0.7717\n",
      "Epoch 146/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5905 - accuracy: 0.6761 - precision_3: 0.6761 - recall_3: 0.6761 - val_loss: 0.5088 - val_accuracy: 0.7752 - val_precision_3: 0.7752 - val_recall_3: 0.7752\n",
      "Epoch 147/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5897 - accuracy: 0.6788 - precision_3: 0.6788 - recall_3: 0.6788 - val_loss: 0.5142 - val_accuracy: 0.7522 - val_precision_3: 0.7522 - val_recall_3: 0.7522\n",
      "Epoch 148/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5928 - accuracy: 0.6832 - precision_3: 0.6832 - recall_3: 0.6832 - val_loss: 0.5030 - val_accuracy: 0.7673 - val_precision_3: 0.7673 - val_recall_3: 0.7673\n",
      "Epoch 149/2000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.6805 - precision_3: 0.6805 - recall_3: 0.6805 - val_loss: 0.4983 - val_accuracy: 0.7743 - val_precision_3: 0.7743 - val_recall_3: 0.7743\n",
      "Epoch 150/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6681 - precision_3: 0.6681 - recall_3: 0.6681 - val_loss: 0.5065 - val_accuracy: 0.7611 - val_precision_3: 0.7611 - val_recall_3: 0.7611\n",
      "Epoch 151/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.6779 - precision_3: 0.6779 - recall_3: 0.6779 - val_loss: 0.5021 - val_accuracy: 0.7717 - val_precision_3: 0.7717 - val_recall_3: 0.7717\n",
      "Epoch 152/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.6947 - precision_3: 0.6947 - recall_3: 0.6947 - val_loss: 0.5177 - val_accuracy: 0.7460 - val_precision_3: 0.7460 - val_recall_3: 0.7460\n",
      "Epoch 153/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5906 - accuracy: 0.6894 - precision_3: 0.6894 - recall_3: 0.6894 - val_loss: 0.4921 - val_accuracy: 0.7779 - val_precision_3: 0.7779 - val_recall_3: 0.7779\n",
      "Epoch 154/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.7062 - precision_3: 0.7062 - recall_3: 0.7062 - val_loss: 0.5019 - val_accuracy: 0.7823 - val_precision_3: 0.7823 - val_recall_3: 0.7823\n",
      "Epoch 155/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5883 - accuracy: 0.6947 - precision_3: 0.6947 - recall_3: 0.6947 - val_loss: 0.4987 - val_accuracy: 0.7584 - val_precision_3: 0.7584 - val_recall_3: 0.7584\n",
      "Epoch 156/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5814 - accuracy: 0.6841 - precision_3: 0.6841 - recall_3: 0.6841 - val_loss: 0.4875 - val_accuracy: 0.7903 - val_precision_3: 0.7903 - val_recall_3: 0.7903\n",
      "Epoch 157/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6012 - accuracy: 0.6770 - precision_3: 0.6770 - recall_3: 0.6770 - val_loss: 0.5014 - val_accuracy: 0.7823 - val_precision_3: 0.7823 - val_recall_3: 0.7823\n",
      "Epoch 158/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5855 - accuracy: 0.6938 - precision_3: 0.6938 - recall_3: 0.6938 - val_loss: 0.5003 - val_accuracy: 0.7814 - val_precision_3: 0.7814 - val_recall_3: 0.7814\n",
      "Epoch 159/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5953 - accuracy: 0.6867 - precision_3: 0.6867 - recall_3: 0.6867 - val_loss: 0.4946 - val_accuracy: 0.7788 - val_precision_3: 0.7788 - val_recall_3: 0.7788\n",
      "Epoch 160/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5916 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4983 - val_accuracy: 0.7841 - val_precision_3: 0.7841 - val_recall_3: 0.7841\n",
      "Epoch 161/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5909 - accuracy: 0.6761 - precision_3: 0.6761 - recall_3: 0.6761 - val_loss: 0.4978 - val_accuracy: 0.7788 - val_precision_3: 0.7788 - val_recall_3: 0.7788\n",
      "Epoch 162/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.7027 - precision_3: 0.7027 - recall_3: 0.7027 - val_loss: 0.5050 - val_accuracy: 0.7566 - val_precision_3: 0.7566 - val_recall_3: 0.7566\n",
      "Epoch 163/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5999 - accuracy: 0.6867 - precision_3: 0.6867 - recall_3: 0.6867 - val_loss: 0.5018 - val_accuracy: 0.7894 - val_precision_3: 0.7894 - val_recall_3: 0.7894\n",
      "Epoch 164/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.6673 - precision_3: 0.6673 - recall_3: 0.6673 - val_loss: 0.5178 - val_accuracy: 0.7655 - val_precision_3: 0.7655 - val_recall_3: 0.7655\n",
      "Epoch 165/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5863 - accuracy: 0.6885 - precision_3: 0.6885 - recall_3: 0.6885 - val_loss: 0.5069 - val_accuracy: 0.7743 - val_precision_3: 0.7743 - val_recall_3: 0.7743\n",
      "Epoch 166/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.6814 - precision_3: 0.6814 - recall_3: 0.6814 - val_loss: 0.4955 - val_accuracy: 0.7735 - val_precision_3: 0.7735 - val_recall_3: 0.7735\n",
      "Epoch 167/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5866 - accuracy: 0.6743 - precision_3: 0.6743 - recall_3: 0.6743 - val_loss: 0.4887 - val_accuracy: 0.7885 - val_precision_3: 0.7885 - val_recall_3: 0.7885\n",
      "Epoch 168/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5820 - accuracy: 0.6920 - precision_3: 0.6920 - recall_3: 0.6920 - val_loss: 0.4880 - val_accuracy: 0.7903 - val_precision_3: 0.7903 - val_recall_3: 0.7903\n",
      "Epoch 169/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5825 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4893 - val_accuracy: 0.7752 - val_precision_3: 0.7752 - val_recall_3: 0.7752\n",
      "Epoch 170/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5927 - accuracy: 0.6805 - precision_3: 0.6805 - recall_3: 0.6805 - val_loss: 0.4804 - val_accuracy: 0.8018 - val_precision_3: 0.8018 - val_recall_3: 0.8018\n",
      "Epoch 171/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.7133 - precision_3: 0.7133 - recall_3: 0.7133 - val_loss: 0.4839 - val_accuracy: 0.7690 - val_precision_3: 0.7690 - val_recall_3: 0.7690\n",
      "Epoch 172/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.7071 - precision_3: 0.7071 - recall_3: 0.7071 - val_loss: 0.4854 - val_accuracy: 0.7903 - val_precision_3: 0.7903 - val_recall_3: 0.7903\n",
      "Epoch 173/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.6929 - precision_3: 0.6929 - recall_3: 0.6929 - val_loss: 0.4982 - val_accuracy: 0.7770 - val_precision_3: 0.7770 - val_recall_3: 0.7770\n",
      "Epoch 174/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5752 - accuracy: 0.6920 - precision_3: 0.6920 - recall_3: 0.6920 - val_loss: 0.4940 - val_accuracy: 0.7850 - val_precision_3: 0.7850 - val_recall_3: 0.7850\n",
      "Epoch 175/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5937 - accuracy: 0.6850 - precision_3: 0.6850 - recall_3: 0.6850 - val_loss: 0.4780 - val_accuracy: 0.7912 - val_precision_3: 0.7912 - val_recall_3: 0.7912\n",
      "Epoch 176/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7257 - precision_3: 0.7257 - recall_3: 0.7257 - val_loss: 0.4701 - val_accuracy: 0.7973 - val_precision_3: 0.7973 - val_recall_3: 0.7973\n",
      "Epoch 177/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6805 - precision_3: 0.6805 - recall_3: 0.6805 - val_loss: 0.4845 - val_accuracy: 0.7805 - val_precision_3: 0.7805 - val_recall_3: 0.7805\n",
      "Epoch 178/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.7204 - precision_3: 0.7204 - recall_3: 0.7204 - val_loss: 0.4990 - val_accuracy: 0.7841 - val_precision_3: 0.7841 - val_recall_3: 0.7841\n",
      "Epoch 179/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4822 - val_accuracy: 0.7867 - val_precision_3: 0.7867 - val_recall_3: 0.7867\n",
      "Epoch 180/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.6973 - precision_3: 0.6973 - recall_3: 0.6973 - val_loss: 0.5078 - val_accuracy: 0.7584 - val_precision_3: 0.7584 - val_recall_3: 0.7584\n",
      "Epoch 181/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5716 - accuracy: 0.6956 - precision_3: 0.6956 - recall_3: 0.6956 - val_loss: 0.4824 - val_accuracy: 0.7823 - val_precision_3: 0.7823 - val_recall_3: 0.7823\n",
      "Epoch 182/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5839 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4806 - val_accuracy: 0.7796 - val_precision_3: 0.7796 - val_recall_3: 0.7796\n",
      "Epoch 183/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.6903 - precision_3: 0.6903 - recall_3: 0.6903 - val_loss: 0.4828 - val_accuracy: 0.7947 - val_precision_3: 0.7947 - val_recall_3: 0.7947\n",
      "Epoch 184/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5597 - accuracy: 0.7018 - precision_3: 0.7018 - recall_3: 0.7018 - val_loss: 0.4770 - val_accuracy: 0.7912 - val_precision_3: 0.7912 - val_recall_3: 0.7912\n",
      "Epoch 185/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5819 - accuracy: 0.6894 - precision_3: 0.6894 - recall_3: 0.6894 - val_loss: 0.4606 - val_accuracy: 0.8053 - val_precision_3: 0.8053 - val_recall_3: 0.8053\n",
      "Epoch 186/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.6779 - precision_3: 0.6779 - recall_3: 0.6779 - val_loss: 0.4611 - val_accuracy: 0.7991 - val_precision_3: 0.7991 - val_recall_3: 0.7991\n",
      "Epoch 187/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5718 - accuracy: 0.6982 - precision_3: 0.6982 - recall_3: 0.6982 - val_loss: 0.4571 - val_accuracy: 0.8106 - val_precision_3: 0.8106 - val_recall_3: 0.8106\n",
      "Epoch 188/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5816 - accuracy: 0.6885 - precision_3: 0.6885 - recall_3: 0.6885 - val_loss: 0.4787 - val_accuracy: 0.7735 - val_precision_3: 0.7735 - val_recall_3: 0.7735\n",
      "Epoch 189/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5910 - accuracy: 0.7035 - precision_3: 0.7035 - recall_3: 0.7035 - val_loss: 0.4556 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 190/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.6770 - precision_3: 0.6770 - recall_3: 0.6770 - val_loss: 0.4637 - val_accuracy: 0.8000 - val_precision_3: 0.8000 - val_recall_3: 0.8000\n",
      "Epoch 191/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7257 - precision_3: 0.7257 - recall_3: 0.7257 - val_loss: 0.4715 - val_accuracy: 0.7938 - val_precision_3: 0.7938 - val_recall_3: 0.7938\n",
      "Epoch 192/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7204 - precision_3: 0.7204 - recall_3: 0.7204 - val_loss: 0.4731 - val_accuracy: 0.7841 - val_precision_3: 0.7841 - val_recall_3: 0.7841\n",
      "Epoch 193/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.6885 - precision_3: 0.6885 - recall_3: 0.6885 - val_loss: 0.4716 - val_accuracy: 0.7876 - val_precision_3: 0.7876 - val_recall_3: 0.7876\n",
      "Epoch 194/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.6982 - precision_3: 0.6982 - recall_3: 0.6982 - val_loss: 0.4556 - val_accuracy: 0.8088 - val_precision_3: 0.8088 - val_recall_3: 0.8088\n",
      "Epoch 195/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5804 - accuracy: 0.7000 - precision_3: 0.7000 - recall_3: 0.7000 - val_loss: 0.4662 - val_accuracy: 0.7947 - val_precision_3: 0.7947 - val_recall_3: 0.7947\n",
      "Epoch 196/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.6841 - precision_3: 0.6841 - recall_3: 0.6841 - val_loss: 0.4620 - val_accuracy: 0.8088 - val_precision_3: 0.8088 - val_recall_3: 0.8088\n",
      "Epoch 197/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.6947 - precision_3: 0.6947 - recall_3: 0.6947 - val_loss: 0.4718 - val_accuracy: 0.7876 - val_precision_3: 0.7876 - val_recall_3: 0.7876\n",
      "Epoch 198/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.6982 - precision_3: 0.6982 - recall_3: 0.6982 - val_loss: 0.4755 - val_accuracy: 0.8009 - val_precision_3: 0.8009 - val_recall_3: 0.8009\n",
      "Epoch 199/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4625 - val_accuracy: 0.8053 - val_precision_3: 0.8053 - val_recall_3: 0.8053\n",
      "Epoch 200/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7186 - precision_3: 0.7186 - recall_3: 0.7186 - val_loss: 0.4524 - val_accuracy: 0.8239 - val_precision_3: 0.8239 - val_recall_3: 0.8239\n",
      "Epoch 201/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7080 - precision_3: 0.7080 - recall_3: 0.7080 - val_loss: 0.4606 - val_accuracy: 0.8071 - val_precision_3: 0.8071 - val_recall_3: 0.8071\n",
      "Epoch 202/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.7133 - precision_3: 0.7133 - recall_3: 0.7133 - val_loss: 0.4842 - val_accuracy: 0.7681 - val_precision_3: 0.7681 - val_recall_3: 0.7681\n",
      "Epoch 203/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.6903 - precision_3: 0.6903 - recall_3: 0.6903 - val_loss: 0.4637 - val_accuracy: 0.7965 - val_precision_3: 0.7965 - val_recall_3: 0.7965\n",
      "Epoch 204/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.6938 - precision_3: 0.6938 - recall_3: 0.6938 - val_loss: 0.4498 - val_accuracy: 0.8133 - val_precision_3: 0.8133 - val_recall_3: 0.8133\n",
      "Epoch 205/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.7035 - precision_3: 0.7035 - recall_3: 0.7035 - val_loss: 0.4659 - val_accuracy: 0.7973 - val_precision_3: 0.7973 - val_recall_3: 0.7973\n",
      "Epoch 206/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5691 - accuracy: 0.6973 - precision_3: 0.6973 - recall_3: 0.6973 - val_loss: 0.4489 - val_accuracy: 0.8035 - val_precision_3: 0.8035 - val_recall_3: 0.8035\n",
      "Epoch 207/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7133 - precision_3: 0.7133 - recall_3: 0.7133 - val_loss: 0.4480 - val_accuracy: 0.8204 - val_precision_3: 0.8204 - val_recall_3: 0.8204\n",
      "Epoch 208/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7150 - precision_3: 0.7150 - recall_3: 0.7150 - val_loss: 0.4553 - val_accuracy: 0.8115 - val_precision_3: 0.8115 - val_recall_3: 0.8115\n",
      "Epoch 209/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5516 - accuracy: 0.7124 - precision_3: 0.7124 - recall_3: 0.7124 - val_loss: 0.4418 - val_accuracy: 0.8097 - val_precision_3: 0.8097 - val_recall_3: 0.8097\n",
      "Epoch 210/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7062 - precision_3: 0.7062 - recall_3: 0.7062 - val_loss: 0.4374 - val_accuracy: 0.8097 - val_precision_3: 0.8097 - val_recall_3: 0.8097\n",
      "Epoch 211/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.6761 - precision_3: 0.6761 - recall_3: 0.6761 - val_loss: 0.4597 - val_accuracy: 0.7938 - val_precision_3: 0.7938 - val_recall_3: 0.7938\n",
      "Epoch 212/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7168 - precision_3: 0.7168 - recall_3: 0.7168 - val_loss: 0.4364 - val_accuracy: 0.8265 - val_precision_3: 0.8265 - val_recall_3: 0.8265\n",
      "Epoch 213/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7133 - precision_3: 0.7133 - recall_3: 0.7133 - val_loss: 0.4397 - val_accuracy: 0.8274 - val_precision_3: 0.8274 - val_recall_3: 0.8274\n",
      "Epoch 214/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7221 - precision_3: 0.7221 - recall_3: 0.7221 - val_loss: 0.4356 - val_accuracy: 0.8265 - val_precision_3: 0.8265 - val_recall_3: 0.8265\n",
      "Epoch 215/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.7124 - precision_3: 0.7124 - recall_3: 0.7124 - val_loss: 0.4314 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 216/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7186 - precision_3: 0.7186 - recall_3: 0.7186 - val_loss: 0.4512 - val_accuracy: 0.8062 - val_precision_3: 0.8062 - val_recall_3: 0.8062\n",
      "Epoch 217/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.7071 - precision_3: 0.7071 - recall_3: 0.7071 - val_loss: 0.4525 - val_accuracy: 0.8195 - val_precision_3: 0.8195 - val_recall_3: 0.8195\n",
      "Epoch 218/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5638 - accuracy: 0.7009 - precision_3: 0.7009 - recall_3: 0.7009 - val_loss: 0.4435 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 219/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5570 - accuracy: 0.7221 - precision_3: 0.7221 - recall_3: 0.7221 - val_loss: 0.4502 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 220/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7265 - precision_3: 0.7265 - recall_3: 0.7265 - val_loss: 0.4441 - val_accuracy: 0.8142 - val_precision_3: 0.8142 - val_recall_3: 0.8142\n",
      "Epoch 221/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7035 - precision_3: 0.7035 - recall_3: 0.7035 - val_loss: 0.4403 - val_accuracy: 0.8274 - val_precision_3: 0.8274 - val_recall_3: 0.8274\n",
      "Epoch 222/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5801 - accuracy: 0.7062 - precision_3: 0.7062 - recall_3: 0.7062 - val_loss: 0.4412 - val_accuracy: 0.8274 - val_precision_3: 0.8274 - val_recall_3: 0.8274\n",
      "Epoch 223/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5753 - accuracy: 0.7000 - precision_3: 0.7000 - recall_3: 0.7000 - val_loss: 0.4484 - val_accuracy: 0.8150 - val_precision_3: 0.8150 - val_recall_3: 0.8150\n",
      "Epoch 224/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5573 - accuracy: 0.7204 - precision_3: 0.7204 - recall_3: 0.7204 - val_loss: 0.4500 - val_accuracy: 0.8000 - val_precision_3: 0.8000 - val_recall_3: 0.8000\n",
      "Epoch 225/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7363 - precision_3: 0.7363 - recall_3: 0.7363 - val_loss: 0.4422 - val_accuracy: 0.8159 - val_precision_3: 0.8159 - val_recall_3: 0.8159\n",
      "Epoch 226/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7124 - precision_3: 0.7124 - recall_3: 0.7124 - val_loss: 0.4503 - val_accuracy: 0.8142 - val_precision_3: 0.8142 - val_recall_3: 0.8142\n",
      "Epoch 227/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7265 - precision_3: 0.7265 - recall_3: 0.7265 - val_loss: 0.4383 - val_accuracy: 0.8133 - val_precision_3: 0.8133 - val_recall_3: 0.8133\n",
      "Epoch 228/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5694 - accuracy: 0.6938 - precision_3: 0.6938 - recall_3: 0.6938 - val_loss: 0.4302 - val_accuracy: 0.8150 - val_precision_3: 0.8150 - val_recall_3: 0.8150\n",
      "Epoch 229/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7159 - precision_3: 0.7159 - recall_3: 0.7159 - val_loss: 0.4324 - val_accuracy: 0.8230 - val_precision_3: 0.8230 - val_recall_3: 0.8230\n",
      "Epoch 230/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5642 - accuracy: 0.7018 - precision_3: 0.7018 - recall_3: 0.7018 - val_loss: 0.4258 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 231/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7460 - precision_3: 0.7460 - recall_3: 0.7460 - val_loss: 0.4242 - val_accuracy: 0.8212 - val_precision_3: 0.8212 - val_recall_3: 0.8212\n",
      "Epoch 232/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5387 - accuracy: 0.7363 - precision_3: 0.7363 - recall_3: 0.7363 - val_loss: 0.4223 - val_accuracy: 0.8283 - val_precision_3: 0.8283 - val_recall_3: 0.8283\n",
      "Epoch 233/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5728 - accuracy: 0.7027 - precision_3: 0.7027 - recall_3: 0.7027 - val_loss: 0.4353 - val_accuracy: 0.8133 - val_precision_3: 0.8133 - val_recall_3: 0.8133\n",
      "Epoch 234/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.7027 - precision_3: 0.7027 - recall_3: 0.7027 - val_loss: 0.4332 - val_accuracy: 0.8195 - val_precision_3: 0.8195 - val_recall_3: 0.8195\n",
      "Epoch 235/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.6912 - precision_3: 0.6912 - recall_3: 0.6912 - val_loss: 0.4425 - val_accuracy: 0.8177 - val_precision_3: 0.8177 - val_recall_3: 0.8177\n",
      "Epoch 236/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5717 - accuracy: 0.6973 - precision_3: 0.6973 - recall_3: 0.6973 - val_loss: 0.4312 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 237/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5667 - accuracy: 0.6982 - precision_3: 0.6982 - recall_3: 0.6982 - val_loss: 0.4391 - val_accuracy: 0.8159 - val_precision_3: 0.8159 - val_recall_3: 0.8159\n",
      "Epoch 238/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7088 - precision_3: 0.7088 - recall_3: 0.7088 - val_loss: 0.4531 - val_accuracy: 0.8142 - val_precision_3: 0.8142 - val_recall_3: 0.8142\n",
      "Epoch 239/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5613 - accuracy: 0.7168 - precision_3: 0.7168 - recall_3: 0.7168 - val_loss: 0.4447 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 240/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.6973 - precision_3: 0.6973 - recall_3: 0.6973 - val_loss: 0.4814 - val_accuracy: 0.7752 - val_precision_3: 0.7752 - val_recall_3: 0.7752\n",
      "Epoch 241/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5633 - accuracy: 0.7080 - precision_3: 0.7080 - recall_3: 0.7080 - val_loss: 0.4563 - val_accuracy: 0.8080 - val_precision_3: 0.8080 - val_recall_3: 0.8080\n",
      "Epoch 242/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5687 - accuracy: 0.7018 - precision_3: 0.7018 - recall_3: 0.7018 - val_loss: 0.4376 - val_accuracy: 0.8106 - val_precision_3: 0.8106 - val_recall_3: 0.8106\n",
      "Epoch 243/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5691 - accuracy: 0.7062 - precision_3: 0.7062 - recall_3: 0.7062 - val_loss: 0.4268 - val_accuracy: 0.8274 - val_precision_3: 0.8274 - val_recall_3: 0.8274\n",
      "Epoch 244/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5526 - accuracy: 0.7186 - precision_3: 0.7186 - recall_3: 0.7186 - val_loss: 0.4411 - val_accuracy: 0.8035 - val_precision_3: 0.8035 - val_recall_3: 0.8035\n",
      "Epoch 245/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7195 - precision_3: 0.7195 - recall_3: 0.7195 - val_loss: 0.4325 - val_accuracy: 0.8124 - val_precision_3: 0.8124 - val_recall_3: 0.8124\n",
      "Epoch 246/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.7088 - precision_3: 0.7088 - recall_3: 0.7088 - val_loss: 0.4351 - val_accuracy: 0.8071 - val_precision_3: 0.8071 - val_recall_3: 0.8071\n",
      "Epoch 247/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7168 - precision_3: 0.7168 - recall_3: 0.7168 - val_loss: 0.4276 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 248/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5440 - accuracy: 0.7230 - precision_3: 0.7230 - recall_3: 0.7230 - val_loss: 0.4258 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 249/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5680 - accuracy: 0.6982 - precision_3: 0.6982 - recall_3: 0.6982 - val_loss: 0.4233 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 250/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.7204 - precision_3: 0.7204 - recall_3: 0.7204 - val_loss: 0.4247 - val_accuracy: 0.8283 - val_precision_3: 0.8283 - val_recall_3: 0.8283\n",
      "Epoch 251/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7319 - precision_3: 0.7319 - recall_3: 0.7319 - val_loss: 0.4286 - val_accuracy: 0.8071 - val_precision_3: 0.8071 - val_recall_3: 0.8071\n",
      "Epoch 252/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5542 - accuracy: 0.7018 - precision_3: 0.7018 - recall_3: 0.7018 - val_loss: 0.4210 - val_accuracy: 0.8363 - val_precision_3: 0.8363 - val_recall_3: 0.8363\n",
      "Epoch 253/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.7257 - precision_3: 0.7257 - recall_3: 0.7257 - val_loss: 0.4190 - val_accuracy: 0.8212 - val_precision_3: 0.8212 - val_recall_3: 0.8212\n",
      "Epoch 254/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5562 - accuracy: 0.7115 - precision_3: 0.7115 - recall_3: 0.7115 - val_loss: 0.4214 - val_accuracy: 0.8336 - val_precision_3: 0.8336 - val_recall_3: 0.8336\n",
      "Epoch 255/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7115 - precision_3: 0.7115 - recall_3: 0.7115 - val_loss: 0.4129 - val_accuracy: 0.8363 - val_precision_3: 0.8363 - val_recall_3: 0.8363\n",
      "Epoch 256/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7195 - precision_3: 0.7195 - recall_3: 0.7195 - val_loss: 0.4130 - val_accuracy: 0.8319 - val_precision_3: 0.8319 - val_recall_3: 0.8319\n",
      "Epoch 257/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7204 - precision_3: 0.7204 - recall_3: 0.7204 - val_loss: 0.4052 - val_accuracy: 0.8460 - val_precision_3: 0.8460 - val_recall_3: 0.8460\n",
      "Epoch 258/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7239 - precision_3: 0.7239 - recall_3: 0.7239 - val_loss: 0.4095 - val_accuracy: 0.8416 - val_precision_3: 0.8416 - val_recall_3: 0.8416\n",
      "Epoch 259/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5534 - accuracy: 0.7168 - precision_3: 0.7168 - recall_3: 0.7168 - val_loss: 0.4092 - val_accuracy: 0.8239 - val_precision_3: 0.8239 - val_recall_3: 0.8239\n",
      "Epoch 260/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5450 - accuracy: 0.7327 - precision_3: 0.7327 - recall_3: 0.7327 - val_loss: 0.3990 - val_accuracy: 0.8398 - val_precision_3: 0.8398 - val_recall_3: 0.8398\n",
      "Epoch 261/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5457 - accuracy: 0.7257 - precision_3: 0.7257 - recall_3: 0.7257 - val_loss: 0.4024 - val_accuracy: 0.8345 - val_precision_3: 0.8345 - val_recall_3: 0.8345\n",
      "Epoch 262/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5435 - accuracy: 0.7195 - precision_3: 0.7195 - recall_3: 0.7195 - val_loss: 0.4096 - val_accuracy: 0.8434 - val_precision_3: 0.8434 - val_recall_3: 0.8434\n",
      "Epoch 263/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7283 - precision_3: 0.7283 - recall_3: 0.7283 - val_loss: 0.4046 - val_accuracy: 0.8496 - val_precision_3: 0.8496 - val_recall_3: 0.8496\n",
      "Epoch 264/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5295 - accuracy: 0.7389 - precision_3: 0.7389 - recall_3: 0.7389 - val_loss: 0.4004 - val_accuracy: 0.8372 - val_precision_3: 0.8372 - val_recall_3: 0.8372\n",
      "Epoch 265/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5357 - accuracy: 0.7513 - precision_3: 0.7513 - recall_3: 0.7513 - val_loss: 0.3845 - val_accuracy: 0.8619 - val_precision_3: 0.8619 - val_recall_3: 0.8619\n",
      "Epoch 266/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5313 - accuracy: 0.7292 - precision_3: 0.7292 - recall_3: 0.7292 - val_loss: 0.3892 - val_accuracy: 0.8513 - val_precision_3: 0.8513 - val_recall_3: 0.8513\n",
      "Epoch 267/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7416 - precision_3: 0.7416 - recall_3: 0.7416 - val_loss: 0.4038 - val_accuracy: 0.8248 - val_precision_3: 0.8248 - val_recall_3: 0.8248\n",
      "Epoch 268/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5327 - accuracy: 0.7274 - precision_3: 0.7274 - recall_3: 0.7274 - val_loss: 0.3994 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 269/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7319 - precision_3: 0.7319 - recall_3: 0.7319 - val_loss: 0.3941 - val_accuracy: 0.8522 - val_precision_3: 0.8522 - val_recall_3: 0.8522\n",
      "Epoch 270/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7327 - precision_3: 0.7327 - recall_3: 0.7327 - val_loss: 0.4005 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 271/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7292 - precision_3: 0.7292 - recall_3: 0.7292 - val_loss: 0.3927 - val_accuracy: 0.8575 - val_precision_3: 0.8575 - val_recall_3: 0.8575\n",
      "Epoch 272/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5188 - accuracy: 0.7549 - precision_3: 0.7549 - recall_3: 0.7549 - val_loss: 0.3924 - val_accuracy: 0.8558 - val_precision_3: 0.8558 - val_recall_3: 0.8558\n",
      "Epoch 273/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7283 - precision_3: 0.7283 - recall_3: 0.7283 - val_loss: 0.3932 - val_accuracy: 0.8292 - val_precision_3: 0.8292 - val_recall_3: 0.8292\n",
      "Epoch 274/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7319 - precision_3: 0.7319 - recall_3: 0.7319 - val_loss: 0.3972 - val_accuracy: 0.8434 - val_precision_3: 0.8434 - val_recall_3: 0.8434\n",
      "Epoch 275/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5423 - accuracy: 0.7345 - precision_3: 0.7345 - recall_3: 0.7345 - val_loss: 0.4250 - val_accuracy: 0.8150 - val_precision_3: 0.8150 - val_recall_3: 0.8150\n",
      "Epoch 276/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7124 - precision_3: 0.7124 - recall_3: 0.7124 - val_loss: 0.4362 - val_accuracy: 0.8230 - val_precision_3: 0.8230 - val_recall_3: 0.8230\n",
      "Epoch 277/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5620 - accuracy: 0.7212 - precision_3: 0.7212 - recall_3: 0.7212 - val_loss: 0.4059 - val_accuracy: 0.8372 - val_precision_3: 0.8372 - val_recall_3: 0.8372\n",
      "Epoch 278/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5356 - accuracy: 0.7301 - precision_3: 0.7301 - recall_3: 0.7301 - val_loss: 0.4042 - val_accuracy: 0.8319 - val_precision_3: 0.8319 - val_recall_3: 0.8319\n",
      "Epoch 279/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7186 - precision_3: 0.7186 - recall_3: 0.7186 - val_loss: 0.4192 - val_accuracy: 0.8177 - val_precision_3: 0.8177 - val_recall_3: 0.8177\n",
      "Epoch 280/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5623 - accuracy: 0.7124 - precision_3: 0.7124 - recall_3: 0.7124 - val_loss: 0.3917 - val_accuracy: 0.8619 - val_precision_3: 0.8619 - val_recall_3: 0.8619\n",
      "Epoch 281/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5517 - accuracy: 0.7195 - precision_3: 0.7195 - recall_3: 0.7195 - val_loss: 0.4063 - val_accuracy: 0.8354 - val_precision_3: 0.8354 - val_recall_3: 0.8354\n",
      "Epoch 282/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7283 - precision_3: 0.7283 - recall_3: 0.7283 - val_loss: 0.3950 - val_accuracy: 0.8469 - val_precision_3: 0.8469 - val_recall_3: 0.8469\n",
      "Epoch 283/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5454 - accuracy: 0.7150 - precision_3: 0.7150 - recall_3: 0.7150 - val_loss: 0.4024 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 284/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5395 - accuracy: 0.7389 - precision_3: 0.7389 - recall_3: 0.7389 - val_loss: 0.4010 - val_accuracy: 0.8345 - val_precision_3: 0.8345 - val_recall_3: 0.8345\n",
      "Epoch 285/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7354 - precision_3: 0.7354 - recall_3: 0.7354 - val_loss: 0.4061 - val_accuracy: 0.8345 - val_precision_3: 0.8345 - val_recall_3: 0.8345\n",
      "Epoch 286/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5522 - accuracy: 0.7230 - precision_3: 0.7230 - recall_3: 0.7230 - val_loss: 0.4125 - val_accuracy: 0.8327 - val_precision_3: 0.8327 - val_recall_3: 0.8327\n",
      "Epoch 287/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7345 - precision_3: 0.7345 - recall_3: 0.7345 - val_loss: 0.4057 - val_accuracy: 0.8292 - val_precision_3: 0.8292 - val_recall_3: 0.8292\n",
      "Epoch 288/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7389 - precision_3: 0.7389 - recall_3: 0.7389 - val_loss: 0.3949 - val_accuracy: 0.8372 - val_precision_3: 0.8372 - val_recall_3: 0.8372\n",
      "Epoch 289/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7619 - precision_3: 0.7619 - recall_3: 0.7619 - val_loss: 0.4073 - val_accuracy: 0.8274 - val_precision_3: 0.8274 - val_recall_3: 0.8274\n",
      "Epoch 290/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5406 - accuracy: 0.7336 - precision_3: 0.7336 - recall_3: 0.7336 - val_loss: 0.3856 - val_accuracy: 0.8558 - val_precision_3: 0.8558 - val_recall_3: 0.8558\n",
      "Epoch 291/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.7230 - precision_3: 0.7230 - recall_3: 0.7230 - val_loss: 0.3953 - val_accuracy: 0.8442 - val_precision_3: 0.8442 - val_recall_3: 0.8442\n",
      "Epoch 292/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7212 - precision_3: 0.7212 - recall_3: 0.7212 - val_loss: 0.3855 - val_accuracy: 0.8566 - val_precision_3: 0.8566 - val_recall_3: 0.8566\n",
      "Epoch 293/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5366 - accuracy: 0.7336 - precision_3: 0.7336 - recall_3: 0.7336 - val_loss: 0.3997 - val_accuracy: 0.8336 - val_precision_3: 0.8336 - val_recall_3: 0.8336\n",
      "Epoch 294/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5588 - accuracy: 0.7018 - precision_3: 0.7018 - recall_3: 0.7018 - val_loss: 0.3909 - val_accuracy: 0.8442 - val_precision_3: 0.8442 - val_recall_3: 0.8442\n",
      "Epoch 295/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7372 - precision_3: 0.7372 - recall_3: 0.7372 - val_loss: 0.4003 - val_accuracy: 0.8434 - val_precision_3: 0.8434 - val_recall_3: 0.8434\n",
      "Epoch 296/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.7292 - precision_3: 0.7292 - recall_3: 0.7292 - val_loss: 0.3781 - val_accuracy: 0.8566 - val_precision_3: 0.8566 - val_recall_3: 0.8566\n",
      "Epoch 297/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7265 - precision_3: 0.7265 - recall_3: 0.7265 - val_loss: 0.3754 - val_accuracy: 0.8593 - val_precision_3: 0.8593 - val_recall_3: 0.8593\n",
      "Epoch 298/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7354 - precision_3: 0.7354 - recall_3: 0.7354 - val_loss: 0.3929 - val_accuracy: 0.8416 - val_precision_3: 0.8416 - val_recall_3: 0.8416\n",
      "Epoch 299/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7487 - precision_3: 0.7487 - recall_3: 0.7487 - val_loss: 0.3792 - val_accuracy: 0.8504 - val_precision_3: 0.8504 - val_recall_3: 0.8504\n",
      "Epoch 300/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5586 - accuracy: 0.6973 - precision_3: 0.6973 - recall_3: 0.6973 - val_loss: 0.3837 - val_accuracy: 0.8522 - val_precision_3: 0.8522 - val_recall_3: 0.8522\n",
      "Epoch 301/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7522 - precision_3: 0.7522 - recall_3: 0.7522 - val_loss: 0.3687 - val_accuracy: 0.8628 - val_precision_3: 0.8628 - val_recall_3: 0.8628\n",
      "Epoch 302/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7372 - precision_3: 0.7372 - recall_3: 0.7372 - val_loss: 0.3633 - val_accuracy: 0.8761 - val_precision_3: 0.8761 - val_recall_3: 0.8761\n",
      "Epoch 303/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7265 - precision_3: 0.7265 - recall_3: 0.7265 - val_loss: 0.3633 - val_accuracy: 0.8850 - val_precision_3: 0.8850 - val_recall_3: 0.8850\n",
      "Epoch 304/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7319 - precision_3: 0.7319 - recall_3: 0.7319 - val_loss: 0.3779 - val_accuracy: 0.8504 - val_precision_3: 0.8504 - val_recall_3: 0.8504\n",
      "Epoch 305/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7549 - precision_3: 0.7549 - recall_3: 0.7549 - val_loss: 0.3671 - val_accuracy: 0.8655 - val_precision_3: 0.8655 - val_recall_3: 0.8655\n",
      "Epoch 306/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5101 - accuracy: 0.7531 - precision_3: 0.7531 - recall_3: 0.7531 - val_loss: 0.3694 - val_accuracy: 0.8619 - val_precision_3: 0.8619 - val_recall_3: 0.8619\n",
      "Epoch 307/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7363 - precision_3: 0.7363 - recall_3: 0.7363 - val_loss: 0.3620 - val_accuracy: 0.8593 - val_precision_3: 0.8593 - val_recall_3: 0.8593\n",
      "Epoch 308/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7292 - precision_3: 0.7292 - recall_3: 0.7292 - val_loss: 0.3661 - val_accuracy: 0.8699 - val_precision_3: 0.8699 - val_recall_3: 0.8699\n",
      "Epoch 309/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5513 - accuracy: 0.7212 - precision_3: 0.7212 - recall_3: 0.7212 - val_loss: 0.3780 - val_accuracy: 0.8558 - val_precision_3: 0.8558 - val_recall_3: 0.8558\n",
      "Epoch 310/2000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5302 - accuracy: 0.7327 - precision_3: 0.7327 - recall_3: 0.7327 - val_loss: 0.3622 - val_accuracy: 0.8726 - val_precision_3: 0.8726 - val_recall_3: 0.8726\n",
      "Epoch 311/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5259 - accuracy: 0.7381 - precision_3: 0.7381 - recall_3: 0.7381 - val_loss: 0.3678 - val_accuracy: 0.8584 - val_precision_3: 0.8584 - val_recall_3: 0.8584\n",
      "Epoch 312/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5006 - accuracy: 0.7558 - precision_3: 0.7558 - recall_3: 0.7558 - val_loss: 0.3928 - val_accuracy: 0.8310 - val_precision_3: 0.8310 - val_recall_3: 0.8310\n",
      "Epoch 313/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5477 - accuracy: 0.7381 - precision_3: 0.7381 - recall_3: 0.7381 - val_loss: 0.3608 - val_accuracy: 0.8646 - val_precision_3: 0.8646 - val_recall_3: 0.8646\n",
      "Epoch 314/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7434 - precision_3: 0.7434 - recall_3: 0.7434 - val_loss: 0.3562 - val_accuracy: 0.8726 - val_precision_3: 0.8726 - val_recall_3: 0.8726\n",
      "Epoch 315/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7531 - precision_3: 0.7531 - recall_3: 0.7531 - val_loss: 0.3533 - val_accuracy: 0.8832 - val_precision_3: 0.8832 - val_recall_3: 0.8832\n",
      "Epoch 316/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.7504 - precision_3: 0.7504 - recall_3: 0.7504 - val_loss: 0.3675 - val_accuracy: 0.8602 - val_precision_3: 0.8602 - val_recall_3: 0.8602\n",
      "Epoch 317/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5261 - accuracy: 0.7469 - precision_3: 0.7469 - recall_3: 0.7469 - val_loss: 0.3512 - val_accuracy: 0.8779 - val_precision_3: 0.8779 - val_recall_3: 0.8779\n",
      "Epoch 318/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.7398 - precision_3: 0.7398 - recall_3: 0.7398 - val_loss: 0.3444 - val_accuracy: 0.8858 - val_precision_3: 0.8858 - val_recall_3: 0.8858\n",
      "Epoch 319/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5026 - accuracy: 0.7584 - precision_3: 0.7584 - recall_3: 0.7584 - val_loss: 0.3516 - val_accuracy: 0.8681 - val_precision_3: 0.8681 - val_recall_3: 0.8681\n",
      "Epoch 320/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.7425 - precision_3: 0.7425 - recall_3: 0.7425 - val_loss: 0.3659 - val_accuracy: 0.8717 - val_precision_3: 0.8717 - val_recall_3: 0.8717\n",
      "Epoch 321/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7558 - precision_3: 0.7558 - recall_3: 0.7558 - val_loss: 0.3930 - val_accuracy: 0.8416 - val_precision_3: 0.8416 - val_recall_3: 0.8416\n",
      "Epoch 322/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5151 - accuracy: 0.7487 - precision_3: 0.7487 - recall_3: 0.7487 - val_loss: 0.3501 - val_accuracy: 0.8876 - val_precision_3: 0.8876 - val_recall_3: 0.8876\n",
      "Epoch 323/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5321 - accuracy: 0.7345 - precision_3: 0.7345 - recall_3: 0.7345 - val_loss: 0.3628 - val_accuracy: 0.8619 - val_precision_3: 0.8619 - val_recall_3: 0.8619\n",
      "Epoch 324/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7655 - precision_3: 0.7655 - recall_3: 0.7655 - val_loss: 0.3456 - val_accuracy: 0.8805 - val_precision_3: 0.8805 - val_recall_3: 0.8805\n",
      "Epoch 325/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5054 - accuracy: 0.7478 - precision_3: 0.7478 - recall_3: 0.7478 - val_loss: 0.3528 - val_accuracy: 0.8708 - val_precision_3: 0.8708 - val_recall_3: 0.8708\n",
      "Epoch 326/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5512 - accuracy: 0.7248 - precision_3: 0.7248 - recall_3: 0.7248 - val_loss: 0.3608 - val_accuracy: 0.8717 - val_precision_3: 0.8717 - val_recall_3: 0.8717\n",
      "Epoch 327/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7389 - precision_3: 0.7389 - recall_3: 0.7389 - val_loss: 0.3566 - val_accuracy: 0.8752 - val_precision_3: 0.8752 - val_recall_3: 0.8752\n",
      "Epoch 328/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7257 - precision_3: 0.7257 - recall_3: 0.7257 - val_loss: 0.3718 - val_accuracy: 0.8522 - val_precision_3: 0.8522 - val_recall_3: 0.8522\n",
      "Epoch 329/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7345 - precision_3: 0.7345 - recall_3: 0.7345 - val_loss: 0.3641 - val_accuracy: 0.8513 - val_precision_3: 0.8513 - val_recall_3: 0.8513\n",
      "Epoch 330/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7531 - precision_3: 0.7531 - recall_3: 0.7531 - val_loss: 0.3620 - val_accuracy: 0.8637 - val_precision_3: 0.8637 - val_recall_3: 0.8637\n",
      "Epoch 331/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7584 - precision_3: 0.7584 - recall_3: 0.7584 - val_loss: 0.3457 - val_accuracy: 0.8752 - val_precision_3: 0.8752 - val_recall_3: 0.8752\n",
      "Epoch 332/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7566 - precision_3: 0.7566 - recall_3: 0.7566 - val_loss: 0.3411 - val_accuracy: 0.8885 - val_precision_3: 0.8885 - val_recall_3: 0.8885\n",
      "Epoch 333/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5032 - accuracy: 0.7540 - precision_3: 0.7540 - recall_3: 0.7540 - val_loss: 0.3421 - val_accuracy: 0.8823 - val_precision_3: 0.8823 - val_recall_3: 0.8823\n",
      "Epoch 334/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7504 - precision_3: 0.7504 - recall_3: 0.7504 - val_loss: 0.3316 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 335/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5119 - accuracy: 0.7655 - precision_3: 0.7655 - recall_3: 0.7655 - val_loss: 0.3434 - val_accuracy: 0.8752 - val_precision_3: 0.8752 - val_recall_3: 0.8752\n",
      "Epoch 336/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7593 - precision_3: 0.7593 - recall_3: 0.7593 - val_loss: 0.3231 - val_accuracy: 0.9035 - val_precision_3: 0.9035 - val_recall_3: 0.9035\n",
      "Epoch 337/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4965 - accuracy: 0.7726 - precision_3: 0.7726 - recall_3: 0.7726 - val_loss: 0.3193 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 338/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7566 - precision_3: 0.7566 - recall_3: 0.7566 - val_loss: 0.3343 - val_accuracy: 0.8788 - val_precision_3: 0.8788 - val_recall_3: 0.8788\n",
      "Epoch 339/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.3266 - val_accuracy: 0.8947 - val_precision_3: 0.8947 - val_recall_3: 0.8947\n",
      "Epoch 340/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7460 - precision_3: 0.7460 - recall_3: 0.7460 - val_loss: 0.3377 - val_accuracy: 0.8673 - val_precision_3: 0.8673 - val_recall_3: 0.8673\n",
      "Epoch 341/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5001 - accuracy: 0.7531 - precision_3: 0.7531 - recall_3: 0.7531 - val_loss: 0.3299 - val_accuracy: 0.8903 - val_precision_3: 0.8903 - val_recall_3: 0.8903\n",
      "Epoch 342/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7646 - precision_3: 0.7646 - recall_3: 0.7646 - val_loss: 0.3222 - val_accuracy: 0.8920 - val_precision_3: 0.8920 - val_recall_3: 0.8920\n",
      "Epoch 343/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7513 - precision_3: 0.7513 - recall_3: 0.7513 - val_loss: 0.3219 - val_accuracy: 0.8894 - val_precision_3: 0.8894 - val_recall_3: 0.8894\n",
      "Epoch 344/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.7611 - precision_3: 0.7611 - recall_3: 0.7611 - val_loss: 0.3244 - val_accuracy: 0.8929 - val_precision_3: 0.8929 - val_recall_3: 0.8929\n",
      "Epoch 345/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4944 - accuracy: 0.7619 - precision_3: 0.7619 - recall_3: 0.7619 - val_loss: 0.3317 - val_accuracy: 0.8805 - val_precision_3: 0.8805 - val_recall_3: 0.8805\n",
      "Epoch 346/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4933 - accuracy: 0.7646 - precision_3: 0.7646 - recall_3: 0.7646 - val_loss: 0.3285 - val_accuracy: 0.8903 - val_precision_3: 0.8903 - val_recall_3: 0.8903\n",
      "Epoch 347/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7593 - precision_3: 0.7593 - recall_3: 0.7593 - val_loss: 0.3162 - val_accuracy: 0.9071 - val_precision_3: 0.9071 - val_recall_3: 0.9071\n",
      "Epoch 348/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5125 - accuracy: 0.7575 - precision_3: 0.7575 - recall_3: 0.7575 - val_loss: 0.3140 - val_accuracy: 0.8991 - val_precision_3: 0.8991 - val_recall_3: 0.8991\n",
      "Epoch 349/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5085 - accuracy: 0.7593 - precision_3: 0.7593 - recall_3: 0.7593 - val_loss: 0.3143 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 350/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7673 - precision_3: 0.7673 - recall_3: 0.7673 - val_loss: 0.3116 - val_accuracy: 0.9097 - val_precision_3: 0.9097 - val_recall_3: 0.9097\n",
      "Epoch 351/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.3165 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 352/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5055 - accuracy: 0.7451 - precision_3: 0.7451 - recall_3: 0.7451 - val_loss: 0.3190 - val_accuracy: 0.8876 - val_precision_3: 0.8876 - val_recall_3: 0.8876\n",
      "Epoch 353/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7646 - precision_3: 0.7646 - recall_3: 0.7646 - val_loss: 0.3140 - val_accuracy: 0.8947 - val_precision_3: 0.8947 - val_recall_3: 0.8947\n",
      "Epoch 354/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7584 - precision_3: 0.7584 - recall_3: 0.7584 - val_loss: 0.3049 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 355/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7681 - precision_3: 0.7681 - recall_3: 0.7681 - val_loss: 0.3137 - val_accuracy: 0.8956 - val_precision_3: 0.8956 - val_recall_3: 0.8956\n",
      "Epoch 356/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4945 - accuracy: 0.7628 - precision_3: 0.7628 - recall_3: 0.7628 - val_loss: 0.3223 - val_accuracy: 0.8912 - val_precision_3: 0.8912 - val_recall_3: 0.8912\n",
      "Epoch 357/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7708 - precision_3: 0.7708 - recall_3: 0.7708 - val_loss: 0.2955 - val_accuracy: 0.9133 - val_precision_3: 0.9133 - val_recall_3: 0.9133\n",
      "Epoch 358/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7752 - precision_3: 0.7752 - recall_3: 0.7752 - val_loss: 0.2915 - val_accuracy: 0.9142 - val_precision_3: 0.9142 - val_recall_3: 0.9142\n",
      "Epoch 359/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7619 - precision_3: 0.7619 - recall_3: 0.7619 - val_loss: 0.3110 - val_accuracy: 0.8912 - val_precision_3: 0.8912 - val_recall_3: 0.8912\n",
      "Epoch 360/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7796 - precision_3: 0.7796 - recall_3: 0.7796 - val_loss: 0.3004 - val_accuracy: 0.8991 - val_precision_3: 0.8991 - val_recall_3: 0.8991\n",
      "Epoch 361/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4834 - accuracy: 0.7664 - precision_3: 0.7664 - recall_3: 0.7664 - val_loss: 0.2879 - val_accuracy: 0.9195 - val_precision_3: 0.9195 - val_recall_3: 0.9195\n",
      "Epoch 362/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7726 - precision_3: 0.7726 - recall_3: 0.7726 - val_loss: 0.2997 - val_accuracy: 0.9027 - val_precision_3: 0.9027 - val_recall_3: 0.9027\n",
      "Epoch 363/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4968 - accuracy: 0.7611 - precision_3: 0.7611 - recall_3: 0.7611 - val_loss: 0.2951 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 364/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.3298 - val_accuracy: 0.8752 - val_precision_3: 0.8752 - val_recall_3: 0.8752\n",
      "Epoch 365/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.7655 - precision_3: 0.7655 - recall_3: 0.7655 - val_loss: 0.3057 - val_accuracy: 0.8991 - val_precision_3: 0.8991 - val_recall_3: 0.8991\n",
      "Epoch 366/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7540 - precision_3: 0.7540 - recall_3: 0.7540 - val_loss: 0.2989 - val_accuracy: 0.9062 - val_precision_3: 0.9062 - val_recall_3: 0.9062\n",
      "Epoch 367/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7487 - precision_3: 0.7487 - recall_3: 0.7487 - val_loss: 0.3100 - val_accuracy: 0.8991 - val_precision_3: 0.8991 - val_recall_3: 0.8991\n",
      "Epoch 368/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7805 - precision_3: 0.7805 - recall_3: 0.7805 - val_loss: 0.3003 - val_accuracy: 0.9097 - val_precision_3: 0.9097 - val_recall_3: 0.9097\n",
      "Epoch 369/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7681 - precision_3: 0.7681 - recall_3: 0.7681 - val_loss: 0.3042 - val_accuracy: 0.9115 - val_precision_3: 0.9115 - val_recall_3: 0.9115\n",
      "Epoch 370/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7637 - precision_3: 0.7637 - recall_3: 0.7637 - val_loss: 0.3063 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 371/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7628 - precision_3: 0.7628 - recall_3: 0.7628 - val_loss: 0.2984 - val_accuracy: 0.9115 - val_precision_3: 0.9115 - val_recall_3: 0.9115\n",
      "Epoch 372/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.7372 - precision_3: 0.7372 - recall_3: 0.7372 - val_loss: 0.3077 - val_accuracy: 0.9062 - val_precision_3: 0.9062 - val_recall_3: 0.9062\n",
      "Epoch 373/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.7619 - precision_3: 0.7619 - recall_3: 0.7619 - val_loss: 0.3067 - val_accuracy: 0.8965 - val_precision_3: 0.8965 - val_recall_3: 0.8965\n",
      "Epoch 374/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7655 - precision_3: 0.7655 - recall_3: 0.7655 - val_loss: 0.3298 - val_accuracy: 0.8832 - val_precision_3: 0.8832 - val_recall_3: 0.8832\n",
      "Epoch 375/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5030 - accuracy: 0.7522 - precision_3: 0.7522 - recall_3: 0.7522 - val_loss: 0.3391 - val_accuracy: 0.8823 - val_precision_3: 0.8823 - val_recall_3: 0.8823\n",
      "Epoch 376/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4746 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.3040 - val_accuracy: 0.8938 - val_precision_3: 0.8938 - val_recall_3: 0.8938\n",
      "Epoch 377/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5090 - accuracy: 0.7478 - precision_3: 0.7478 - recall_3: 0.7478 - val_loss: 0.3010 - val_accuracy: 0.8947 - val_precision_3: 0.8947 - val_recall_3: 0.8947\n",
      "Epoch 378/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4988 - accuracy: 0.7549 - precision_3: 0.7549 - recall_3: 0.7549 - val_loss: 0.2951 - val_accuracy: 0.9106 - val_precision_3: 0.9106 - val_recall_3: 0.9106\n",
      "Epoch 379/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4779 - accuracy: 0.7673 - precision_3: 0.7673 - recall_3: 0.7673 - val_loss: 0.3164 - val_accuracy: 0.8912 - val_precision_3: 0.8912 - val_recall_3: 0.8912\n",
      "Epoch 380/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4869 - accuracy: 0.7752 - precision_3: 0.7752 - recall_3: 0.7752 - val_loss: 0.2922 - val_accuracy: 0.9044 - val_precision_3: 0.9044 - val_recall_3: 0.9044\n",
      "Epoch 381/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4619 - accuracy: 0.7850 - precision_3: 0.7850 - recall_3: 0.7850 - val_loss: 0.2997 - val_accuracy: 0.9053 - val_precision_3: 0.9053 - val_recall_3: 0.9053\n",
      "Epoch 382/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.3018 - val_accuracy: 0.8965 - val_precision_3: 0.8965 - val_recall_3: 0.8965\n",
      "Epoch 383/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7611 - precision_3: 0.7611 - recall_3: 0.7611 - val_loss: 0.3440 - val_accuracy: 0.8673 - val_precision_3: 0.8673 - val_recall_3: 0.8673\n",
      "Epoch 384/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.7584 - precision_3: 0.7584 - recall_3: 0.7584 - val_loss: 0.3061 - val_accuracy: 0.8982 - val_precision_3: 0.8982 - val_recall_3: 0.8982\n",
      "Epoch 385/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4906 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.3076 - val_accuracy: 0.8929 - val_precision_3: 0.8929 - val_recall_3: 0.8929\n",
      "Epoch 386/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7558 - precision_3: 0.7558 - recall_3: 0.7558 - val_loss: 0.2914 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 387/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7566 - precision_3: 0.7566 - recall_3: 0.7566 - val_loss: 0.3013 - val_accuracy: 0.9097 - val_precision_3: 0.9097 - val_recall_3: 0.9097\n",
      "Epoch 388/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.7681 - precision_3: 0.7681 - recall_3: 0.7681 - val_loss: 0.3248 - val_accuracy: 0.8832 - val_precision_3: 0.8832 - val_recall_3: 0.8832\n",
      "Epoch 389/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7460 - precision_3: 0.7460 - recall_3: 0.7460 - val_loss: 0.3251 - val_accuracy: 0.8832 - val_precision_3: 0.8832 - val_recall_3: 0.8832\n",
      "Epoch 390/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.2924 - val_accuracy: 0.9009 - val_precision_3: 0.9009 - val_recall_3: 0.9009\n",
      "Epoch 391/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7912 - precision_3: 0.7912 - recall_3: 0.7912 - val_loss: 0.2833 - val_accuracy: 0.9062 - val_precision_3: 0.9062 - val_recall_3: 0.9062\n",
      "Epoch 392/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7451 - precision_3: 0.7451 - recall_3: 0.7451 - val_loss: 0.2785 - val_accuracy: 0.9097 - val_precision_3: 0.9097 - val_recall_3: 0.9097\n",
      "Epoch 393/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7611 - precision_3: 0.7611 - recall_3: 0.7611 - val_loss: 0.2826 - val_accuracy: 0.9115 - val_precision_3: 0.9115 - val_recall_3: 0.9115\n",
      "Epoch 394/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.2799 - val_accuracy: 0.9071 - val_precision_3: 0.9071 - val_recall_3: 0.9071\n",
      "Epoch 395/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7637 - precision_3: 0.7637 - recall_3: 0.7637 - val_loss: 0.2679 - val_accuracy: 0.9221 - val_precision_3: 0.9221 - val_recall_3: 0.9221\n",
      "Epoch 396/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7920 - precision_3: 0.7920 - recall_3: 0.7920 - val_loss: 0.2691 - val_accuracy: 0.9133 - val_precision_3: 0.9133 - val_recall_3: 0.9133\n",
      "Epoch 397/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.2711 - val_accuracy: 0.9168 - val_precision_3: 0.9168 - val_recall_3: 0.9168\n",
      "Epoch 398/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7779 - precision_3: 0.7779 - recall_3: 0.7779 - val_loss: 0.2885 - val_accuracy: 0.9106 - val_precision_3: 0.9106 - val_recall_3: 0.9106\n",
      "Epoch 399/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4898 - accuracy: 0.7681 - precision_3: 0.7681 - recall_3: 0.7681 - val_loss: 0.2826 - val_accuracy: 0.9186 - val_precision_3: 0.9186 - val_recall_3: 0.9186\n",
      "Epoch 400/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7743 - precision_3: 0.7743 - recall_3: 0.7743 - val_loss: 0.2700 - val_accuracy: 0.9195 - val_precision_3: 0.9195 - val_recall_3: 0.9195\n",
      "Epoch 401/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.7903 - precision_3: 0.7903 - recall_3: 0.7903 - val_loss: 0.3026 - val_accuracy: 0.8965 - val_precision_3: 0.8965 - val_recall_3: 0.8965\n",
      "Epoch 402/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4896 - accuracy: 0.7699 - precision_3: 0.7699 - recall_3: 0.7699 - val_loss: 0.2869 - val_accuracy: 0.9071 - val_precision_3: 0.9071 - val_recall_3: 0.9071\n",
      "Epoch 403/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7832 - precision_3: 0.7832 - recall_3: 0.7832 - val_loss: 0.3028 - val_accuracy: 0.8965 - val_precision_3: 0.8965 - val_recall_3: 0.8965\n",
      "Epoch 404/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7796 - precision_3: 0.7796 - recall_3: 0.7796 - val_loss: 0.3022 - val_accuracy: 0.8938 - val_precision_3: 0.8938 - val_recall_3: 0.8938\n",
      "Epoch 405/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7841 - precision_3: 0.7841 - recall_3: 0.7841 - val_loss: 0.2840 - val_accuracy: 0.9150 - val_precision_3: 0.9150 - val_recall_3: 0.9150\n",
      "Epoch 406/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4964 - accuracy: 0.7566 - precision_3: 0.7566 - recall_3: 0.7566 - val_loss: 0.2760 - val_accuracy: 0.9177 - val_precision_3: 0.9177 - val_recall_3: 0.9177\n",
      "Epoch 407/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.7814 - precision_3: 0.7814 - recall_3: 0.7814 - val_loss: 0.2824 - val_accuracy: 0.9097 - val_precision_3: 0.9097 - val_recall_3: 0.9097\n",
      "Epoch 408/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7796 - precision_3: 0.7796 - recall_3: 0.7796 - val_loss: 0.2819 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 409/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4748 - accuracy: 0.7779 - precision_3: 0.7779 - recall_3: 0.7779 - val_loss: 0.2709 - val_accuracy: 0.9195 - val_precision_3: 0.9195 - val_recall_3: 0.9195\n",
      "Epoch 410/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4857 - accuracy: 0.7894 - precision_3: 0.7894 - recall_3: 0.7894 - val_loss: 0.2672 - val_accuracy: 0.9115 - val_precision_3: 0.9115 - val_recall_3: 0.9115\n",
      "Epoch 411/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7858 - precision_3: 0.7858 - recall_3: 0.7858 - val_loss: 0.2807 - val_accuracy: 0.9124 - val_precision_3: 0.9124 - val_recall_3: 0.9124\n",
      "Epoch 412/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7664 - precision_3: 0.7664 - recall_3: 0.7664 - val_loss: 0.2905 - val_accuracy: 0.9000 - val_precision_3: 0.9000 - val_recall_3: 0.9000\n",
      "Epoch 413/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.7743 - precision_3: 0.7743 - recall_3: 0.7743 - val_loss: 0.2735 - val_accuracy: 0.9142 - val_precision_3: 0.9142 - val_recall_3: 0.9142\n",
      "Epoch 414/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7867 - precision_3: 0.7867 - recall_3: 0.7867 - val_loss: 0.2818 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 415/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.7805 - precision_3: 0.7805 - recall_3: 0.7805 - val_loss: 0.2759 - val_accuracy: 0.9080 - val_precision_3: 0.9080 - val_recall_3: 0.9080\n",
      "Epoch 416/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.7858 - precision_3: 0.7858 - recall_3: 0.7858 - val_loss: 0.2731 - val_accuracy: 0.9044 - val_precision_3: 0.9044 - val_recall_3: 0.9044\n",
      "Epoch 417/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7788 - precision_3: 0.7788 - recall_3: 0.7788 - val_loss: 0.2987 - val_accuracy: 0.8885 - val_precision_3: 0.8885 - val_recall_3: 0.8885\n",
      "Epoch 418/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7743 - precision_3: 0.7743 - recall_3: 0.7743 - val_loss: 0.2674 - val_accuracy: 0.9248 - val_precision_3: 0.9248 - val_recall_3: 0.9248\n",
      "Epoch 419/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7584 - precision_3: 0.7584 - recall_3: 0.7584 - val_loss: 0.2722 - val_accuracy: 0.9195 - val_precision_3: 0.9195 - val_recall_3: 0.9195\n",
      "Epoch 420/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7973 - precision_3: 0.7973 - recall_3: 0.7973 - val_loss: 0.2817 - val_accuracy: 0.9106 - val_precision_3: 0.9106 - val_recall_3: 0.9106\n",
      "Epoch 421/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7973 - precision_3: 0.7973 - recall_3: 0.7973 - val_loss: 0.2629 - val_accuracy: 0.9177 - val_precision_3: 0.9177 - val_recall_3: 0.9177\n",
      "Epoch 422/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.2642 - val_accuracy: 0.9257 - val_precision_3: 0.9257 - val_recall_3: 0.9257\n",
      "Epoch 423/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7991 - precision_3: 0.7991 - recall_3: 0.7991 - val_loss: 0.2601 - val_accuracy: 0.9327 - val_precision_3: 0.9327 - val_recall_3: 0.9327\n",
      "Epoch 424/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7805 - precision_3: 0.7805 - recall_3: 0.7805 - val_loss: 0.2803 - val_accuracy: 0.9035 - val_precision_3: 0.9035 - val_recall_3: 0.9035\n",
      "Epoch 425/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7947 - precision_3: 0.7947 - recall_3: 0.7947 - val_loss: 0.2530 - val_accuracy: 0.9239 - val_precision_3: 0.9239 - val_recall_3: 0.9239\n",
      "Epoch 426/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7858 - precision_3: 0.7858 - recall_3: 0.7858 - val_loss: 0.2519 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 427/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7814 - precision_3: 0.7814 - recall_3: 0.7814 - val_loss: 0.2450 - val_accuracy: 0.9398 - val_precision_3: 0.9398 - val_recall_3: 0.9398\n",
      "Epoch 428/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7673 - precision_3: 0.7673 - recall_3: 0.7673 - val_loss: 0.2534 - val_accuracy: 0.9239 - val_precision_3: 0.9239 - val_recall_3: 0.9239\n",
      "Epoch 429/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7885 - precision_3: 0.7885 - recall_3: 0.7885 - val_loss: 0.2446 - val_accuracy: 0.9469 - val_precision_3: 0.9469 - val_recall_3: 0.9469\n",
      "Epoch 430/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7858 - precision_3: 0.7858 - recall_3: 0.7858 - val_loss: 0.2545 - val_accuracy: 0.9248 - val_precision_3: 0.9248 - val_recall_3: 0.9248\n",
      "Epoch 431/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7690 - precision_3: 0.7690 - recall_3: 0.7690 - val_loss: 0.2525 - val_accuracy: 0.9292 - val_precision_3: 0.9292 - val_recall_3: 0.9292\n",
      "Epoch 432/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7832 - precision_3: 0.7832 - recall_3: 0.7832 - val_loss: 0.2600 - val_accuracy: 0.9221 - val_precision_3: 0.9221 - val_recall_3: 0.9221\n",
      "Epoch 433/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.7619 - precision_3: 0.7619 - recall_3: 0.7619 - val_loss: 0.2342 - val_accuracy: 0.9398 - val_precision_3: 0.9398 - val_recall_3: 0.9398\n",
      "Epoch 434/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8062 - precision_3: 0.8062 - recall_3: 0.8062 - val_loss: 0.2541 - val_accuracy: 0.9212 - val_precision_3: 0.9212 - val_recall_3: 0.9212\n",
      "Epoch 435/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.7991 - precision_3: 0.7991 - recall_3: 0.7991 - val_loss: 0.2478 - val_accuracy: 0.9389 - val_precision_3: 0.9389 - val_recall_3: 0.9389\n",
      "Epoch 436/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.2359 - val_accuracy: 0.9381 - val_precision_3: 0.9381 - val_recall_3: 0.9381\n",
      "Epoch 437/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.7832 - precision_3: 0.7832 - recall_3: 0.7832 - val_loss: 0.2349 - val_accuracy: 0.9434 - val_precision_3: 0.9434 - val_recall_3: 0.9434\n",
      "Epoch 438/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4726 - accuracy: 0.7779 - precision_3: 0.7779 - recall_3: 0.7779 - val_loss: 0.2316 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 439/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7743 - precision_3: 0.7743 - recall_3: 0.7743 - val_loss: 0.2346 - val_accuracy: 0.9407 - val_precision_3: 0.9407 - val_recall_3: 0.9407\n",
      "Epoch 440/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.2272 - val_accuracy: 0.9416 - val_precision_3: 0.9416 - val_recall_3: 0.9416\n",
      "Epoch 441/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7770 - precision_3: 0.7770 - recall_3: 0.7770 - val_loss: 0.2440 - val_accuracy: 0.9363 - val_precision_3: 0.9363 - val_recall_3: 0.9363\n",
      "Epoch 442/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.7991 - precision_3: 0.7991 - recall_3: 0.7991 - val_loss: 0.2457 - val_accuracy: 0.9363 - val_precision_3: 0.9363 - val_recall_3: 0.9363\n",
      "Epoch 443/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.2413 - val_accuracy: 0.9389 - val_precision_3: 0.9389 - val_recall_3: 0.9389\n",
      "Epoch 444/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7752 - precision_3: 0.7752 - recall_3: 0.7752 - val_loss: 0.2346 - val_accuracy: 0.9310 - val_precision_3: 0.9310 - val_recall_3: 0.9310\n",
      "Epoch 445/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7814 - precision_3: 0.7814 - recall_3: 0.7814 - val_loss: 0.2257 - val_accuracy: 0.9496 - val_precision_3: 0.9496 - val_recall_3: 0.9496\n",
      "Epoch 446/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7867 - precision_3: 0.7867 - recall_3: 0.7867 - val_loss: 0.2536 - val_accuracy: 0.9195 - val_precision_3: 0.9195 - val_recall_3: 0.9195\n",
      "Epoch 447/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4498 - accuracy: 0.7929 - precision_3: 0.7929 - recall_3: 0.7929 - val_loss: 0.2527 - val_accuracy: 0.9239 - val_precision_3: 0.9239 - val_recall_3: 0.9239\n",
      "Epoch 448/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7850 - precision_3: 0.7850 - recall_3: 0.7850 - val_loss: 0.2429 - val_accuracy: 0.9319 - val_precision_3: 0.9319 - val_recall_3: 0.9319\n",
      "Epoch 449/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.7735 - precision_3: 0.7735 - recall_3: 0.7735 - val_loss: 0.2390 - val_accuracy: 0.9265 - val_precision_3: 0.9265 - val_recall_3: 0.9265\n",
      "Epoch 450/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7779 - precision_3: 0.7779 - recall_3: 0.7779 - val_loss: 0.2193 - val_accuracy: 0.9522 - val_precision_3: 0.9522 - val_recall_3: 0.9522\n",
      "Epoch 451/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8000 - precision_3: 0.8000 - recall_3: 0.8000 - val_loss: 0.2240 - val_accuracy: 0.9407 - val_precision_3: 0.9407 - val_recall_3: 0.9407\n",
      "Epoch 452/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4569 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.2401 - val_accuracy: 0.9363 - val_precision_3: 0.9363 - val_recall_3: 0.9363\n",
      "Epoch 453/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8150 - precision_3: 0.8150 - recall_3: 0.8150 - val_loss: 0.2332 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 454/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7929 - precision_3: 0.7929 - recall_3: 0.7929 - val_loss: 0.2457 - val_accuracy: 0.9088 - val_precision_3: 0.9088 - val_recall_3: 0.9088\n",
      "Epoch 455/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7947 - precision_3: 0.7947 - recall_3: 0.7947 - val_loss: 0.2285 - val_accuracy: 0.9407 - val_precision_3: 0.9407 - val_recall_3: 0.9407\n",
      "Epoch 456/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.2465 - val_accuracy: 0.9274 - val_precision_3: 0.9274 - val_recall_3: 0.9274\n",
      "Epoch 457/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7664 - precision_3: 0.7664 - recall_3: 0.7664 - val_loss: 0.2766 - val_accuracy: 0.9018 - val_precision_3: 0.9018 - val_recall_3: 0.9018\n",
      "Epoch 458/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7920 - precision_3: 0.7920 - recall_3: 0.7920 - val_loss: 0.2600 - val_accuracy: 0.9168 - val_precision_3: 0.9168 - val_recall_3: 0.9168\n",
      "Epoch 459/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.2446 - val_accuracy: 0.9221 - val_precision_3: 0.9221 - val_recall_3: 0.9221\n",
      "Epoch 460/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7885 - precision_3: 0.7885 - recall_3: 0.7885 - val_loss: 0.2327 - val_accuracy: 0.9372 - val_precision_3: 0.9372 - val_recall_3: 0.9372\n",
      "Epoch 461/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7965 - precision_3: 0.7965 - recall_3: 0.7965 - val_loss: 0.2461 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 462/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7761 - precision_3: 0.7761 - recall_3: 0.7761 - val_loss: 0.2344 - val_accuracy: 0.9310 - val_precision_3: 0.9310 - val_recall_3: 0.9310\n",
      "Epoch 463/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.7973 - precision_3: 0.7973 - recall_3: 0.7973 - val_loss: 0.2252 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 464/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7982 - precision_3: 0.7982 - recall_3: 0.7982 - val_loss: 0.2316 - val_accuracy: 0.9407 - val_precision_3: 0.9407 - val_recall_3: 0.9407\n",
      "Epoch 465/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.2098 - val_accuracy: 0.9460 - val_precision_3: 0.9460 - val_recall_3: 0.9460\n",
      "Epoch 466/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.8053 - precision_3: 0.8053 - recall_3: 0.8053 - val_loss: 0.2136 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 467/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.8044 - precision_3: 0.8044 - recall_3: 0.8044 - val_loss: 0.2312 - val_accuracy: 0.9469 - val_precision_3: 0.9469 - val_recall_3: 0.9469\n",
      "Epoch 468/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4555 - accuracy: 0.7912 - precision_3: 0.7912 - recall_3: 0.7912 - val_loss: 0.2461 - val_accuracy: 0.9336 - val_precision_3: 0.9336 - val_recall_3: 0.9336\n",
      "Epoch 469/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4137 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.2366 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 470/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.8035 - precision_3: 0.8035 - recall_3: 0.8035 - val_loss: 0.2143 - val_accuracy: 0.9487 - val_precision_3: 0.9487 - val_recall_3: 0.9487\n",
      "Epoch 471/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7956 - precision_3: 0.7956 - recall_3: 0.7956 - val_loss: 0.2231 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 472/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.2753 - val_accuracy: 0.9115 - val_precision_3: 0.9115 - val_recall_3: 0.9115\n",
      "Epoch 473/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4589 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.2761 - val_accuracy: 0.9044 - val_precision_3: 0.9044 - val_recall_3: 0.9044\n",
      "Epoch 474/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8044 - precision_3: 0.8044 - recall_3: 0.8044 - val_loss: 0.2540 - val_accuracy: 0.9265 - val_precision_3: 0.9265 - val_recall_3: 0.9265\n",
      "Epoch 475/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.7982 - precision_3: 0.7982 - recall_3: 0.7982 - val_loss: 0.2343 - val_accuracy: 0.9381 - val_precision_3: 0.9381 - val_recall_3: 0.9381\n",
      "Epoch 476/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8106 - precision_3: 0.8106 - recall_3: 0.8106 - val_loss: 0.2105 - val_accuracy: 0.9522 - val_precision_3: 0.9522 - val_recall_3: 0.9522\n",
      "Epoch 477/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.2164 - val_accuracy: 0.9496 - val_precision_3: 0.9496 - val_recall_3: 0.9496\n",
      "Epoch 478/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7814 - precision_3: 0.7814 - recall_3: 0.7814 - val_loss: 0.2056 - val_accuracy: 0.9531 - val_precision_3: 0.9531 - val_recall_3: 0.9531\n",
      "Epoch 479/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4500 - accuracy: 0.7814 - precision_3: 0.7814 - recall_3: 0.7814 - val_loss: 0.2343 - val_accuracy: 0.9274 - val_precision_3: 0.9274 - val_recall_3: 0.9274\n",
      "Epoch 480/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.7912 - precision_3: 0.7912 - recall_3: 0.7912 - val_loss: 0.2180 - val_accuracy: 0.9398 - val_precision_3: 0.9398 - val_recall_3: 0.9398\n",
      "Epoch 481/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7673 - precision_3: 0.7673 - recall_3: 0.7673 - val_loss: 0.2257 - val_accuracy: 0.9372 - val_precision_3: 0.9372 - val_recall_3: 0.9372\n",
      "Epoch 482/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.8062 - precision_3: 0.8062 - recall_3: 0.8062 - val_loss: 0.2274 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 483/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.8000 - precision_3: 0.8000 - recall_3: 0.8000 - val_loss: 0.2321 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 484/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.7938 - precision_3: 0.7938 - recall_3: 0.7938 - val_loss: 0.2158 - val_accuracy: 0.9434 - val_precision_3: 0.9434 - val_recall_3: 0.9434\n",
      "Epoch 485/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.7991 - precision_3: 0.7991 - recall_3: 0.7991 - val_loss: 0.2179 - val_accuracy: 0.9434 - val_precision_3: 0.9434 - val_recall_3: 0.9434\n",
      "Epoch 486/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7938 - precision_3: 0.7938 - recall_3: 0.7938 - val_loss: 0.2268 - val_accuracy: 0.9372 - val_precision_3: 0.9372 - val_recall_3: 0.9372\n",
      "Epoch 487/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.2010 - val_accuracy: 0.9496 - val_precision_3: 0.9496 - val_recall_3: 0.9496\n",
      "Epoch 488/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7867 - precision_3: 0.7867 - recall_3: 0.7867 - val_loss: 0.2044 - val_accuracy: 0.9549 - val_precision_3: 0.9549 - val_recall_3: 0.9549\n",
      "Epoch 489/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8274 - precision_3: 0.8274 - recall_3: 0.8274 - val_loss: 0.2190 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 490/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7973 - precision_3: 0.7973 - recall_3: 0.7973 - val_loss: 0.2396 - val_accuracy: 0.9354 - val_precision_3: 0.9354 - val_recall_3: 0.9354\n",
      "Epoch 491/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.2333 - val_accuracy: 0.9398 - val_precision_3: 0.9398 - val_recall_3: 0.9398\n",
      "Epoch 492/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7912 - precision_3: 0.7912 - recall_3: 0.7912 - val_loss: 0.2208 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 493/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4568 - accuracy: 0.7903 - precision_3: 0.7903 - recall_3: 0.7903 - val_loss: 0.1978 - val_accuracy: 0.9549 - val_precision_3: 0.9549 - val_recall_3: 0.9549\n",
      "Epoch 494/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.7956 - precision_3: 0.7956 - recall_3: 0.7956 - val_loss: 0.2103 - val_accuracy: 0.9504 - val_precision_3: 0.9504 - val_recall_3: 0.9504\n",
      "Epoch 495/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7965 - precision_3: 0.7965 - recall_3: 0.7965 - val_loss: 0.2210 - val_accuracy: 0.9434 - val_precision_3: 0.9434 - val_recall_3: 0.9434\n",
      "Epoch 496/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.2372 - val_accuracy: 0.9221 - val_precision_3: 0.9221 - val_recall_3: 0.9221\n",
      "Epoch 497/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7920 - precision_3: 0.7920 - recall_3: 0.7920 - val_loss: 0.2043 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 498/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4168 - accuracy: 0.8212 - precision_3: 0.8212 - recall_3: 0.8212 - val_loss: 0.2184 - val_accuracy: 0.9354 - val_precision_3: 0.9354 - val_recall_3: 0.9354\n",
      "Epoch 499/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.8195 - precision_3: 0.8195 - recall_3: 0.8195 - val_loss: 0.2290 - val_accuracy: 0.9381 - val_precision_3: 0.9381 - val_recall_3: 0.9381\n",
      "Epoch 500/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.7903 - precision_3: 0.7903 - recall_3: 0.7903 - val_loss: 0.2153 - val_accuracy: 0.9469 - val_precision_3: 0.9469 - val_recall_3: 0.9469\n",
      "Epoch 501/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8150 - precision_3: 0.8150 - recall_3: 0.8150 - val_loss: 0.2116 - val_accuracy: 0.9389 - val_precision_3: 0.9389 - val_recall_3: 0.9389\n",
      "Epoch 502/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7788 - precision_3: 0.7788 - recall_3: 0.7788 - val_loss: 0.2182 - val_accuracy: 0.9398 - val_precision_3: 0.9398 - val_recall_3: 0.9398\n",
      "Epoch 503/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8009 - precision_3: 0.8009 - recall_3: 0.8009 - val_loss: 0.2198 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 504/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.8106 - precision_3: 0.8106 - recall_3: 0.8106 - val_loss: 0.2056 - val_accuracy: 0.9372 - val_precision_3: 0.9372 - val_recall_3: 0.9372\n",
      "Epoch 505/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7850 - precision_3: 0.7850 - recall_3: 0.7850 - val_loss: 0.2099 - val_accuracy: 0.9451 - val_precision_3: 0.9451 - val_recall_3: 0.9451\n",
      "Epoch 506/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7850 - precision_3: 0.7850 - recall_3: 0.7850 - val_loss: 0.1960 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 507/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8195 - precision_3: 0.8195 - recall_3: 0.8195 - val_loss: 0.2062 - val_accuracy: 0.9460 - val_precision_3: 0.9460 - val_recall_3: 0.9460\n",
      "Epoch 508/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8009 - precision_3: 0.8009 - recall_3: 0.8009 - val_loss: 0.1940 - val_accuracy: 0.9513 - val_precision_3: 0.9513 - val_recall_3: 0.9513\n",
      "Epoch 509/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7956 - precision_3: 0.7956 - recall_3: 0.7956 - val_loss: 0.2147 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 510/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8168 - precision_3: 0.8168 - recall_3: 0.8168 - val_loss: 0.2146 - val_accuracy: 0.9416 - val_precision_3: 0.9416 - val_recall_3: 0.9416\n",
      "Epoch 511/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.8027 - precision_3: 0.8027 - recall_3: 0.8027 - val_loss: 0.1921 - val_accuracy: 0.9566 - val_precision_3: 0.9566 - val_recall_3: 0.9566\n",
      "Epoch 512/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7965 - precision_3: 0.7965 - recall_3: 0.7965 - val_loss: 0.1900 - val_accuracy: 0.9531 - val_precision_3: 0.9531 - val_recall_3: 0.9531\n",
      "Epoch 513/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8168 - precision_3: 0.8168 - recall_3: 0.8168 - val_loss: 0.1907 - val_accuracy: 0.9504 - val_precision_3: 0.9504 - val_recall_3: 0.9504\n",
      "Epoch 514/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.7912 - precision_3: 0.7912 - recall_3: 0.7912 - val_loss: 0.2010 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 515/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.8009 - precision_3: 0.8009 - recall_3: 0.8009 - val_loss: 0.2138 - val_accuracy: 0.9416 - val_precision_3: 0.9416 - val_recall_3: 0.9416\n",
      "Epoch 516/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.2132 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 517/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7858 - precision_3: 0.7858 - recall_3: 0.7858 - val_loss: 0.2069 - val_accuracy: 0.9522 - val_precision_3: 0.9522 - val_recall_3: 0.9522\n",
      "Epoch 518/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8106 - precision_3: 0.8106 - recall_3: 0.8106 - val_loss: 0.1960 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 519/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8035 - precision_3: 0.8035 - recall_3: 0.8035 - val_loss: 0.2031 - val_accuracy: 0.9513 - val_precision_3: 0.9513 - val_recall_3: 0.9513\n",
      "Epoch 520/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.2193 - val_accuracy: 0.9389 - val_precision_3: 0.9389 - val_recall_3: 0.9389\n",
      "Epoch 521/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7956 - precision_3: 0.7956 - recall_3: 0.7956 - val_loss: 0.2173 - val_accuracy: 0.9345 - val_precision_3: 0.9345 - val_recall_3: 0.9345\n",
      "Epoch 522/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8080 - precision_3: 0.8080 - recall_3: 0.8080 - val_loss: 0.1827 - val_accuracy: 0.9566 - val_precision_3: 0.9566 - val_recall_3: 0.9566\n",
      "Epoch 523/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.1907 - val_accuracy: 0.9460 - val_precision_3: 0.9460 - val_recall_3: 0.9460\n",
      "Epoch 524/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8150 - precision_3: 0.8150 - recall_3: 0.8150 - val_loss: 0.1823 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 525/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8168 - precision_3: 0.8168 - recall_3: 0.8168 - val_loss: 0.1979 - val_accuracy: 0.9531 - val_precision_3: 0.9531 - val_recall_3: 0.9531\n",
      "Epoch 526/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.1974 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 527/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8053 - precision_3: 0.8053 - recall_3: 0.8053 - val_loss: 0.1732 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 528/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.1898 - val_accuracy: 0.9487 - val_precision_3: 0.9487 - val_recall_3: 0.9487\n",
      "Epoch 529/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7850 - precision_3: 0.7850 - recall_3: 0.7850 - val_loss: 0.1942 - val_accuracy: 0.9558 - val_precision_3: 0.9558 - val_recall_3: 0.9558\n",
      "Epoch 530/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8000 - precision_3: 0.8000 - recall_3: 0.8000 - val_loss: 0.1919 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 531/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1883 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 532/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1882 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 533/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.1893 - val_accuracy: 0.9558 - val_precision_3: 0.9558 - val_recall_3: 0.9558\n",
      "Epoch 534/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.1889 - val_accuracy: 0.9522 - val_precision_3: 0.9522 - val_recall_3: 0.9522\n",
      "Epoch 535/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.1835 - val_accuracy: 0.9584 - val_precision_3: 0.9584 - val_recall_3: 0.9584\n",
      "Epoch 536/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1810 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 537/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4208 - accuracy: 0.8106 - precision_3: 0.8106 - recall_3: 0.8106 - val_loss: 0.1804 - val_accuracy: 0.9593 - val_precision_3: 0.9593 - val_recall_3: 0.9593\n",
      "Epoch 538/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1944 - val_accuracy: 0.9513 - val_precision_3: 0.9513 - val_recall_3: 0.9513\n",
      "Epoch 539/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8080 - precision_3: 0.8080 - recall_3: 0.8080 - val_loss: 0.1870 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 540/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.8115 - precision_3: 0.8115 - recall_3: 0.8115 - val_loss: 0.1762 - val_accuracy: 0.9584 - val_precision_3: 0.9584 - val_recall_3: 0.9584\n",
      "Epoch 541/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8133 - precision_3: 0.8133 - recall_3: 0.8133 - val_loss: 0.1833 - val_accuracy: 0.9531 - val_precision_3: 0.9531 - val_recall_3: 0.9531\n",
      "Epoch 542/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1760 - val_accuracy: 0.9584 - val_precision_3: 0.9584 - val_recall_3: 0.9584\n",
      "Epoch 543/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8177 - precision_3: 0.8177 - recall_3: 0.8177 - val_loss: 0.1908 - val_accuracy: 0.9478 - val_precision_3: 0.9478 - val_recall_3: 0.9478\n",
      "Epoch 544/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8274 - precision_3: 0.8274 - recall_3: 0.8274 - val_loss: 0.1806 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 545/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8248 - precision_3: 0.8248 - recall_3: 0.8248 - val_loss: 0.1975 - val_accuracy: 0.9504 - val_precision_3: 0.9504 - val_recall_3: 0.9504\n",
      "Epoch 546/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8071 - precision_3: 0.8071 - recall_3: 0.8071 - val_loss: 0.1921 - val_accuracy: 0.9478 - val_precision_3: 0.9478 - val_recall_3: 0.9478\n",
      "Epoch 547/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4174 - accuracy: 0.8071 - precision_3: 0.8071 - recall_3: 0.8071 - val_loss: 0.1992 - val_accuracy: 0.9522 - val_precision_3: 0.9522 - val_recall_3: 0.9522\n",
      "Epoch 548/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1984 - val_accuracy: 0.9460 - val_precision_3: 0.9460 - val_recall_3: 0.9460\n",
      "Epoch 549/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8115 - precision_3: 0.8115 - recall_3: 0.8115 - val_loss: 0.1762 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 550/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8195 - precision_3: 0.8195 - recall_3: 0.8195 - val_loss: 0.1567 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 551/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1512 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 552/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1560 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 553/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8080 - precision_3: 0.8080 - recall_3: 0.8080 - val_loss: 0.1611 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 554/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8150 - precision_3: 0.8150 - recall_3: 0.8150 - val_loss: 0.1756 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 555/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.8035 - precision_3: 0.8035 - recall_3: 0.8035 - val_loss: 0.1964 - val_accuracy: 0.9549 - val_precision_3: 0.9549 - val_recall_3: 0.9549\n",
      "Epoch 556/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.2260 - val_accuracy: 0.9239 - val_precision_3: 0.9239 - val_recall_3: 0.9239\n",
      "Epoch 557/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7938 - precision_3: 0.7938 - recall_3: 0.7938 - val_loss: 0.1988 - val_accuracy: 0.9451 - val_precision_3: 0.9451 - val_recall_3: 0.9451\n",
      "Epoch 558/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4038 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1740 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 559/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7991 - precision_3: 0.7991 - recall_3: 0.7991 - val_loss: 0.1679 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 560/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.2150 - val_accuracy: 0.9274 - val_precision_3: 0.9274 - val_recall_3: 0.9274\n",
      "Epoch 561/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1810 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 562/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1771 - val_accuracy: 0.9549 - val_precision_3: 0.9549 - val_recall_3: 0.9549\n",
      "Epoch 563/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1952 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 564/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8133 - precision_3: 0.8133 - recall_3: 0.8133 - val_loss: 0.2035 - val_accuracy: 0.9460 - val_precision_3: 0.9460 - val_recall_3: 0.9460\n",
      "Epoch 565/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.1761 - val_accuracy: 0.9602 - val_precision_3: 0.9602 - val_recall_3: 0.9602\n",
      "Epoch 566/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1729 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 567/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8044 - precision_3: 0.8044 - recall_3: 0.8044 - val_loss: 0.1867 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 568/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.8035 - precision_3: 0.8035 - recall_3: 0.8035 - val_loss: 0.1724 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 569/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.8053 - precision_3: 0.8053 - recall_3: 0.8053 - val_loss: 0.1743 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 570/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.2056 - val_accuracy: 0.9354 - val_precision_3: 0.9354 - val_recall_3: 0.9354\n",
      "Epoch 571/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1803 - val_accuracy: 0.9619 - val_precision_3: 0.9619 - val_recall_3: 0.9619\n",
      "Epoch 572/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.2074 - val_accuracy: 0.9381 - val_precision_3: 0.9381 - val_recall_3: 0.9381\n",
      "Epoch 573/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.8044 - precision_3: 0.8044 - recall_3: 0.8044 - val_loss: 0.2040 - val_accuracy: 0.9416 - val_precision_3: 0.9416 - val_recall_3: 0.9416\n",
      "Epoch 574/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8106 - precision_3: 0.8106 - recall_3: 0.8106 - val_loss: 0.1961 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 575/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8301 - precision_3: 0.8301 - recall_3: 0.8301 - val_loss: 0.1988 - val_accuracy: 0.9478 - val_precision_3: 0.9478 - val_recall_3: 0.9478\n",
      "Epoch 576/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1618 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 577/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8248 - precision_3: 0.8248 - recall_3: 0.8248 - val_loss: 0.1752 - val_accuracy: 0.9531 - val_precision_3: 0.9531 - val_recall_3: 0.9531\n",
      "Epoch 578/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.1721 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 579/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1626 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 580/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1626 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 581/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1608 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 582/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1784 - val_accuracy: 0.9549 - val_precision_3: 0.9549 - val_recall_3: 0.9549\n",
      "Epoch 583/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8221 - precision_3: 0.8221 - recall_3: 0.8221 - val_loss: 0.1626 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 584/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8097 - precision_3: 0.8097 - recall_3: 0.8097 - val_loss: 0.1999 - val_accuracy: 0.9442 - val_precision_3: 0.9442 - val_recall_3: 0.9442\n",
      "Epoch 585/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7956 - precision_3: 0.7956 - recall_3: 0.7956 - val_loss: 0.1782 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 586/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.1659 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 587/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.8018 - precision_3: 0.8018 - recall_3: 0.8018 - val_loss: 0.1658 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 588/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1628 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 589/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1633 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 590/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4078 - accuracy: 0.8088 - precision_3: 0.8088 - recall_3: 0.8088 - val_loss: 0.1719 - val_accuracy: 0.9619 - val_precision_3: 0.9619 - val_recall_3: 0.9619\n",
      "Epoch 591/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8212 - precision_3: 0.8212 - recall_3: 0.8212 - val_loss: 0.1924 - val_accuracy: 0.9434 - val_precision_3: 0.9434 - val_recall_3: 0.9434\n",
      "Epoch 592/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1677 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 593/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1564 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 594/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8204 - precision_3: 0.8204 - recall_3: 0.8204 - val_loss: 0.1790 - val_accuracy: 0.9496 - val_precision_3: 0.9496 - val_recall_3: 0.9496\n",
      "Epoch 595/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1621 - val_accuracy: 0.9673 - val_precision_3: 0.9673 - val_recall_3: 0.9673\n",
      "Epoch 596/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.8372 - precision_3: 0.8372 - recall_3: 0.8372 - val_loss: 0.1620 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 597/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1666 - val_accuracy: 0.9593 - val_precision_3: 0.9593 - val_recall_3: 0.9593\n",
      "Epoch 598/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1637 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 599/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1506 - val_accuracy: 0.9717 - val_precision_3: 0.9717 - val_recall_3: 0.9717\n",
      "Epoch 600/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1684 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 601/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1424 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 602/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1523 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 603/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8274 - precision_3: 0.8274 - recall_3: 0.8274 - val_loss: 0.1529 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 604/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8274 - precision_3: 0.8274 - recall_3: 0.8274 - val_loss: 0.1565 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 605/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1448 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 606/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1578 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 607/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8142 - precision_3: 0.8142 - recall_3: 0.8142 - val_loss: 0.1609 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 608/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1860 - val_accuracy: 0.9496 - val_precision_3: 0.9496 - val_recall_3: 0.9496\n",
      "Epoch 609/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8257 - precision_3: 0.8257 - recall_3: 0.8257 - val_loss: 0.1572 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 610/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1562 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 611/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1405 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 612/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.1370 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 613/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1605 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 614/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8115 - precision_3: 0.8115 - recall_3: 0.8115 - val_loss: 0.1387 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 615/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4106 - accuracy: 0.8115 - precision_3: 0.8115 - recall_3: 0.8115 - val_loss: 0.1410 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 616/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1605 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 617/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8115 - precision_3: 0.8115 - recall_3: 0.8115 - val_loss: 0.1766 - val_accuracy: 0.9558 - val_precision_3: 0.9558 - val_recall_3: 0.9558\n",
      "Epoch 618/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8027 - precision_3: 0.8027 - recall_3: 0.8027 - val_loss: 0.1613 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 619/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1675 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 620/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1695 - val_accuracy: 0.9584 - val_precision_3: 0.9584 - val_recall_3: 0.9584\n",
      "Epoch 621/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1587 - val_accuracy: 0.9593 - val_precision_3: 0.9593 - val_recall_3: 0.9593\n",
      "Epoch 622/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8177 - precision_3: 0.8177 - recall_3: 0.8177 - val_loss: 0.1603 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 623/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1489 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 624/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1573 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 625/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8221 - precision_3: 0.8221 - recall_3: 0.8221 - val_loss: 0.1644 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 626/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8177 - precision_3: 0.8177 - recall_3: 0.8177 - val_loss: 0.1640 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 627/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8265 - precision_3: 0.8265 - recall_3: 0.8265 - val_loss: 0.1669 - val_accuracy: 0.9602 - val_precision_3: 0.9602 - val_recall_3: 0.9602\n",
      "Epoch 628/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8265 - precision_3: 0.8265 - recall_3: 0.8265 - val_loss: 0.1880 - val_accuracy: 0.9425 - val_precision_3: 0.9425 - val_recall_3: 0.9425\n",
      "Epoch 629/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.8027 - precision_3: 0.8027 - recall_3: 0.8027 - val_loss: 0.1685 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 630/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8159 - precision_3: 0.8159 - recall_3: 0.8159 - val_loss: 0.1471 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 631/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1775 - val_accuracy: 0.9540 - val_precision_3: 0.9540 - val_recall_3: 0.9540\n",
      "Epoch 632/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1475 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 633/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1530 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 634/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8372 - precision_3: 0.8372 - recall_3: 0.8372 - val_loss: 0.1588 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 635/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1696 - val_accuracy: 0.9593 - val_precision_3: 0.9593 - val_recall_3: 0.9593\n",
      "Epoch 636/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8248 - precision_3: 0.8248 - recall_3: 0.8248 - val_loss: 0.1502 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 637/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8221 - precision_3: 0.8221 - recall_3: 0.8221 - val_loss: 0.1577 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 638/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1533 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 639/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1441 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 640/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8381 - precision_3: 0.8381 - recall_3: 0.8381 - val_loss: 0.1394 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 641/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1413 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 642/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8221 - precision_3: 0.8221 - recall_3: 0.8221 - val_loss: 0.1321 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 643/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8124 - precision_3: 0.8124 - recall_3: 0.8124 - val_loss: 0.1447 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 644/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1401 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 645/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.1667 - val_accuracy: 0.9584 - val_precision_3: 0.9584 - val_recall_3: 0.9584\n",
      "Epoch 646/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8062 - precision_3: 0.8062 - recall_3: 0.8062 - val_loss: 0.1508 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 647/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3906 - accuracy: 0.8186 - precision_3: 0.8186 - recall_3: 0.8186 - val_loss: 0.1399 - val_accuracy: 0.9673 - val_precision_3: 0.9673 - val_recall_3: 0.9673\n",
      "Epoch 648/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8230 - precision_3: 0.8230 - recall_3: 0.8230 - val_loss: 0.1490 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 649/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7876 - precision_3: 0.7876 - recall_3: 0.7876 - val_loss: 0.1524 - val_accuracy: 0.9673 - val_precision_3: 0.9673 - val_recall_3: 0.9673\n",
      "Epoch 650/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8301 - precision_3: 0.8301 - recall_3: 0.8301 - val_loss: 0.1530 - val_accuracy: 0.9673 - val_precision_3: 0.9673 - val_recall_3: 0.9673\n",
      "Epoch 651/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8248 - precision_3: 0.8248 - recall_3: 0.8248 - val_loss: 0.1556 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 652/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.1289 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 653/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1230 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 654/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8301 - precision_3: 0.8301 - recall_3: 0.8301 - val_loss: 0.1308 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 655/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1436 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 656/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1335 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 657/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1510 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 658/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1593 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 659/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1527 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 660/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1200 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 661/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3892 - accuracy: 0.8363 - precision_3: 0.8363 - recall_3: 0.8363 - val_loss: 0.1280 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 662/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1559 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 663/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1340 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 664/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8265 - precision_3: 0.8265 - recall_3: 0.8265 - val_loss: 0.1398 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 665/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3632 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.1540 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 666/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8301 - precision_3: 0.8301 - recall_3: 0.8301 - val_loss: 0.1567 - val_accuracy: 0.9619 - val_precision_3: 0.9619 - val_recall_3: 0.9619\n",
      "Epoch 667/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8221 - precision_3: 0.8221 - recall_3: 0.8221 - val_loss: 0.1380 - val_accuracy: 0.9717 - val_precision_3: 0.9717 - val_recall_3: 0.9717\n",
      "Epoch 668/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1325 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 669/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8248 - precision_3: 0.8248 - recall_3: 0.8248 - val_loss: 0.1457 - val_accuracy: 0.9655 - val_precision_3: 0.9655 - val_recall_3: 0.9655\n",
      "Epoch 670/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.1496 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 671/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1449 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 672/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3657 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1437 - val_accuracy: 0.9752 - val_precision_3: 0.9752 - val_recall_3: 0.9752\n",
      "Epoch 673/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8496 - precision_3: 0.8496 - recall_3: 0.8496 - val_loss: 0.1430 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 674/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1577 - val_accuracy: 0.9637 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 675/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8363 - precision_3: 0.8363 - recall_3: 0.8363 - val_loss: 0.1560 - val_accuracy: 0.9646 - val_precision_3: 0.9646 - val_recall_3: 0.9646\n",
      "Epoch 676/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1377 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 677/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1280 - val_accuracy: 0.9752 - val_precision_3: 0.9752 - val_recall_3: 0.9752\n",
      "Epoch 678/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1358 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 679/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1155 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 680/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1181 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 681/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.1182 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 682/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3554 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1228 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 683/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8363 - precision_3: 0.8363 - recall_3: 0.8363 - val_loss: 0.1178 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 684/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.1241 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 685/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1166 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 686/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.1280 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 687/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1311 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 688/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1257 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 689/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3326 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.1232 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 690/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8212 - precision_3: 0.8212 - recall_3: 0.8212 - val_loss: 0.1236 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 691/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1340 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 692/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3682 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1518 - val_accuracy: 0.9602 - val_precision_3: 0.9602 - val_recall_3: 0.9602\n",
      "Epoch 693/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1401 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 694/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8257 - precision_3: 0.8257 - recall_3: 0.8257 - val_loss: 0.1363 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 695/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1329 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 696/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.1602 - val_accuracy: 0.9558 - val_precision_3: 0.9558 - val_recall_3: 0.9558\n",
      "Epoch 697/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8310 - precision_3: 0.8310 - recall_3: 0.8310 - val_loss: 0.1596 - val_accuracy: 0.9619 - val_precision_3: 0.9619 - val_recall_3: 0.9619\n",
      "Epoch 698/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1580 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 699/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1242 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 700/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1300 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 701/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1589 - val_accuracy: 0.9593 - val_precision_3: 0.9593 - val_recall_3: 0.9593\n",
      "Epoch 702/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.1410 - val_accuracy: 0.9611 - val_precision_3: 0.9611 - val_recall_3: 0.9611\n",
      "Epoch 703/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8319 - precision_3: 0.8319 - recall_3: 0.8319 - val_loss: 0.1335 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 704/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1302 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 705/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.1344 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 706/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8257 - precision_3: 0.8257 - recall_3: 0.8257 - val_loss: 0.1655 - val_accuracy: 0.9487 - val_precision_3: 0.9487 - val_recall_3: 0.9487\n",
      "Epoch 707/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1406 - val_accuracy: 0.9681 - val_precision_3: 0.9681 - val_recall_3: 0.9681\n",
      "Epoch 708/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8204 - precision_3: 0.8204 - recall_3: 0.8204 - val_loss: 0.1358 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 709/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1314 - val_accuracy: 0.9752 - val_precision_3: 0.9752 - val_recall_3: 0.9752\n",
      "Epoch 710/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.8212 - precision_3: 0.8212 - recall_3: 0.8212 - val_loss: 0.1306 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 711/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.1441 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 712/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8336 - precision_3: 0.8336 - recall_3: 0.8336 - val_loss: 0.1317 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 713/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8239 - precision_3: 0.8239 - recall_3: 0.8239 - val_loss: 0.1141 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 714/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8504 - precision_3: 0.8504 - recall_3: 0.8504 - val_loss: 0.1468 - val_accuracy: 0.9575 - val_precision_3: 0.9575 - val_recall_3: 0.9575\n",
      "Epoch 715/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1128 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 716/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1206 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 717/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8372 - precision_3: 0.8372 - recall_3: 0.8372 - val_loss: 0.1214 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 718/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3577 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.1069 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 719/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1145 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 720/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1182 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 721/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.1223 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 722/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.1177 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 723/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.1242 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 724/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8496 - precision_3: 0.8496 - recall_3: 0.8496 - val_loss: 0.1384 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 725/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.1269 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 726/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1340 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 727/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1333 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 728/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3227 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.1308 - val_accuracy: 0.9717 - val_precision_3: 0.9717 - val_recall_3: 0.9717\n",
      "Epoch 729/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.1206 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 730/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3484 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1167 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 731/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.1136 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 732/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3644 - accuracy: 0.8381 - precision_3: 0.8381 - recall_3: 0.8381 - val_loss: 0.1172 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 733/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.1077 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 734/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3262 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1147 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 735/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1073 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 736/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1135 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 737/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3453 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.1130 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 738/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8425 - precision_3: 0.8425 - recall_3: 0.8425 - val_loss: 0.1153 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 739/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1111 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 740/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3421 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1088 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 741/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1124 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 742/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1250 - val_accuracy: 0.9673 - val_precision_3: 0.9673 - val_recall_3: 0.9673\n",
      "Epoch 743/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.1052 - val_accuracy: 0.9938 - val_precision_3: 0.9938 - val_recall_3: 0.9938\n",
      "Epoch 744/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8425 - precision_3: 0.8425 - recall_3: 0.8425 - val_loss: 0.0991 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 745/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.0983 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 746/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1067 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 747/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3336 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.0982 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 748/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1017 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 749/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.0949 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 750/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.0928 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 751/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.1044 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 752/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3399 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0989 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 753/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.0939 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 754/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.0992 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 755/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0943 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 756/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1013 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 757/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1015 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 758/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3461 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.0996 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 759/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.0990 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 760/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8283 - precision_3: 0.8283 - recall_3: 0.8283 - val_loss: 0.1103 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 761/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.1151 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 762/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.1096 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 763/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8363 - precision_3: 0.8363 - recall_3: 0.8363 - val_loss: 0.1161 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 764/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8496 - precision_3: 0.8496 - recall_3: 0.8496 - val_loss: 0.1117 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 765/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1246 - val_accuracy: 0.9664 - val_precision_3: 0.9664 - val_recall_3: 0.9664\n",
      "Epoch 766/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8451 - precision_3: 0.8451 - recall_3: 0.8451 - val_loss: 0.1321 - val_accuracy: 0.9717 - val_precision_3: 0.9717 - val_recall_3: 0.9717\n",
      "Epoch 767/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.1255 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 768/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3693 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.1395 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 769/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8265 - precision_3: 0.8265 - recall_3: 0.8265 - val_loss: 0.1213 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 770/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.8584 - precision_3: 0.8584 - recall_3: 0.8584 - val_loss: 0.1263 - val_accuracy: 0.9761 - val_precision_3: 0.9761 - val_recall_3: 0.9761\n",
      "Epoch 771/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3614 - accuracy: 0.8425 - precision_3: 0.8425 - recall_3: 0.8425 - val_loss: 0.1277 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 772/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8381 - precision_3: 0.8381 - recall_3: 0.8381 - val_loss: 0.1056 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 773/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8274 - precision_3: 0.8274 - recall_3: 0.8274 - val_loss: 0.1020 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 774/2000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3774 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1159 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 775/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.1018 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 776/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8381 - precision_3: 0.8381 - recall_3: 0.8381 - val_loss: 0.1030 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 777/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8372 - precision_3: 0.8372 - recall_3: 0.8372 - val_loss: 0.1283 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 778/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3515 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1234 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 779/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.1082 - val_accuracy: 0.9752 - val_precision_3: 0.9752 - val_recall_3: 0.9752\n",
      "Epoch 780/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8292 - precision_3: 0.8292 - recall_3: 0.8292 - val_loss: 0.0995 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 781/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3511 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.1115 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 782/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3447 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1072 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 783/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.1187 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 784/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8434 - precision_3: 0.8434 - recall_3: 0.8434 - val_loss: 0.1419 - val_accuracy: 0.9628 - val_precision_3: 0.9628 - val_recall_3: 0.9628\n",
      "Epoch 785/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3313 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1248 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 786/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1300 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 787/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.1358 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 788/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1267 - val_accuracy: 0.9743 - val_precision_3: 0.9743 - val_recall_3: 0.9743\n",
      "Epoch 789/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.1251 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 790/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3425 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.1129 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 791/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8451 - precision_3: 0.8451 - recall_3: 0.8451 - val_loss: 0.1225 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 792/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1075 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 793/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3248 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0986 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 794/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.1038 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 795/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.0944 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 796/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.0942 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 797/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1158 - val_accuracy: 0.9708 - val_precision_3: 0.9708 - val_recall_3: 0.9708\n",
      "Epoch 798/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3692 - accuracy: 0.8504 - precision_3: 0.8504 - recall_3: 0.8504 - val_loss: 0.1018 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 799/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.0922 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 800/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.0930 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 801/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1028 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 802/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3070 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0976 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 803/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3196 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0861 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 804/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8504 - precision_3: 0.8504 - recall_3: 0.8504 - val_loss: 0.0848 - val_accuracy: 0.9929 - val_precision_3: 0.9929 - val_recall_3: 0.9929\n",
      "Epoch 805/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.8664 - precision_3: 0.8664 - recall_3: 0.8664 - val_loss: 0.0916 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 806/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.1039 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 807/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.0996 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 808/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1134 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 809/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.1009 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 810/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3456 - accuracy: 0.8425 - precision_3: 0.8425 - recall_3: 0.8425 - val_loss: 0.0928 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 811/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.1041 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 812/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0943 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 813/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.1030 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 814/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3430 - accuracy: 0.8673 - precision_3: 0.8673 - recall_3: 0.8673 - val_loss: 0.1059 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 815/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1132 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 816/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3255 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.1023 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 817/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.0898 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 818/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.0959 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 819/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3313 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.0909 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 820/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8327 - precision_3: 0.8327 - recall_3: 0.8327 - val_loss: 0.0949 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 821/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.1033 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 822/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3449 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.1095 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 823/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.1046 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 824/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3588 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.1065 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 825/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.1053 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 826/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8389 - precision_3: 0.8389 - recall_3: 0.8389 - val_loss: 0.0925 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 827/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8531 - precision_3: 0.8531 - recall_3: 0.8531 - val_loss: 0.0985 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 828/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3376 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.1110 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 829/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3241 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.1128 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 830/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3594 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1091 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 831/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3386 - accuracy: 0.8628 - precision_3: 0.8628 - recall_3: 0.8628 - val_loss: 0.0968 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 832/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3293 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1023 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 833/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.0876 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 834/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3586 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.0958 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 835/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3438 - accuracy: 0.8531 - precision_3: 0.8531 - recall_3: 0.8531 - val_loss: 0.0938 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 836/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8416 - precision_3: 0.8416 - recall_3: 0.8416 - val_loss: 0.0981 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 837/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.1064 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 838/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0954 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 839/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3376 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.1035 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 840/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3399 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.1085 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 841/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3434 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1036 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 842/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.0991 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 843/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3153 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.0967 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 844/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.0841 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 845/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.1088 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 846/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3188 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.1235 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 847/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1092 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 848/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0867 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 849/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.0976 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 850/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3151 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.0971 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 851/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3193 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.1053 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 852/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3470 - accuracy: 0.8752 - precision_3: 0.8752 - recall_3: 0.8752 - val_loss: 0.1164 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 853/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.0957 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 854/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3389 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.0956 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 855/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3317 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.1040 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 856/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3421 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.1012 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 857/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0929 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 858/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3132 - accuracy: 0.8735 - precision_3: 0.8735 - recall_3: 0.8735 - val_loss: 0.0919 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 859/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3226 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.1114 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 860/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3303 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.1189 - val_accuracy: 0.9779 - val_precision_3: 0.9779 - val_recall_3: 0.9779\n",
      "Epoch 861/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8407 - precision_3: 0.8407 - recall_3: 0.8407 - val_loss: 0.0922 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 862/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.1029 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 863/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8628 - precision_3: 0.8628 - recall_3: 0.8628 - val_loss: 0.1173 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 864/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3475 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.1097 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 865/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3245 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0853 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 866/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.1012 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 867/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3211 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0907 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 868/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3143 - accuracy: 0.8717 - precision_3: 0.8717 - recall_3: 0.8717 - val_loss: 0.0788 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 869/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.8681 - precision_3: 0.8681 - recall_3: 0.8681 - val_loss: 0.0917 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 870/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.1177 - val_accuracy: 0.9699 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 871/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3224 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.1058 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 872/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8398 - precision_3: 0.8398 - recall_3: 0.8398 - val_loss: 0.0940 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 873/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3528 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.0898 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 874/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.8628 - precision_3: 0.8628 - recall_3: 0.8628 - val_loss: 0.0933 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 875/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.8779 - precision_3: 0.8779 - recall_3: 0.8779 - val_loss: 0.1002 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 876/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3137 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0824 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 877/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.0931 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 878/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.0940 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 879/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3183 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.0837 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 880/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3171 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0937 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 881/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3457 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1288 - val_accuracy: 0.9690 - val_precision_3: 0.9690 - val_recall_3: 0.9690\n",
      "Epoch 882/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.8425 - precision_3: 0.8425 - recall_3: 0.8425 - val_loss: 0.0995 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 883/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0806 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 884/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.0973 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 885/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.0877 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 886/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8354 - precision_3: 0.8354 - recall_3: 0.8354 - val_loss: 0.0795 - val_accuracy: 0.9920 - val_precision_3: 0.9920 - val_recall_3: 0.9920\n",
      "Epoch 887/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0838 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 888/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0901 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 889/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8381 - precision_3: 0.8381 - recall_3: 0.8381 - val_loss: 0.0965 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 890/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8496 - precision_3: 0.8496 - recall_3: 0.8496 - val_loss: 0.0801 - val_accuracy: 0.9938 - val_precision_3: 0.9938 - val_recall_3: 0.9938\n",
      "Epoch 891/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3403 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0874 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 892/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0859 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 893/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8655 - precision_3: 0.8655 - recall_3: 0.8655 - val_loss: 0.1002 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 894/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0930 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 895/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0771 - val_accuracy: 0.9947 - val_precision_3: 0.9947 - val_recall_3: 0.9947\n",
      "Epoch 896/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8584 - precision_3: 0.8584 - recall_3: 0.8584 - val_loss: 0.0739 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 897/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3201 - accuracy: 0.8717 - precision_3: 0.8717 - recall_3: 0.8717 - val_loss: 0.0735 - val_accuracy: 0.9920 - val_precision_3: 0.9920 - val_recall_3: 0.9920\n",
      "Epoch 898/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3224 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0941 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 899/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0770 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 900/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3031 - accuracy: 0.8735 - precision_3: 0.8735 - recall_3: 0.8735 - val_loss: 0.0774 - val_accuracy: 0.9929 - val_precision_3: 0.9929 - val_recall_3: 0.9929\n",
      "Epoch 901/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0848 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 902/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.1056 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 903/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3130 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0947 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 904/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8496 - precision_3: 0.8496 - recall_3: 0.8496 - val_loss: 0.0875 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 905/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0850 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 906/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0786 - val_accuracy: 0.9920 - val_precision_3: 0.9920 - val_recall_3: 0.9920\n",
      "Epoch 907/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0698 - val_accuracy: 0.9965 - val_precision_3: 0.9965 - val_recall_3: 0.9965\n",
      "Epoch 908/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3392 - accuracy: 0.8478 - precision_3: 0.8478 - recall_3: 0.8478 - val_loss: 0.0884 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 909/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3104 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.0860 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 910/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.0807 - val_accuracy: 0.9947 - val_precision_3: 0.9947 - val_recall_3: 0.9947\n",
      "Epoch 911/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0804 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 912/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0965 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 913/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3510 - accuracy: 0.8345 - precision_3: 0.8345 - recall_3: 0.8345 - val_loss: 0.0829 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 914/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3187 - accuracy: 0.8655 - precision_3: 0.8655 - recall_3: 0.8655 - val_loss: 0.0828 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 915/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3182 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0983 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 916/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3191 - accuracy: 0.8717 - precision_3: 0.8717 - recall_3: 0.8717 - val_loss: 0.0819 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 917/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0810 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 918/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3443 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.0859 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 919/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2919 - accuracy: 0.8735 - precision_3: 0.8735 - recall_3: 0.8735 - val_loss: 0.0839 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 920/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.8726 - precision_3: 0.8726 - recall_3: 0.8726 - val_loss: 0.0748 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 921/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3144 - accuracy: 0.8788 - precision_3: 0.8788 - recall_3: 0.8788 - val_loss: 0.0765 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 922/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3297 - accuracy: 0.8540 - precision_3: 0.8540 - recall_3: 0.8540 - val_loss: 0.0752 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 923/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3110 - accuracy: 0.8743 - precision_3: 0.8743 - recall_3: 0.8743 - val_loss: 0.0851 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 924/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3700 - accuracy: 0.8451 - precision_3: 0.8451 - recall_3: 0.8451 - val_loss: 0.0827 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 925/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.8442 - precision_3: 0.8442 - recall_3: 0.8442 - val_loss: 0.0832 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 926/2000\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3505 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.0793 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 927/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3217 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.0932 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 928/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.8628 - precision_3: 0.8628 - recall_3: 0.8628 - val_loss: 0.1099 - val_accuracy: 0.9726 - val_precision_3: 0.9726 - val_recall_3: 0.9726\n",
      "Epoch 929/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8752 - precision_3: 0.8752 - recall_3: 0.8752 - val_loss: 0.0977 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 930/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3461 - accuracy: 0.8531 - precision_3: 0.8531 - recall_3: 0.8531 - val_loss: 0.0901 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 931/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.1028 - val_accuracy: 0.9788 - val_precision_3: 0.9788 - val_recall_3: 0.9788\n",
      "Epoch 932/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3416 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.0934 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 933/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2825 - accuracy: 0.8823 - precision_3: 0.8823 - recall_3: 0.8823 - val_loss: 0.0801 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 934/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3171 - accuracy: 0.8664 - precision_3: 0.8664 - recall_3: 0.8664 - val_loss: 0.0928 - val_accuracy: 0.9805 - val_precision_3: 0.9805 - val_recall_3: 0.9805\n",
      "Epoch 935/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0929 - val_accuracy: 0.9832 - val_precision_3: 0.9832 - val_recall_3: 0.9832\n",
      "Epoch 936/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.0898 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 937/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8522 - precision_3: 0.8522 - recall_3: 0.8522 - val_loss: 0.0806 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 938/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8655 - precision_3: 0.8655 - recall_3: 0.8655 - val_loss: 0.0835 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 939/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3238 - accuracy: 0.8664 - precision_3: 0.8664 - recall_3: 0.8664 - val_loss: 0.0760 - val_accuracy: 0.9929 - val_precision_3: 0.9929 - val_recall_3: 0.9929\n",
      "Epoch 940/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.2897 - accuracy: 0.8752 - precision_3: 0.8752 - recall_3: 0.8752 - val_loss: 0.0820 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 941/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0768 - val_accuracy: 0.9938 - val_precision_3: 0.9938 - val_recall_3: 0.9938\n",
      "Epoch 942/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3159 - accuracy: 0.8717 - precision_3: 0.8717 - recall_3: 0.8717 - val_loss: 0.0765 - val_accuracy: 0.9920 - val_precision_3: 0.9920 - val_recall_3: 0.9920\n",
      "Epoch 943/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3110 - accuracy: 0.8779 - precision_3: 0.8779 - recall_3: 0.8779 - val_loss: 0.0802 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 944/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3391 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0835 - val_accuracy: 0.9929 - val_precision_3: 0.9929 - val_recall_3: 0.9929\n",
      "Epoch 945/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3399 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0771 - val_accuracy: 0.9929 - val_precision_3: 0.9929 - val_recall_3: 0.9929\n",
      "Epoch 946/2000\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.0835 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 947/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.8584 - precision_3: 0.8584 - recall_3: 0.8584 - val_loss: 0.0694 - val_accuracy: 0.9947 - val_precision_3: 0.9947 - val_recall_3: 0.9947\n",
      "Epoch 948/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8593 - precision_3: 0.8593 - recall_3: 0.8593 - val_loss: 0.0814 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 949/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.1067 - val_accuracy: 0.9814 - val_precision_3: 0.9814 - val_recall_3: 0.9814\n",
      "Epoch 950/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3039 - accuracy: 0.8664 - precision_3: 0.8664 - recall_3: 0.8664 - val_loss: 0.0858 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 951/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3199 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.0785 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 952/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0764 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 953/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.8566 - precision_3: 0.8566 - recall_3: 0.8566 - val_loss: 0.0818 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 954/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3317 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0960 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 955/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.0826 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 956/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3138 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.0858 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 957/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3148 - accuracy: 0.8761 - precision_3: 0.8761 - recall_3: 0.8761 - val_loss: 0.0863 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 958/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0817 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 959/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3266 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0836 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 960/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.0900 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 961/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.8602 - precision_3: 0.8602 - recall_3: 0.8602 - val_loss: 0.0834 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 962/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3403 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0913 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 963/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3126 - accuracy: 0.8628 - precision_3: 0.8628 - recall_3: 0.8628 - val_loss: 0.0819 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 964/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3397 - accuracy: 0.8487 - precision_3: 0.8487 - recall_3: 0.8487 - val_loss: 0.1005 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 965/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.8673 - precision_3: 0.8673 - recall_3: 0.8673 - val_loss: 0.0927 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 966/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3200 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0884 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 967/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.8549 - precision_3: 0.8549 - recall_3: 0.8549 - val_loss: 0.0926 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 968/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3005 - accuracy: 0.8770 - precision_3: 0.8770 - recall_3: 0.8770 - val_loss: 0.0826 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 969/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3371 - accuracy: 0.8655 - precision_3: 0.8655 - recall_3: 0.8655 - val_loss: 0.0759 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 970/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3117 - accuracy: 0.8664 - precision_3: 0.8664 - recall_3: 0.8664 - val_loss: 0.0860 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 971/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8504 - precision_3: 0.8504 - recall_3: 0.8504 - val_loss: 0.0829 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 972/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3254 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0970 - val_accuracy: 0.9841 - val_precision_3: 0.9841 - val_recall_3: 0.9841\n",
      "Epoch 973/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3255 - accuracy: 0.8717 - precision_3: 0.8717 - recall_3: 0.8717 - val_loss: 0.0971 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 974/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3152 - accuracy: 0.8743 - precision_3: 0.8743 - recall_3: 0.8743 - val_loss: 0.0831 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 975/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3250 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0854 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 976/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8469 - precision_3: 0.8469 - recall_3: 0.8469 - val_loss: 0.1194 - val_accuracy: 0.9735 - val_precision_3: 0.9735 - val_recall_3: 0.9735\n",
      "Epoch 977/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0977 - val_accuracy: 0.9796 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 978/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3358 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.0762 - val_accuracy: 0.9867 - val_precision_3: 0.9867 - val_recall_3: 0.9867\n",
      "Epoch 979/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8655 - precision_3: 0.8655 - recall_3: 0.8655 - val_loss: 0.0793 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 980/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3351 - accuracy: 0.8558 - precision_3: 0.8558 - recall_3: 0.8558 - val_loss: 0.0778 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 981/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8513 - precision_3: 0.8513 - recall_3: 0.8513 - val_loss: 0.0823 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 982/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0720 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 983/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3057 - accuracy: 0.8770 - precision_3: 0.8770 - recall_3: 0.8770 - val_loss: 0.0733 - val_accuracy: 0.9912 - val_precision_3: 0.9912 - val_recall_3: 0.9912\n",
      "Epoch 984/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3160 - accuracy: 0.8611 - precision_3: 0.8611 - recall_3: 0.8611 - val_loss: 0.0770 - val_accuracy: 0.9903 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "Epoch 985/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3050 - accuracy: 0.8726 - precision_3: 0.8726 - recall_3: 0.8726 - val_loss: 0.0799 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 986/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3245 - accuracy: 0.8575 - precision_3: 0.8575 - recall_3: 0.8575 - val_loss: 0.0827 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 987/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0850 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 988/2000\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8619 - precision_3: 0.8619 - recall_3: 0.8619 - val_loss: 0.0796 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 989/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3127 - accuracy: 0.8708 - precision_3: 0.8708 - recall_3: 0.8708 - val_loss: 0.0999 - val_accuracy: 0.9823 - val_precision_3: 0.9823 - val_recall_3: 0.9823\n",
      "Epoch 990/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3312 - accuracy: 0.8646 - precision_3: 0.8646 - recall_3: 0.8646 - val_loss: 0.0997 - val_accuracy: 0.9770 - val_precision_3: 0.9770 - val_recall_3: 0.9770\n",
      "Epoch 991/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3570 - accuracy: 0.8460 - precision_3: 0.8460 - recall_3: 0.8460 - val_loss: 0.0897 - val_accuracy: 0.9850 - val_precision_3: 0.9850 - val_recall_3: 0.9850\n",
      "Epoch 992/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3394 - accuracy: 0.8637 - precision_3: 0.8637 - recall_3: 0.8637 - val_loss: 0.0804 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 993/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3090 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0734 - val_accuracy: 0.9885 - val_precision_3: 0.9885 - val_recall_3: 0.9885\n",
      "Epoch 994/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3125 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0795 - val_accuracy: 0.9876 - val_precision_3: 0.9876 - val_recall_3: 0.9876\n",
      "Epoch 995/2000\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.3151 - accuracy: 0.8690 - precision_3: 0.8690 - recall_3: 0.8690 - val_loss: 0.0773 - val_accuracy: 0.9858 - val_precision_3: 0.9858 - val_recall_3: 0.9858\n",
      "Epoch 996/2000\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.3090 - accuracy: 0.8699 - precision_3: 0.8699 - recall_3: 0.8699 - val_loss: 0.0751 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n",
      "Epoch 997/2000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.8841 - precision_3: 0.8841 - recall_3: 0.8841 - val_loss: 0.0762 - val_accuracy: 0.9894 - val_precision_3: 0.9894 - val_recall_3: 0.9894\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epochs = 2000\n",
    "n_random_search = 1\n",
    "\n",
    "batch_size = [128]\n",
    "n_layers = [1] \n",
    "cnn_dropout_p = [None, 0.2, 0.5]\n",
    "dense_dropout_p = [None, 0.2, 0.5]\n",
    "activation = ['tanh']\n",
    "n_dense_layers = [1,2,3]\n",
    "n_dense_neurons = [100]\n",
    "batch_normalization = [True]\n",
    "optimizer = [Adam(learning_rate=0.005, clipvalue=0.5)]\n",
    "#optimizer = [SGD(0.001)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, cnn_dropout_p, dense_dropout_p, activation, n_dense_layers, n_dense_neurons, batch_normalization, batch_size, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'tcn', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([508, 622]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([113, 206]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([80, 80]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 2, 'batch_size': 32, 'lstm_neurons': 500, 'n_dense_neurons': 1000, 'dropout': None, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7efd0cd56bd0>}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 31, 500)             1018000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, 500)                 2002000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 1000)                501000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, 2)                   2002      \n",
      "=================================================================\n",
      "Total params: 3,523,002\n",
      "Trainable params: 3,523,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "35/35 [==============================] - 15s 366ms/step - loss: 0.8825 - accuracy: 0.5384 - precision_1: 0.5384 - recall_1: 0.5384 - val_loss: 0.6895 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 12s 334ms/step - loss: 0.6920 - accuracy: 0.5223 - precision_1: 0.5223 - recall_1: 0.5223 - val_loss: 0.6872 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 11s 326ms/step - loss: 0.6891 - accuracy: 0.5518 - precision_1: 0.5518 - recall_1: 0.5518 - val_loss: 0.6861 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 11s 328ms/step - loss: 0.6886 - accuracy: 0.5491 - precision_1: 0.5491 - recall_1: 0.5491 - val_loss: 0.6852 - val_accuracy: 0.5536 - val_precision_1: 0.5536 - val_recall_1: 0.5536\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 12s 340ms/step - loss: 0.6920 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6878 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 12s 342ms/step - loss: 0.6859 - accuracy: 0.5500 - precision_1: 0.5500 - recall_1: 0.5500 - val_loss: 0.6799 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 11s 303ms/step - loss: 0.6887 - accuracy: 0.5420 - precision_1: 0.5420 - recall_1: 0.5420 - val_loss: 0.6863 - val_accuracy: 0.5527 - val_precision_1: 0.5527 - val_recall_1: 0.5527\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 10s 293ms/step - loss: 0.6943 - accuracy: 0.5562 - precision_1: 0.5562 - recall_1: 0.5562 - val_loss: 0.6869 - val_accuracy: 0.5616 - val_precision_1: 0.5616 - val_recall_1: 0.5616\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 10s 292ms/step - loss: 0.6885 - accuracy: 0.5402 - precision_1: 0.5402 - recall_1: 0.5402 - val_loss: 0.6789 - val_accuracy: 0.5670 - val_precision_1: 0.5670 - val_recall_1: 0.5670\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 10s 298ms/step - loss: 0.6859 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6802 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 11s 308ms/step - loss: 0.6861 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6693 - val_accuracy: 0.5804 - val_precision_1: 0.5804 - val_recall_1: 0.5804\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 11s 302ms/step - loss: 0.6808 - accuracy: 0.5607 - precision_1: 0.5607 - recall_1: 0.5607 - val_loss: 0.6824 - val_accuracy: 0.5589 - val_precision_1: 0.5589 - val_recall_1: 0.5589\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 10s 294ms/step - loss: 0.6851 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6770 - val_accuracy: 0.5598 - val_precision_1: 0.5598 - val_recall_1: 0.5598\n",
      "Epoch 14/500\n",
      "16/35 [============>.................] - ETA: 4s - loss: 0.6842 - accuracy: 0.5586 - precision_1: 0.5586 - recall_1: 0.5586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-191f5e051644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n\u001b[0;32m---> 17\u001b[0;31m                            model_randomgs_params, 'lstm', flush=True, save_plot=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_gs_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreproducible_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36mperform_gs_training\u001b[0;34m(self, model_fn, checkpoint_filepath)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                                           \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                                                           checkpoint_callback],\n\u001b[0;32m--> 247\u001b[0;31m                                              epochs=self.max_epochs, verbose=1)\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 500\n",
    "n_random_search = 1\n",
    "\n",
    "n_layers = [2]\n",
    "batch_size = [32]\n",
    "lstm_neurons = [100, 500, 1000]\n",
    "n_dense_neurons = [100, 500, 1000]\n",
    "dropout = [None, 0.2, 0.5, 0.8]\n",
    "optimizer = [Adam(learning_rate=0.01, clipvalue=0.5)]\n",
    "#optimizer = [SGD(learning_rate=0.01)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, batch_size, lstm_neurons, n_dense_neurons, dropout, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'lstm', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
