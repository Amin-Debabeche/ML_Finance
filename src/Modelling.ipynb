{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "import pickle as pkl\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "\n",
    "RANDOM_SEED = 7\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "INTERM_DIR = '../compiled_data'\n",
    "TRAIN_DATA_PATH = os.path.join(INTERM_DIR, 'train_data.pkl')\n",
    "MODEL_DIR = './models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_tcn, build_lstm\n",
    "\n",
    "class PerformTraining:\n",
    "    \n",
    "    \"\"\"\n",
    "    This class performs the training of the desired model\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    seed : int\n",
    "        the integer of the seed utilised for reproducibility \n",
    "    TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "    INTERM_DATA_DIR : str\n",
    "        a string indicating the directory containing intermediate computed data\n",
    "    MODEL_DIR : str\n",
    "        a string indicating the directory containing created models\n",
    "    model_gs_params : dict\n",
    "        a dictionary of preprocessing parameters\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    reproducible_results()\n",
    "        Sets seed and ensures all deterministic operations are reproducible\n",
    "    retrieve_data()\n",
    "        Retrieves the data given the data directory and folders\n",
    "    prepare_data(preprocessing_params, tuning=True):\n",
    "        Combines the preprocessing methods and splits the data for training \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot):\n",
    "        \n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        TRAIN_DATA_PATH : str\n",
    "            a string indicating the directory containing preprocessed data split\n",
    "            into train, val and test sets\n",
    "        INTERM_DATA_DIR : str\n",
    "            a string indicating the directory containing intermediate computed data\n",
    "        MODEL_DIR : str\n",
    "            a string indicating the directory containing created models\n",
    "        model_gs_params : list of lists\n",
    "            a list of lists containing the parameters for model training\n",
    "        \"\"\"\n",
    "\n",
    "        self.seed = 7\n",
    "\n",
    "        self.TRAIN_DATA_PATH = TRAIN_DATA_PATH\n",
    "        self.INTERM_DATA_DIR = INTERM_DATA_DIR\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.model_gs_params = model_gs_params\n",
    "        self.max_epochs = epochs\n",
    "        self.model_type = model_type\n",
    "        self.flush = flush\n",
    "        self.save_plot = save_plot\n",
    "        \n",
    "        with open(TRAIN_DATA_PATH, 'rb') as f:\n",
    "            self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = pkl.load(f)\n",
    "            \n",
    "        # random shuffle dataset\n",
    "        p = np.random.permutation(len(self.X_train))\n",
    "        self.X_train, self.y_train = self.X_train[p], self.y_train[p]\n",
    "            \n",
    "        print(f\"The class distributions in the training set are: {np.unique(self.y_train, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the validation set are: {np.unique(self.y_val, return_counts=True)}\")\n",
    "        print(f\"The class distributions in the test set are: {np.unique(self.y_test, return_counts=True)}\")\n",
    "\n",
    "        self.y_train, self.y_val, self.y_test = keras.utils.to_categorical(self.y_train), keras.utils.to_categorical(self.y_val), keras.utils.to_categorical(self.y_test)\n",
    "        \n",
    "        self.reproducible_results()\n",
    "#         self.X_train, self.X_val, self.X_test = self.X_train[:,:,:12], self.X_val[:,:,:12], self.X_test[:,:,:12]\n",
    "#         sample_mean = np.mean(self.X_train, axis=0)\n",
    "#         sample_std = np.mean(self.X_train, axis=0)\n",
    "#         self.X_train = (self.X_train - sample_mean) / sample_std\n",
    "#         self.X_val = (self.X_val - sample_mean) / sample_std\n",
    "#         self.X_test = (self.X_test - sample_mean) / sample_std\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "            self.perform_gs_training(build_tcn, os.path.join(self.MODEL_DIR, 'tcn'))\n",
    "            \n",
    "        if self.model_type == 'lstm':\n",
    "            self.perform_gs_training(build_lstm, os.path.join(self.MODEL_DIR, 'lstm'))\n",
    "\n",
    "    def reproducible_results(self):\n",
    "\n",
    "        \"\"\"Obtain reproducible results with keras, source: https://stackoverflow.com/a/52897216\"\"\"\n",
    "\n",
    "        # 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "        os.environ['PYTHONHASHSEED'] = str(self.seed)\n",
    "\n",
    "        # 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "        random.seed(self.seed)\n",
    "\n",
    "        # 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        # 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "        tf.compat.v1.set_random_seed(self.seed)\n",
    "\n",
    "        # 5. Configure a new global `tensorflow` session\n",
    "        session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "        sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "        K.set_session(sess)\n",
    "\n",
    "    def plot_confusion_matrix(self, confusion_matrix, title, save_plot_dir):\n",
    "        \"\"\"Plots a given confusion matrix and saves it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        confusion_matrix : ndarray\n",
    "            a numpy array of the confusion matrix\n",
    "        title : str\n",
    "            a string of the title name\n",
    "        save_plot_dir : str\n",
    "            a string of where to save the plot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (ndarray, ndarray)\n",
    "            a tuple of the numpy arrays of the upsampled feature and label arrays\n",
    "        \"\"\"  \n",
    "        # Plot confusion matrix\n",
    "        labels = np.unique(self.y_train)\n",
    "        df_cm = pd.DataFrame(confusion_matrix, index = [i for i in np.unique(self.y_train)], columns = [i for i in np.unique(self.y_train)])\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sn.heatmap(df_cm, annot=True)\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title(title, ha=\"center\")\n",
    "        plt.xticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        plt.yticks(np.arange(0.5, len(labels) + 0.5, 1), labels, rotation='horizontal')\n",
    "        if save_plot_dir is not None: \n",
    "            plt.savefig(f'{save_plot_dir}.pdf', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def model_param_setup(self, params):\n",
    "        \"\"\"Retrieve from a given ordered list the correct parameters depending on model type\"\"\"\n",
    "        \n",
    "        if self.model_type == 'tcn':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'cnn_dropout_p' : params[1], \n",
    "                            'dense_dropout_p' : params[2], \n",
    "                            'activation' : params[3], \n",
    "                            'n_dense_layers' : params[4], \n",
    "                            'n_dense_neurons' : params[5], \n",
    "                            'batch_normalization' : params[6], \n",
    "                            'batch_size' : params[7],\n",
    "                            'optimizer' : params[8]}\n",
    "\n",
    "        if self.model_type == 'lstm':\n",
    "\n",
    "            model_params = {'n_layers' : params[0], \n",
    "                            'batch_size' : params[1],\n",
    "                            'lstm_neurons' : params[2], \n",
    "                            'n_dense_neurons' : params[3], \n",
    "                            'dropout' : params[4], \n",
    "                            'optimizer' : params[5]}\n",
    "\n",
    "        return model_params    \n",
    "    \n",
    "    \n",
    "    def perform_gs_training(self, model_fn, checkpoint_filepath):\n",
    "\n",
    "        \"\"\"Performs cross-validated grid search training for selected model function\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_fn : function\n",
    "            a function which creates a keras compiled model\n",
    "        checkpoint_filepath : str\n",
    "            a string indicating where to save the plots and grid search results \n",
    "            of the cross-validated grid search\n",
    "        Returns\n",
    "        -------\n",
    "        pandas.DataFrame\n",
    "            a pandas dataframe containing the results of the grid search, \n",
    "            specifically average performance for given hyperparameters\n",
    "        \"\"\"  \n",
    "\n",
    "        pkl_name = os.path.join(checkpoint_filepath, 'gs_res.pkl')\n",
    "        if os.path.isfile(pkl_name) and self.flush==False:\n",
    "            with open(pkl_name, 'rb') as f:\n",
    "                gs_res = pkl.load(f)\n",
    "        else: \n",
    "            gs_res = []\n",
    "\n",
    "        for idx, params in enumerate(self.model_gs_params): \n",
    "\n",
    "            print(\"=================================================\")\n",
    "            print(\"Presenting Results for: %s/%s Hyperparameter Combination\" % (idx+1, len(self.model_gs_params)))\n",
    "\n",
    "            model_params = self.model_param_setup(params)\n",
    "            print(model_params)\n",
    "\n",
    "            batch_size = model_params['batch_size']\n",
    "\n",
    "            # Create backlog for accuracy in each fold\n",
    "            val_fold_accuracy = []\n",
    "            test_fold_accuracy = []\n",
    "\n",
    "            try:     \n",
    "\n",
    "                # Prepare the training dataset\n",
    "                train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
    "                train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "\n",
    "                # Prepare the validation dataset\n",
    "                val_dataset = tf.data.Dataset.from_tensor_slices((self.X_val, self.y_val))\n",
    "                val_dataset = val_dataset.shuffle(buffer_size = 1024).batch(batch_size)\n",
    "                \n",
    "                if self.model_type == 'lstm':\n",
    "                    # In stateful lstm, need to have full batches, i.e. a dataset size divisible by batch_size\n",
    "                    rem_last_n_train = (self.X_train.shape[0] % batch_size)\n",
    "                    if rem_last_n_train > 0:\n",
    "                        self.X_train, self.y_train = self.X_train[:-rem_last_n_train], self.y_train[:-rem_last_n_train]\n",
    "\n",
    "                    rem_last_n_val = (self.X_val.shape[0] % batch_size)\n",
    "                    if rem_last_n_val > 0:\n",
    "                        self.X_val, self.y_val = self.X_val[:-rem_last_n_val], self.y_val[:-rem_last_n_val]\n",
    "                    \n",
    "                    rem_last_n_test = (self.X_test.shape[0] % batch_size)\n",
    "                    if rem_last_n_test > 0:\n",
    "                        self.X_test, self.y_test = self.X_test[:-rem_last_n_test], self.y_test[:-rem_last_n_test]\n",
    "                    \n",
    "                model = model_fn(self.X_train, **model_params)\n",
    "\n",
    "                # Create Tensorboard\n",
    "                logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch', profile_batch=0)\n",
    "                # Model Checkpoint Callback\n",
    "                checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(checkpoint_filepath,'checkpoint'), save_weights_only=True, monitor='val_loss', mode='min', save_best_only=True)\n",
    "                # Early Stopping Callback\n",
    "                early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 50)\n",
    "\n",
    "                # Train the model\n",
    "                training_history = model.fit(self.X_train, self.y_train, batch_size=batch_size, validation_data=(self.X_train, self.y_train),\n",
    "                                             steps_per_epoch = self.X_train.shape[0] // batch_size if self.model_type == 'lstm' else None, \n",
    "                                             callbacks = [tensorboard_callback,\n",
    "                                                          early_stopping_callback,\n",
    "                                                          checkpoint_callback],\n",
    "                                             epochs=self.max_epochs, verbose=1)\n",
    "                \n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "            try: \n",
    "\n",
    "                # Compute confusion matrix across validation folds, and the test set\n",
    "                def compute_confusion_matrix(set_to_predict, true_values, model):\n",
    "                    y_predicted = model.predict(set_to_predict)\n",
    "                    class_pred = np.argmax(y_predicted,axis = 1)\n",
    "                    class_true = np.argmax(true_values,axis = 1)\n",
    "                    res = metrics.confusion_matrix(class_true, class_pred)\n",
    "                    perc_acc = res / res.sum(axis=0)\n",
    "                    return perc_acc\n",
    "\n",
    "                test_accuracy = compute_confusion_matrix(self.X_test, self.y_test, model)\n",
    "                val_accuracy = compute_confusion_matrix(self.X_val, self.y_val, model)\n",
    "                \n",
    "                if self.save_plot == True: \n",
    "                    string_model_params = model_params\n",
    "                    del string_model_params['optimizer']\n",
    "                    string_model_params['learning_rate'] = K.eval(model.optimizer.lr)\n",
    "\n",
    "                    string_model_params = [str(x) for x in [*string_model_params.values()]]\n",
    "                    save_plot_dir = os.path.join(checkpoint_filepath, 'plots')\n",
    "                    save_plot_val_dir = os.path.join(save_plot_dir, 'Val CM ' + ' '.join(string_model_params))\n",
    "                    save_plot_test_dir = os.path.join(save_plot_dir, 'Test CM ' + ' '.join(string_model_params))\n",
    "                else: \n",
    "                    save_plot_val_dir = None\n",
    "                    save_plot_test_dir = None\n",
    "\n",
    "                self.plot_confusion_matrix(test_accuracy, 'Validation Dataset Accuracy', save_plot_val_dir)    \n",
    "                self.plot_confusion_matrix(val_accuracy, 'Test Validation Dataset Accuracy', save_plot_test_dir)    \n",
    "\n",
    "                curr_gs_res = [model_params, self.model_type, test_accuracy.diagonal(), val_accuracy.diagonal()]\n",
    "                gs_res.append(curr_gs_res)\n",
    "                with open(pkl_name, 'wb') as f:\n",
    "                    pkl.dump(gs_res, f)\n",
    "\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "\n",
    "        return gs_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([508, 622]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([113, 206]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([80, 80]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 1, 'cnn_dropout_p': 0.5, 'dense_dropout_p': 0.2, 'activation': 'relu', 'n_dense_layers': 2, 'n_dense_neurons': 500, 'batch_normalization': True, 'batch_size': 32, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7efc8c3d4250>}\n",
      "Epoch 1/5000\n",
      "36/36 [==============================] - 1s 12ms/step - loss: 0.7471 - accuracy: 0.5150 - precision: 0.5150 - recall: 0.5150 - val_loss: 0.6912 - val_accuracy: 0.5496 - val_precision: 0.5496 - val_recall: 0.5496\n",
      "Epoch 2/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5487 - precision: 0.5487 - recall: 0.5487 - val_loss: 0.6889 - val_accuracy: 0.5496 - val_precision: 0.5496 - val_recall: 0.5496\n",
      "Epoch 3/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5531 - precision: 0.5531 - recall: 0.5531 - val_loss: 0.6886 - val_accuracy: 0.5522 - val_precision: 0.5522 - val_recall: 0.5522\n",
      "Epoch 4/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5531 - precision: 0.5531 - recall: 0.5531 - val_loss: 0.6880 - val_accuracy: 0.5487 - val_precision: 0.5487 - val_recall: 0.5487\n",
      "Epoch 5/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5469 - precision: 0.5469 - recall: 0.5469 - val_loss: 0.6882 - val_accuracy: 0.5460 - val_precision: 0.5460 - val_recall: 0.5460\n",
      "Epoch 6/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5460 - precision: 0.5460 - recall: 0.5460 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 7/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5451 - precision: 0.5451 - recall: 0.5451 - val_loss: 0.6882 - val_accuracy: 0.5496 - val_precision: 0.5496 - val_recall: 0.5496\n",
      "Epoch 8/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6879 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 9/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6887 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 10/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 11/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 12/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 13/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 14/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - val_loss: 0.6886 - val_accuracy: 0.5487 - val_precision: 0.5487 - val_recall: 0.5487\n",
      "Epoch 15/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5478 - precision: 0.5478 - recall: 0.5478 - val_loss: 0.6887 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 16/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5540 - precision: 0.5540 - recall: 0.5540 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 17/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5513 - precision: 0.5513 - recall: 0.5513 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 18/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 19/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6888 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 20/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 21/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 22/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 23/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 24/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6884 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 25/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 26/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6882 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 27/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 28/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6885 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 29/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 30/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 31/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 32/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 33/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 34/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 35/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6881 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 36/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 37/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 38/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 39/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 40/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 41/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 42/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 43/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 44/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 45/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 46/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 47/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6880 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 48/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 49/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 50/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 51/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5292 - precision: 0.5292 - recall: 0.5292 - val_loss: 0.6886 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 52/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 53/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 54/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 55/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 56/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.5496 - precision: 0.5496 - recall: 0.5496 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 57/5000\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n",
      "Epoch 58/5000\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5504 - precision: 0.5504 - recall: 0.5504 - val_loss: 0.6881 - val_accuracy: 0.5504 - val_precision: 0.5504 - val_recall: 0.5504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamran/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:261: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/kamran/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:261: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAG5CAYAAABlWIVSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5hlZXnn/e+vGxoUDyBohKbVjqKOGhWVjsmrhmhE0IQe4iFgguAhHeMQdDKaIXkZNTjJRCeJThQnbzNBQRRRI7GNJAgmHgPaLcMhoEiLKE0DAk2jgtB01/3+sVft2hRV1dVYVbv2Wt+P17qudXjWep69+yr3zX0/a61UFZIkSW23ZNgDkCRJWggGPZIkqRMMeiRJUicY9EiSpE4w6JEkSZ1g0CNJkjrBoEeaQpLHJakkuzXb/5TkuNm0fQB9/UmS//OzjFeStHMGPWqlJOcnOWWK/auT3LSrAUpVHVFVZ8zBuA5NsmnStf+8qt7ws157ir6OT7IjyU+a5XtJPpTkibtwjQ8n+e9zPbYH2k96rk1y1XyPSVL7GPSorT4MHJskk/YfC3y0qrYv/JCG4qKqegjwcODXgJ8C30zytOEO6wF7AfAo4OeTHLKQHT/QTJ6kxcOgR231D8AjgOeP70iyD/DrwJnN9suS/N8kP0pyfZJ3TnexJF9M8oZmfWmSv0xya5JrgZdNavvaJN9K8uMmK/F7zf69gH8CDhjIvhyQ5J1Jzho4/8gkVybZ2vT7HwaOXZfkrUkuT3JHknOS7LmzL6OqdlTVd6vqTcCXgP5nTfLJJvt1R5IvJ3lqs38N8NvAHzVj/Wyz/6Qk320+31VJjhq41hOSfKm51q1Jzhk49uQkFyTZkuTqJK+aqZ9pHAd8BjivWR/83h/RZLI2J7k9yT8MHFud5NLm3/q7SQ4f+D5/baBd/99ioGz5+iQ/AP5lpu+rOfagJH+V5PvN8a82+z6X5A8mjffyJP9xhs8qaY4Z9KiVquqnwCeA1wzsfhXw7aq6rNm+szm+N73A5fdn+SP0u/SCp4OB5wCvmHT8h83xhwGvBd6b5FlVdSdwBLC5qh7SLJsHT2xKT2cDbwEeSe/H/bNJlk36HIcDK4GnA8fPYsyDPs1AMEgvEDuIXgblEuCjAFW1tll/TzPW32jaf7c5/+HAnwJnJdm/OfYu4PPAPsCBwPubz7UXcAHwsaafY4APJnnqDP3cR5IH0/uuP9osR0/6Xj4CPBh4atPHe5vzVtELdN9G79/6BcB1s/+6+BXgPwAvmen7avwl8Gzgl+kF3X8EjAFnAL8z8FmeASyn9+8raYEY9KjNzgBemeRBzfZrmn0AVNUXq+qKqhqrqsvpBRu/Movrvgp4X1VdX1VbgP8xeLCqPtdkVaqqvkQvCHj+VBeawm8Bn6uqC6rqXno/og+i9yM67m+qanPT92eBZ87y2uM20/tBHh/v6VX146q6h14G6BlJHj7dyVX1yab/sao6B7gGWNUcvhd4LHBAVd1dVV9t9v86cF1VfaiqtlfVJcDfc/+AcSa/CdxD7/v8R2A3mixbE3QdAbyxqm6vqnub7x7g9cDpzXc6VlU3VNW3d6Hfd1bVnU0gPe33lWQJ8DrgzU0fO6rq35p2nwEOSnJQc81jgXOqatsujEPSz8igR63V/ODeAqxO8vPAIfQyDQAk+cUk/5rkliR3AG8E9pvFpQ8Arh/Y/v7gwSRHJLm4KeNsBV46y+uOX7t/vaoaa/paPtDmpoH1u4CHzPLa45YDW5qxLk3yF03J50dMZECmHW+S1zSloq3N53vaQPs/AgJ8oynRva7Z/1jgF8fPac77beDRuzDu44BPNEHTPfQyVuMlrhXAlqq6fYrzVtDLTj1Q/X/rnXxf+wF7TtVXM95PAL/TBEfH0MtMSVpATsxT251JL8PzJODzVXXzwLGPAR8Ajqiqu5O8j9kFJzfS+yEd95jxlSR70MtgvAb4TFXd28wtGZ9QXTu59mbgFwaul6avG2Yxrtk6CvhKs/5qYDW9Sc7X0StZ3c40403yWOA04EX0JknvSHLpePuquole+Y8kzwMuTPJleoHDl6rqxdOMacbvJcmBwAuBVUle3ux+MLBnkv2a6z8iyd5VtXXS6dcDj5/m0nc21xk3VRA2OLaZvq9bgbubvi7j/s6gF+h8Fbirqi6aZkyS5omZHrXdmfR+oH6XgdJW46H0sgN3N/M+Xj3La34CODHJgelNjj5p4NgyYA96GabtSY4ADhs4fjOw7wzlo08AL0vyoiS7A/+FXknn32Y5tik1GYqVSd4PHEpvLg70voN7gNvo/fj/+aRTbwZ+fmB7L3pBwC3NdV9LL9Mz3s8rmwAFesFAATvolaOemOTYJLs3yyGZmKQ9uZ/JjgW+Qy94fWazPBHYBBxTVTfSm2vzwST7NNd/QXPu3wGvbb7TJUmWJ3lyc+xSenODdk8y1fysyab9vpqs3OnAX6c3QX1pkl9qAmGaIGcM+CvM8khDYdCjVquq6+gFDHsB6yYdfhNwSpIfA2+nF3DMxmnA+fT+a/4SemWW8f5+DJzYXOt2eoHUuoHj36Y3d+japsxzwKTxXk1vwuv76WUOfgP4jZ9h7scvJfkJ8CPgi/QmVx9SVVc0x8+kV067AbgKuHjS+X8HPKUZ6z9U1VX0frQvoheo/ALwtYH2hwBfb/pcR29+y/ea7+Uw4Gh62aybgHfTCxDv188Un+M44INVddPgAvwtEyWuY+nNKfo2vcnkbwGoqm/QTCgH7qB399pjm3P+G73MzO30AsF++XMaO/u+3gpcAaynV0J8N/f9/9kz6X1nZyFpwaVqZ9l2SdJcSPIaYE1VPW/YY5G6yEyPJC2A5pb7NwFrhz0WqasMeiRpniV5Cb15UDez8xKapHlieUuSJHWCmR5JktQJo/icHlNT0hCsX37UzhtJmnOH3HDu5Bcnz6t7b712zn5nd9/v5xd07DtjpkeSJHXCKGZ6JEnSfBnbMewRzBszPZIkqRPM9EiSpAk1NuwRzBuDHkmSNGGsvUGP5S1JktQJZnokSVJfWd6SJEmdYHlLkiRptJnpkSRJEyxvSZKkTvDhhJIkSaPNTI8kSZpgeUuSJHWCd29JkiSNNjM9kiSpz4cTSpKkbrC8JUmSNNrM9EiSpAmWtyRJUif4cEJJkqTRZqZHkiRNsLwlSZI6wbu3JEmSRpuZHkmSNMHyliRJ6gTLW5IkSaPNTI8kSeqrau9zegx6JEnShBbP6bG8JUmSOsFMjyRJmtDiicwGPZIkaUKLy1sGPZIkaYIvHJUkSRptBj2SJGlCjc3dMgtJDk9ydZKNSU6a4vjxSW5JcmmzvGHS8YcluSHJB3bWl+UtSZI0YQEnMidZCpwKvBjYBKxPsq6qrprU9JyqOmGay7wL+NJs+jPTI0mShmUVsLGqrq2qbcDHgdWzPTnJs4GfAz4/m/YGPZIkacIclreSrEmyYWBZM6m35cD1A9ubmn2TvTzJ5Uk+lWQFQJIlwF8Bb5vtR7O8JUmSJsxheauq1gJrZ2iSqU6btP1Z4OyquifJG4EzgBcCbwLOq6rrk6kuc38GPZIkaVg2ASsGtg8ENg82qKrbBjZPA97drP8S8PwkbwIeAixL8pOqut9k6HEGPZIkacLCPpF5PXBQkpXADcDRwKsHGyTZv6pubDaPBL4FUFW/PdDmeOA5MwU8YNAjSZIGLORb1qtqe5ITgPOBpcDpVXVlklOADVW1DjgxyZHAdmALcPwD7S9Vk0tni97IDVhqg/XLjxr2EKROOuSGc2c3YWWO/PTLH56z39kHveD4BR37zpjpkSRJE3zhqCRJ6oQWv3DU5/RIkqROMNMjSZImWN6SJEmdYHlLkiRptJnpkSRJEyxvSZKkTrC8JUmSNNrM9EiSpAmWtyRJUie0OOixvCVJkjrBTI8kSZrQ4onMBj2SJGmC5S1JkqTRZqZHkiRNsLwlSZI6wfKWJEnSaDPTI0mSJljekiRJnWB5S5IkabSZ6ZEkSRNanOkx6JEkSROqhj2CeWN5S5IkdYKZHkmSNMHyliRJ6oQWBz2WtyRJUieY6ZEkSRN8OKEkSeoEy1uSJEmjzUyPJEma0OLn9Bj0SJKkCZa3JEmSRpuZHkmSNKHFmR6DHkmSNKHFt6xb3pIkSZ1gpkeSJPXVmHdvSZKkLmjxnB7LW5IkqRPM9EiSpAktnshs0CNJkia0eE6P5S1JktQJZnokSdKEFk9kNuiRJEkTDHokSVIntPgt687pkSRJnWCmR5IkTbC8JUkaBQ879GAec8rryZIl3HL2hdx06qfvc3zfV/0qK04+jntv2gLAzR86j1vPvnAYQ9Vi1eJb1uc16ElyOPC/gKXA/6mqv5h0fA/gTODZwG3Ab1XVdfM5JklqrSVLeOyfreE7x7yTbTfexlPOew9bP/8N7r5m032abVn3NX5w8mlDGqQ0PPM2pyfJUuBU4AjgKcAxSZ4yqdnrgdur6gnAe4F3z9d4JKnt9jr4IO657kbu+cHN1L3b2fKZr7LPS1YNe1gaNTU2d8siM58TmVcBG6vq2qraBnwcWD2pzWrgjGb9U8CLkmQexyRJrbXs0Y9g2+Zb+9vbbryN3R+97/3a7fPS5/LUC97L49e+jWUH3P+4Om6s5m5ZZOYz6FkOXD+wvanZN2WbqtoO3AHc7y8wyZokG5JsWLt27TwNV5JG3FT/zTjp9uOtF2zg8uf+Hle++D/zo69czsr3vXmBBicN33zO6ZkqYzM57JtNG6pqLbB2uuOSpF5mZ9kB+/W3l+2/L/fevOU+bXbc/uP++i0fvYAD/+TYBRufRkO1+O6t+cz0bAJWDGwfCGyerk2S3YCHA1uQJO2yOy+9hj1W7s+yFY8iu+/GI1Y/j9s/v/4+bXZ/1D799b0PO4S7N26afBl1XYvLW/OZ6VkPHJRkJXADcDTw6klt1gHHARcBrwD+parFj4KUpPm0Y4wfnHwaT/rYO2DJEm495wvc/Z3rOeCtx3DXZRvZesF6fu51L2Pvww6hduxg+9af8L23vH/Yo5YWTOYzxkjyUuB99G5ZP72q/izJKcCGqlqXZE/gI8DB9DI8R1fVtTu5rEGRNATrlx817CFInXTIDecu6A0+d/7335mz39m9Tj5rUd2cNK/P6amq84DzJu17+8D63cAr53MMkiRpFyzCstRc8d1bkiSpE3wNhSRJmtDiu7cMeiRJ0gTLW5IkSaPNTI8kSZqwCN+ZNVcMeiRJ0gTLW5IkSaPNTI8kSepr87u3DHokSdIEy1uSJEmjzaBHkiRNWOC3rCc5PMnVSTYmOWmK48cnuSXJpc3yhmb/M5NclOTKJJcn+a2d9WV5S5IkTVjAW9aTLAVOBV4MbALWJ1lXVVdNanpOVZ0wad9dwGuq6pokBwDfTHJ+VW2drj8zPZIkaVhWARur6tqq2gZ8HFg9mxOr6jtVdU2zvhn4IfDImc4x6JEkSRPmsLyVZE2SDQPLmkm9LQeuH9je1Oyb7OVNCetTSVZMPphkFbAM+O5MH83yliRJ6qs5vHurqtYCa2dokqlOm7T9WeDsqronyRuBM4AX9i+Q7A98BDiuaubanJkeSZI0LJuAwczNgcDmwQZVdVtV3dNsngY8e/xYkocBnwNOrqqLd9aZQY8kSZqwsHdvrQcOSrIyyTLgaGDdYIMmkzPuSOBbzf5lwLnAmVX1ydl0ZnlLkiRNWMAnMlfV9iQnAOcDS4HTq+rKJKcAG6pqHXBikiOB7cAW4Pjm9FcBLwD2TTK+7/iqunS6/gx6JEnS0FTVecB5k/a9fWD9j4E/nuK8s4CzdqUvgx5JkjShxa+hMOiRJEkTWhz0OJFZkiR1gpkeSZLUV9XeTI9BjyRJmmB5S5IkabSZ6ZEkSRNanOkx6JEkSX1z+e6txcbyliRJ6gQzPZIkaUKLMz0GPZIkacLCvXprwVnekiRJnWCmR5Ik9bV5IrNBjyRJmtDioMfyliRJ6gQzPZIkaUKLJzIb9EiSpL42z+mxvCVJkjrBTI8kSZpgeUuSJHWB5S1JkqQRZ6ZHkiRNsLwlSZK6oAx6JElSJ7Q46HFOjyRJ6gQzPZIkqc/yliRJ6oYWBz2WtyRJUieY6ZEkSX2WtyRJUie0OeixvCVJkjrBTI8kSeprc6bHoEeSJE2oDHsE88byliRJ6gQzPZIkqc/yliRJ6oQas7wlSZI00sz0SJKkPstbkiSpE8q7tyRJkkabmR5JktRneUuSJHWCd29JkiSNODM9kiSpr2rYI5g/Bj2SJKnP8pYkSdKIM9MjSZL62pzpmTboSXIuMG1lr6p+c15GJEmShqarc3o+sGCjkCRJmmfTBj1V9YXx9STLgMdU1cYFGZUkSRqKNpe3djqROcnLgCuAC5rtZzalL0mS1DJVmbNlsZnN3VunAL8IbAWoqkuBJ8znoCRJkubabO7eureqtib3idhaPM1JkqTu6vq7t76V5FXAkiQrgTcDF8/vsCRJ0jCMLcKy1FyZTXnrBODZwBhwLnAP8Jb5HJQkSdJc22mmp6ruBP5rkj/tbdZP539YkiRpGBbjBOS5stOgJ8mzgL8DHtls3wz8blVdMs9jkyRJC6zTt6wDHwL+sKoOrKoDgf/S7JMkSRoZs5nIfGdV/ev4RlV9MclP5nFMkiRpSDr5GookT29Wv57kVOBsereq/xbwr9OdJ0mSRleby1szZXpOnbT99IH1FseBkiSpjWZ699bzF3IgkiRp+Nr8nJ7ZzOkhyUuApwJ7ju+rqj+fr0FJkqTh6Pot6x8E9gZeQO+urZfjE5klSdKImc0t68+rqlcDt1XVf6P38tED53dYkiRpGKrmbllsZlPeGn8C891JHg3cBjxu3kYkSZKGputzev4pyd7AXwKXAjuAM+Z1VJIkSXNsp+WtqnpnVW2tqk8CK4FfAP5+3kcmSZIWXFXmbJmNJIcnuTrJxiQnTXH8+CS3JLm0Wd4wcOy4JNc0y3E762tWd29NfBH1U+CnSS4FHrMr50qSpMVvIefiJFlK77mALwY2AeuTrKuqqyY1PaeqTph07iOAdwDPoff8wG82594+XX+zmcg85Tgf4HmSJEnjVgEbq+raqtoGfBxYPctzXwJcUFVbmkDnAuDwmU54oEHPIpyTLUmSflZjlTlbZmE5cP3A9qZm32QvT3J5kk8lWbGL5/bN9O6tc5k6uAmw70wXlSRJo2kuH06YZA2wZmDX2qpaO9hkqiFM2v4scHZV3ZPkjfRupnrhLM+9j5nm9HzgAR6TJEmiCXDWztBkE7BiYPtAYPOka9w2sHka8O6Bcw+ddO4XZxrPTO/e+sJMJ0qSpPZZ4Of0rAcOSrISuAE4Gnj1YIMk+1fVjc3mkcC3mvXzgT9Psk+zfRjwxzN1tkt3b0mSpHZbyEm7VbU9yQn0ApilwOlVdWWSU4ANVbUOODHJkcB2YAtwfHPuliTvohc4AZxSVVtm6i+1GJ8TPbORG7DUBuuXHzXsIUiddMgN5y5o6uXf9n/5nP3O/vKNf7+o7vae9d1bSfaYz4FIkiTNp50GPUlWJbkCuKbZfkaS98/7yCRJ0oJb6CcyL6TZZHr+Bvh1ei8apaouA351PgclSZKGY2wOl8VmNkHPkqr6/qR9O+ZjMJIkSfNlNndvXZ9kFVDNOzL+APjO/A5LkiQNQ7X4TVOzCXp+n16J6zHAzcCFzT5JktQyYy2+R3qnQU9V/ZDew4IkSZJG1k6DniSnMcWzcapqzRTNJUnSCBvreHnrwoH1PYGjuO9bTSVJUkt0ek5PVZ0zuJ3kI8AF8zYiSZKkefBA3r21EnjsXA9EkiQN32J8vs5cmc2cntuZmNOzhN7Lvk6az0FJkqTh6Gx5K0mAZ9B73TvAWI3gG0olSZJmfCJzE+CcW1U7msWAR5KkFuv6ayi+keRZ8z4SSZI0dG0OeqYtbyXZraq2A88DfjfJd4E7gdBLAhkISZKkkTHTnJ5vAM8C/uMCjUWSJA1ZVycyB6CqvrtAY5EkSUM21t6YZ8ag55FJ/nC6g1X11/MwHkmSpHkxU9CzFHgItDjPJUmS7qOr7966sapOWbCRSJKkoWvzs2lmumW9vaGeJEnqnJkyPS9asFFIkqRFYTE+X2euTBv0VNWWhRyIJEkavrG0t9AzmycyS5IkjbydvmVdkiR1R5snMhv0SJKkvjbP6bG8JUmSOsFMjyRJ6uvqaygkSVLHtPmJzJa3JElSJ5jpkSRJfd69JUmSOqHNc3osb0mSpE4w0yNJkvra/Jwegx5JktTX5jk9lrckSVInmOmRJEl9bZ7IbNAjSZL62jynx/KWJEnqBDM9kiSpr82ZHoMeSZLUVy2e02N5S5IkdYKZHkmS1Gd5S5IkdUKbgx7LW5IkqRPM9EiSpL42v4bCoEeSJPW1+YnMlrckSVInmOmRJEl9bZ7IbNAjSZL62hz0WN6SJEmdYKZHkiT1efeWJEnqhDbfvWXQI0mS+pzTI0mSNOLM9EiSpD7n9EiSpE4Ya3HYY3lLkiR1gpkeSZLU1+aJzAY9kiSpr73FLctbkiSpI8z0SJKkPstbkiSpE9r8RGbLW5IkqRPM9EiSpL42P6fHoEeSJPW1N+SxvCVJkjrCoEeSJPWNzeEyG0kOT3J1ko1JTpqh3SuSVJLnNNu7JzkjyRVJvpXkj3fWl+UtSZLUt5BzepIsBU4FXgxsAtYnWVdVV01q91DgRODrA7tfCexRVb+Q5MHAVUnOrqrrpuvPTI8kSRqWVcDGqrq2qrYBHwdWT9HuXcB7gLsH9hWwV5LdgAcB24AfzdSZQY8kSeqrOVySrEmyYWBZM6m75cD1A9ubmn19SQ4GVlTVP04691PAncCNwA+Av6yqLTN9NstbkiSpby6fyFxVa4G1MzSZ6lGI/fpakiXAe4Hjp2i3CtgBHADsA3wlyYVVde10nRn0SJKkYdkErBjYPhDYPLD9UOBpwBeTADwaWJfkSODVwD9X1b3AD5N8DXgOMG3QY3lLkiT1jVFztszCeuCgJCuTLAOOBtaNH6yqO6pqv6p6XFU9DrgYOLKqNtArab0wPXsBzwW+PVNnBj2SJKlvLuf07LSvqu3ACcD5wLeAT1TVlUlOabI5MzkVeAjw7/SCpw9V1eUznWB5S5IkDU1VnQecN2nf26dpe+jA+k/o3bY+awY9kiSpby4nMi82Bj2SJKmvWvz2Lef0SJKkTjDTI0mS+ixvSZKkTljId28tNMtbkiSpE8z0SJKkvvbmeQx6JEnSAMtbkiRJI85MjyS1yMMOPZjHnPJ6smQJt5x9ITed+un7HN/3Vb/KipOP496btgBw84fO49azLxzGULVIeffWA5DkdODXgR9W1dOmOB7gfwEvBe4Cjq+qS+ZrPJLUekuW8Ng/W8N3jnkn2268jaec9x62fv4b3H3Npvs027Lua/zg5NOGNEgtdj6c8IH5MHD4DMePAA5qljXA/57HsUhS6+118EHcc92N3PODm6l7t7PlM19ln5esGvawpEVj3oKeqvoysGWGJquBM6vnYmDvJPvP13gkqe2WPfoRbNt8a3972423sfuj971fu31e+lyeesF7efzat7HsgPsfV7eNzeGy2AxzIvNy4PqB7U3NvvtJsibJhiQb1q5duyCDk6SRk9x/X923VLH1gg1c/tzf48oX/2d+9JXLWfm+Ny/Q4DQqag7/t9gMcyLzFH+dU39DVbUWWDtTG0nqum033sayA/brby/bf1/uvfm+Cfcdt/+4v37LRy/gwD85dsHGJw3bMDM9m4AVA9sHApuHNBZJGnl3XnoNe6zcn2UrHkV2341HrH4et39+/X3a7P6offrrex92CHdv3DT5Muq4Npe3hpnpWQeckOTjwC8Cd1TVjUMcjySNth1j/ODk03jSx94BS5Zw6zlf4O7vXM8Bbz2Guy7byNYL1vNzr3sZex92CLVjB9u3/oTvveX9wx61Fpmxam9BJTVPHy7J2cChwH7AzcA7gN0Bqupvm1vWP0DvDq+7gNdW1YZZXLq9/xrSIrZ++VHDHoLUSYfccO5U00HmzbGP/c05+539yPc/vaBj35l5y/RU1TE7OV7Af5qv/iVJ0q5rc2bBJzJLkqQ+370lSZI04sz0SJKkvsX4fJ25YtAjSZL6FuOt5nPF8pYkSeoEMz2SJKmvzROZDXokSVJfm+f0WN6SJEmdYKZHkiT1tXkis0GPJEnqm6/XUy0GlrckSVInmOmRJEl93r0lSZI6wTk9kiSpE7xlXZIkacSZ6ZEkSX3O6ZEkSZ3gLeuSJEkjzkyPJEnq8+4tSZLUCd69JUmSNOLM9EiSpD7v3pIkSZ3g3VuSJEkjzkyPJEnqs7wlSZI6wbu3JEmSRpyZHkmS1DfW4onMBj2SJKmvvSGP5S1JktQRZnokSVKfd29JkqROaHPQY3lLkiR1gpkeSZLU1+bXUBj0SJKkPstbkiRJI85MjyRJ6mvzaygMeiRJUl+b5/RY3pIkSZ1gpkeSJPW1eSKzQY8kSeqzvCVJkjTizPRIkqQ+y1uSJKkT2nzLuuUtSZLUCWZ6JElS31iLJzIb9EiSpD7LW5IkSSPOoEeSJPWNVc3ZMhtJDk9ydZKNSU6aod0rklSS5wzse3qSi5JcmeSKJHvO1JflLUmS1LeQ5a0kS4FTgRcDm4D1SdZV1VWT2j0UOBH4+sC+3YCzgGOr6rIk+wL3ztSfmR5JkjQsq4CNVXVtVW0DPg6snqLdu4D3AHcP7DsMuLyqLgOoqtuqasdMnRn0SJKkvrksbyVZk2TDwLJmUnfLgesHtjc1+/qSHAysqKp/nHTuE4FKcn6SS5L80c4+m+UtSZLUN5flrapaC6ydoUmmHML4wWQJ8F7g+Cna7QY8DzgEuAv4QpJvVtUXpuvMTI8kSRqWTcCKge0Dgc0D2w8FngZ8Mcl1wHOBdc1k5k3Al6rq1qq6CzgPeNZMnRn0SJKkvgW+e2s9cFCSlUmWAUcD68YPVtUdVbVfVT2uqh4HXAwcWVUbgPOBpyd5cDOp+VeAq+7fxQTLW5IkqW8h796qqu1JTqAXwCwFTq+qK5OcAmyoqnUznHt7kr+mFzgVcF5VfW6m/gx6JEnS0FTVefRKU4P73j5N20MnbZ9F77b1Wd6aWFEAAAYNSURBVDHokSRJfVVjwx7CvDHokSRJfWO+e0uSJGm0memRJEl9Nct3Zo0igx5JktRneUuSJGnEmemRJEl9lrckSVInzPJJyiPJ8pYkSeoEMz2SJKlvIV9DsdAMeiRJUp9zeiRJUid4y7okSdKIM9MjSZL6LG9JkqRO8JZ1SZKkEWemR5Ik9VnekiRJneDdW5IkSSPOTI8kSeqzvCVJkjrBu7ckSZJGnJkeSZLU5wtHJUlSJ1jekiRJGnFmeiRJUp93b0mSpE5o85wey1uSJKkTzPRIkqQ+y1uSJKkT2hz0WN6SJEmdYKZHkiT1tTfPA2lzGkuLT5I1VbV22OOQusa/PcnylhbemmEPQOoo//bUeQY9kiSpEwx6JElSJxj0aKE5p0AaDv/21HlOZJYkSZ1gpkeSJHWCQY8kSeoEgx7NuSSHJ7k6ycYkJ01xfI8k5zTHv57kcQs/Sql9kpye5IdJ/n2a40nyN83f3uVJnrXQY5SGyaBHcyrJUuBU4AjgKcAxSZ4yqdnrgdur6gnAe4F3L+wopdb6MHD4DMePAA5qljXA/16AMUmLhkGP5toqYGNVXVtV24CPA6sntVkNnNGsfwp4UZIs4BilVqqqLwNbZmiyGjizei4G9k6y/8KMTho+gx7NteXA9QPbm5p9U7apqu3AHcC+CzI6qdtm8/cptZZBj+baVBmbyc9FmE0bSXPPvz11mkGP5tomYMXA9oHA5unaJNkNeDgzp+QlzY3Z/H1KrWXQo7m2Hjgoycoky4CjgXWT2qwDjmvWXwH8S/mUTGkhrANe09zF9Vzgjqq6cdiDkhbKbsMegNqlqrYnOQE4H1gKnF5VVyY5BdhQVeuAvwM+kmQjvQzP0cMbsdQeSc4GDgX2S7IJeAewO0BV/S1wHvBSYCNwF/Da4YxUGg5fQyFJkjrB8pYkSeoEgx5JktQJBj2SJKkTDHokSVInGPRIkqROMOiRFqEkO5JcmuTfk3wyyYN/hmsdmuQfm/UjM8Wb7wfa7p3kTQ+gj3cmeets989wnZ/MRb+SNBWDHmlx+mlVPbOqngZsA944eLB5uNwu//1W1bqq+osZmuwN7HLQI0mjwKBHWvy+AjwhyeOSfCvJB4FLgBVJDktyUZJLmozQQwCSHJ7k20m+Cvzm+IWSHJ/kA836zyU5N8llzfLLwF8Aj2+yTP+zafe2JOuTXJ7kTweu9f8muTrJhcCTduUDJfmHJN9McmWSNZOO/VXzeb6Q5JHNvscn+efmnK8kefID+B4ldZxBj7SINe8mOwK4otn1JODMqjoYuBM4Gfi1qnoWsAH4wyR7AqcBvwE8H3j0NJf/G+BLVfUM4FnAlcBJwHebLNPbkhwGHASsAp4JPDvJC5I8m96TtA+mF1Qdsosf7XVV9WzgOcCJSfZt9u8FXNJ8ni/Re6IwwFrgD5pz3gp8cBf7kyRfQyEtUg9Kcmmz/hV6r+44APh+VV3c7H8u8BTga0kAlgEXAU8GvldV1wAkOQu4Tzal8ULgNQBVtQO4I8k+k9oc1iz/t9l+CL0g6KHAuVV1V9PH5Per7cyJSY5q1lc017wNGAPOafafBXy6yV79MvDJ5nMC7LGL/UmSQY+0SP20qp45uKP5wb9zcBdwQVUdM6ndM4G5er9MgP9RVf/fpD7e8kD7SHIo8GvAL1XVXUm+COw5TfOil5HeOvn7kKRdZXlLGl0XA/9PkicAJHlwkicC3wZWJnl80+6Yac7/AvD7zblLkzwM+DG9LM6484HXDcwVWp7kUcCXgaOSPCjJQ+mV0mbr4cDtTcDzZHoZq3FLgFc0668GvlpVPwK+l+SVzRiS5Bm70J8kAQY90siqqluA44Gzk1xOLwh6clXdTa+c9blmIvP3p7nEm4FfTXIF8E3gqVV1G71y2b8n+Z9V9XngY8BFTbtPAQ+tqkvolaEuBf6eXgluOicn2TS+AP8M7NaM+V3NuMfdCTw1yTfpld9Oafb/NvD6JJfRm3u0erbfkySN8y3rkiSpE8z0SJKkTjDokSRJnWDQI0mSOsGgR5IkdYJBjyRJ6gSDHkmS1AkGPZIkqRP+f78cXJVkhjaWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_epochs = 5000\n",
    "n_random_search = 1\n",
    "\n",
    "batch_size = [32]\n",
    "n_layers = [1] \n",
    "cnn_dropout_p = [None, 0.2, 0.5]\n",
    "dense_dropout_p = [None, 0.2, 0.5]\n",
    "activation = ['relu']\n",
    "n_dense_layers = [1,2,3]\n",
    "n_dense_neurons = [100,500,1500]\n",
    "batch_normalization = [True]\n",
    "optimizer = [Adam(learning_rate=0.01, clipvalue=0.5)]\n",
    "#optimizer = [SGD(0.001)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, cnn_dropout_p, dense_dropout_p, activation, n_dense_layers, n_dense_neurons, batch_normalization, batch_size, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'tcn', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hyperparameter combinations determined\n",
      "The class distributions in the training set are: (array([0., 1.]), array([508, 622]))\n",
      "The class distributions in the validation set are: (array([0., 1.]), array([113, 206]))\n",
      "The class distributions in the test set are: (array([0., 1.]), array([80, 80]))\n",
      "=================================================\n",
      "Presenting Results for: 1/1 Hyperparameter Combination\n",
      "{'n_layers': 2, 'batch_size': 32, 'lstm_neurons': 500, 'n_dense_neurons': 1000, 'dropout': None, 'optimizer': <keras.optimizer_v2.adam.Adam object at 0x7efd0cd56bd0>}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (32, 31, 500)             1018000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, 500)                 2002000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 1000)                501000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, 2)                   2002      \n",
      "=================================================================\n",
      "Total params: 3,523,002\n",
      "Trainable params: 3,523,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "35/35 [==============================] - 15s 366ms/step - loss: 0.8825 - accuracy: 0.5384 - precision_1: 0.5384 - recall_1: 0.5384 - val_loss: 0.6895 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 12s 334ms/step - loss: 0.6920 - accuracy: 0.5223 - precision_1: 0.5223 - recall_1: 0.5223 - val_loss: 0.6872 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 11s 326ms/step - loss: 0.6891 - accuracy: 0.5518 - precision_1: 0.5518 - recall_1: 0.5518 - val_loss: 0.6861 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 11s 328ms/step - loss: 0.6886 - accuracy: 0.5491 - precision_1: 0.5491 - recall_1: 0.5491 - val_loss: 0.6852 - val_accuracy: 0.5536 - val_precision_1: 0.5536 - val_recall_1: 0.5536\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 12s 340ms/step - loss: 0.6920 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6878 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 12s 342ms/step - loss: 0.6859 - accuracy: 0.5500 - precision_1: 0.5500 - recall_1: 0.5500 - val_loss: 0.6799 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 11s 303ms/step - loss: 0.6887 - accuracy: 0.5420 - precision_1: 0.5420 - recall_1: 0.5420 - val_loss: 0.6863 - val_accuracy: 0.5527 - val_precision_1: 0.5527 - val_recall_1: 0.5527\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 10s 293ms/step - loss: 0.6943 - accuracy: 0.5562 - precision_1: 0.5562 - recall_1: 0.5562 - val_loss: 0.6869 - val_accuracy: 0.5616 - val_precision_1: 0.5616 - val_recall_1: 0.5616\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 10s 292ms/step - loss: 0.6885 - accuracy: 0.5402 - precision_1: 0.5402 - recall_1: 0.5402 - val_loss: 0.6789 - val_accuracy: 0.5670 - val_precision_1: 0.5670 - val_recall_1: 0.5670\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 10s 298ms/step - loss: 0.6859 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6802 - val_accuracy: 0.5518 - val_precision_1: 0.5518 - val_recall_1: 0.5518\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 11s 308ms/step - loss: 0.6861 - accuracy: 0.5527 - precision_1: 0.5527 - recall_1: 0.5527 - val_loss: 0.6693 - val_accuracy: 0.5804 - val_precision_1: 0.5804 - val_recall_1: 0.5804\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 11s 302ms/step - loss: 0.6808 - accuracy: 0.5607 - precision_1: 0.5607 - recall_1: 0.5607 - val_loss: 0.6824 - val_accuracy: 0.5589 - val_precision_1: 0.5589 - val_recall_1: 0.5589\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 10s 294ms/step - loss: 0.6851 - accuracy: 0.5455 - precision_1: 0.5455 - recall_1: 0.5455 - val_loss: 0.6770 - val_accuracy: 0.5598 - val_precision_1: 0.5598 - val_recall_1: 0.5598\n",
      "Epoch 14/500\n",
      "16/35 [============>.................] - ETA: 4s - loss: 0.6842 - accuracy: 0.5586 - precision_1: 0.5586 - recall_1: 0.5586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-191f5e051644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n\u001b[0;32m---> 17\u001b[0;31m                            model_randomgs_params, 'lstm', flush=True, save_plot=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, epochs, TRAIN_DATA_PATH, INTERM_DATA_DIR, MODEL_DIR, model_gs_params, model_type, flush, save_plot)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_gs_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreproducible_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0f4cdb63efb6>\u001b[0m in \u001b[0;36mperform_gs_training\u001b[0;34m(self, model_fn, checkpoint_filepath)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                                           \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                                                           checkpoint_callback],\n\u001b[0;32m--> 247\u001b[0;31m                                              epochs=self.max_epochs, verbose=1)\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_epochs = 500\n",
    "n_random_search = 1\n",
    "\n",
    "n_layers = [2]\n",
    "batch_size = [32]\n",
    "lstm_neurons = [100, 500, 1000]\n",
    "n_dense_neurons = [100, 500, 1000]\n",
    "dropout = [None, 0.2, 0.5, 0.8]\n",
    "optimizer = [Adam(learning_rate=0.01, clipvalue=0.5)]\n",
    "#optimizer = [SGD(learning_rate=0.01)]\n",
    "\n",
    "model_gs_params = list(itertools.product(*[n_layers, batch_size, lstm_neurons, n_dense_neurons, dropout, optimizer]))\n",
    "model_randomgs_params = random.sample(model_gs_params, n_random_search) if len(model_gs_params) > n_random_search else model_gs_params\n",
    "print(\"%s Hyperparameter combinations determined\" % len(model_randomgs_params))\n",
    "\n",
    "training = PerformTraining(max_epochs, TRAIN_DATA_PATH, INTERM_DIR, MODEL_DIR,\n",
    "                           model_randomgs_params, 'lstm', flush=True, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
