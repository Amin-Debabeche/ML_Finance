{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML4F Semester Project\n",
    "\n",
    "Current blocks/issues: \n",
    "- What precision do we want to operate on? The created_utc column (date of the comment) has precision up to the seconds, imo we could group by hour and create more observations this way, than if we simply aggregated and predicted daily\n",
    "- Need to find stock data depending on the frequency we desire\n",
    "- Check out Preprocessing function, maybe more interesting columns we could use too now that we can really inspect the data\n",
    "- Note: I used mostly nltk so far, will add some spacy functionalities soon for PartsOfSpeech tags etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>edited</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>editable</th>\n",
       "      <th>media_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LazyMeal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>...</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math_salts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>...</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legendary_Squirrel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>...</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSBMORONICTRADER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>...</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>t5_2th52</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  associated_award              author  \\\n",
       "0            []               NaN            LazyMeal   \n",
       "1            []               NaN          math_salts   \n",
       "2            []               NaN  Legendary_Squirrel   \n",
       "3            []               NaN    WSBMORONICTRADER   \n",
       "4            []               NaN           [deleted]   \n",
       "\n",
       "  author_flair_background_color  author_flair_css_class author_flair_richtext  \\\n",
       "0                           NaN                     NaN                    []   \n",
       "1                           NaN                     NaN                    []   \n",
       "2                           NaN                     NaN                    []   \n",
       "3                           NaN                     NaN                    []   \n",
       "4                           NaN                     NaN                   NaN   \n",
       "\n",
       "  author_flair_template_id author_flair_text author_flair_text_color  \\\n",
       "0                      NaN               NaN                     NaN   \n",
       "1                      NaN               NaN                     NaN   \n",
       "2                      NaN               NaN                     NaN   \n",
       "3                      NaN               NaN                     NaN   \n",
       "4                      NaN               NaN                    dark   \n",
       "\n",
       "  author_flair_type  ... subreddit_id total_awards_received treatment_tags  \\\n",
       "0              text  ...     t5_2th52                     0            NaN   \n",
       "1              text  ...     t5_2th52                     0            NaN   \n",
       "2              text  ...     t5_2th52                     0            NaN   \n",
       "3              text  ...     t5_2th52                     0            NaN   \n",
       "4               NaN  ...     t5_2th52                     0            NaN   \n",
       "\n",
       "  top_awarded_type edited  distinguished  comment_type author_cakeday  \\\n",
       "0              NaN    NaN            NaN           NaN            NaN   \n",
       "1              NaN    NaN            NaN           NaN            NaN   \n",
       "2              NaN    NaN            NaN           NaN            NaN   \n",
       "3              NaN    NaN            NaN           NaN            NaN   \n",
       "4              NaN    NaN            NaN           NaN            NaN   \n",
       "\n",
       "  editable  media_metadata  \n",
       "0      NaN             NaN  \n",
       "1      NaN             NaN  \n",
       "2      NaN             NaN  \n",
       "3      NaN             NaN  \n",
       "4      NaN             NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>barCount</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20201224  10:45:00</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20201224  11:00:00</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201224  11:15:00</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20201224  11:30:00</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>21.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20201224  11:45:00</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date   open   high    low  close  volume  barCount  average\n",
       "0  20201224  10:45:00  21.18  21.18  21.18  21.18       1         1    21.18\n",
       "1  20201224  11:00:00  21.18  21.18  21.18  21.18       0         0    21.18\n",
       "2  20201224  11:15:00  21.18  21.18  21.18  21.18       0         0    21.18\n",
       "3  20201224  11:30:00  21.18  21.18  21.18  21.18       0         0    21.18\n",
       "4  20201224  11:45:00  20.80  20.80  20.80  20.80       1         1    20.80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re  \n",
    "import pandas as pd  \n",
    "from time import time \n",
    "import sys\n",
    "\n",
    "import spacy  \n",
    "import logging  \n",
    "import nltk\n",
    "import multiprocessing\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "wsb_data_path = os.path.join(DATA_DIR, 'wsb_comments/wsb_comments_raw.csv')\n",
    "stock_data_path = os.path.join(DATA_DIR, 'GME')\n",
    "\n",
    "def load_wsb_data(data_path, nrows=None):\n",
    "    \"Load wsb data, nrows None indicates all rows, otherwise specified integer of rows\"\n",
    "    return pd.read_csv(wsb_data_path, nrows = nrows, delimiter=',')\n",
    "\n",
    "wsb_df = load_wsb_data(wsb_data_path, nrows=1000)\n",
    "display(wsb_df.head())\n",
    "\n",
    "# Scraped from IB via https://gist.github.com/wrighter/dd201adb09518b3c1d862255238d2534\n",
    "def load_stock_data(data_path):\n",
    "    \"Load GME stock price data\"\n",
    "    gme_dfs = [pd.read_csv(os.path.join(data_path, f), delimiter=',') for f in os.listdir(stock_data_path) if os.path.isfile(os.path.join(stock_data_path, f))]\n",
    "    gme_final_df = pd.concat(gme_dfs, ignore_index=True)\n",
    "    return gme_final_df\n",
    "\n",
    "stock_df = load_stock_data(stock_data_path)\n",
    "display(stock_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing: \n",
    "    \n",
    "    def __init__(self, wsb_data, lemmatize=True, lower_case=True, rem_stopwords=True, rem_punctuation=True, tokenize=True):\n",
    "        \"\"\"\n",
    "        Initialise all class parameters\n",
    "        \n",
    "        :param data: nonempty pandas dataframe, wsb dataframe \n",
    "        :param lemmatize: bool, whether to perform lemmatization\n",
    "        :param lower_case: bool, whether to lowercase\n",
    "        :param rem_stopwords: bool, whether to remove stopwords\n",
    "        :param tokenize: bool, whether to tokenize\n",
    "        \"\"\"\n",
    "        \n",
    "        self.wsb_data = wsb_data\n",
    "        self.lemmatize = lemmatize\n",
    "        self.lower_case = lower_case\n",
    "        self.rem_stopwords = rem_stopwords\n",
    "        self.rem_punctuation = rem_punctuation\n",
    "        self.tokenize = tokenize\n",
    "        \n",
    "    ### Ensure Parameter types \n",
    "    #K: need to add to this one gradually as we add columns that we use etc.\n",
    "    @property\n",
    "    def wsb_data(self):\n",
    "        return self._wsb_data\n",
    "    @wsb_data.setter\n",
    "    def wsb_data(self, wsb_data):\n",
    "        \n",
    "        req_columns = ['author','body','created_utc']\n",
    "        str_columns = ['body']\n",
    "        date_columns = ['created_utc']\n",
    "\n",
    "        # Ensure the provided object is a dataframe\n",
    "        if not isinstance(wsb_data, pd.DataFrame):\n",
    "            raise Exception(\"The provided data must be a pandas Dataframe\")\n",
    "        \n",
    "        # Ensure wsb dataframe is non empty\n",
    "        if wsb_data.shape[0] == 0: \n",
    "            raise Exception(\"Provided Dataframe is empty\")\n",
    "        \n",
    "        # Ensure all required columns are provided\n",
    "        missing_columns = set(req_columns).difference(set(wsb_data.columns.tolist()))\n",
    "        if len(missing_columns) > 0:\n",
    "            raise Exception(f\"The columns {missing_columns} are missing from the provided dataframe!\")\n",
    "            \n",
    "        # Ensure all column names don't have unexpected periods\n",
    "        if '.' in list(''.join(wsb_data.columns.tolist())):\n",
    "            raise Exception(\"All Column names must not include periods :'.'\")\n",
    "            \n",
    "        # Ensure all string columns are strings\n",
    "        non_str_columns = set(str_columns).difference(set(wsb_data.select_dtypes(include='object')))\n",
    "        if len(non_str_columns) > 0:\n",
    "            raise Exception(f'The columns {non_str_columns} are expected as string (pandas object) columns.')\n",
    "        \n",
    "        # Ensure dates are interpretable\n",
    "        for date_col in date_columns: \n",
    "            if pd.to_datetime(wsb_data[date_col], format='%Y-%m-%d %H:%M:%S', errors='coerce').notnull().all():\n",
    "                try:\n",
    "                    # Otherwise Convert date using unixtimestamp to datetime object\n",
    "                    wsb_data[date_col] = pd.to_datetime(wsb_data[date_col], format='%Y-%m-%d %H:%M:%S')\n",
    "                except: \n",
    "                    raise Exception(f\"{date_col} must be a valid unixtimestamp format\")\n",
    "                    \n",
    "        self._wsb_data = wsb_data\n",
    "        \n",
    "    @property\n",
    "    def lemmatize(self):\n",
    "        return self._lemmatize\n",
    "    @lemmatize.setter\n",
    "    def lemmatize(self, lemmatize):\n",
    "        if not isinstance(lemmatize, bool): \n",
    "            raise Exception('lemmatize must be provided as a boolean parameter (True/False) to the class')\n",
    "        self._lemmatize = lemmatize\n",
    "    \n",
    "    @property\n",
    "    def lower_case(self):\n",
    "        return self._lower_case\n",
    "    @lower_case.setter\n",
    "    def lower_case(self, lower_case):\n",
    "        if not isinstance(lower_case, bool): \n",
    "            raise Exception('lower_case must be provided as a boolean parameter (True/False) to the class')\n",
    "        self._lower_case = lower_case\n",
    "      \n",
    "    @property\n",
    "    def rem_stopwords(self):\n",
    "        return self._rem_stopwords\n",
    "    @rem_stopwords.setter\n",
    "    def rem_stopwords(self, rem_stopwords):\n",
    "        if not isinstance(rem_stopwords, bool): \n",
    "            raise Exception('rem_stopwords must be provided as a boolean parameter (True/False) to the class')\n",
    "        self._rem_stopwords = rem_stopwords\n",
    "        \n",
    "    @property\n",
    "    def rem_punctuation(self):\n",
    "        return self._rem_punctuation\n",
    "    @rem_punctuation.setter\n",
    "    def rem_punctuation(self, rem_punctuation):\n",
    "        if not isinstance(rem_punctuation, bool): \n",
    "            raise Exception('rem_punctuation must be provided as a boolean parameter (True/False) to the class')\n",
    "        self._rem_punctuation = rem_punctuation\n",
    "        \n",
    "    @property\n",
    "    def tokenize(self):\n",
    "        return self._tokenize\n",
    "    @tokenize.setter\n",
    "    def tokenize(self, tokenize):\n",
    "        if not isinstance(tokenize, bool): \n",
    "            raise Exception('tokenize must be provided as a boolean parameter (True/False) to the class')\n",
    "        self._tokenize = tokenize\n",
    "        \n",
    "    def clean_textual_data(self, textual_columns):\n",
    "        \n",
    "        ### Ensure the provided textual columns exist, and if single string column name convert it into a list\n",
    "        if len(textual_columns)<1:\n",
    "            raise Exception('The number of textual columns to clean must be greater than 0')\n",
    "        if isinstance(textual_columns, str):\n",
    "            textual_columns = [textual_columns]\n",
    "        missing_columns = set(textual_columns).difference(set(self.wsb_data.columns.tolist()))\n",
    "        if len(missing_columns) > 0:\n",
    "            raise Exception(f\"The columns {missing_columns} to clean are missing from the wsb dataframe!\")\n",
    "\n",
    "        def lower_case_fn(self, col_name): \n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].str.lower()\n",
    "            return self.wsb_data\n",
    "\n",
    "        def lemmatize_fn(self, col_name):\n",
    "            w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "            lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])\n",
    "            return self.wsb_data\n",
    "\n",
    "        def stemming_fn(self, col_name):\n",
    "            w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "            stemmer = nltk.stem.porter.PorterStemmer()\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: [stemmer.stem(w) for w in w_tokenizer.tokenize(x)])\n",
    "            return self.wsb_data\n",
    "\n",
    "        def tokenize_fn(self, col_name):\n",
    "            w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: [w for w in w_tokenizer.tokenize(x)])\n",
    "            return self.wsb_data\n",
    "\n",
    "        def rem_punctuation_fn(self, col_name):\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: [w for w in x if w.isalnum()])\n",
    "            return self.wsb_data\n",
    "\n",
    "        def rem_stopwords_fn(self, col_name):\n",
    "            \"stopwords dictionary considered English, wsb is an english forum\"\n",
    "            remove_elements = set(nltk.corpus.stopwords.words('english'))\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: [w for w in x if not w in remove_elements])\n",
    "            return self.wsb_data\n",
    "\n",
    "        def remove_tokenization(self, col_name):\n",
    "            \"Necessary as final step to untokenize in case desired, tokenization required for other functions to not break\"\n",
    "            self.wsb_data[col_name] = self.wsb_data[col_name].apply(lambda x: ' '.join(x))\n",
    "            return self.wsb_data\n",
    "\n",
    "        for textual_col in textual_columns:\n",
    "\n",
    "            if self.lower_case:\n",
    "                lower_case_fn(self, textual_col)\n",
    "\n",
    "            # lemmatize tokens if true, if false, stem tokens, if None then just tokenize\n",
    "            if self.lemmatize:\n",
    "                lemmatize_fn(self, textual_col)\n",
    "            elif self.lemmatize:\n",
    "                stemming_fn(self, textual_col)\n",
    "            else: \n",
    "                tokenize_fn(self, textual_col)\n",
    "\n",
    "            if self.rem_punctuation:\n",
    "                rem_punctuation_fn(self, textual_col)\n",
    "            if self.rem_stopwords:\n",
    "                rem_stopwords_fn(self, textual_col)\n",
    "            if not self.tokenize:\n",
    "                remove_tokenization(self, textual_col)\n",
    "\n",
    "        return self.wsb_data\n",
    "        \n",
    "        \n",
    "    # to later remove: for development\n",
    "    def output_data(self):\n",
    "        return self.wsb_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LazyMeal</td>\n",
       "      <td>[retarded, claim, listen, doe, make]</td>\n",
       "      <td>1970-01-01 00:00:01.585123910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math_salts</td>\n",
       "      <td>[yes]</td>\n",
       "      <td>1970-01-01 00:00:01.585123909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legendary_Squirrel</td>\n",
       "      <td>[market, open, 13]</td>\n",
       "      <td>1970-01-01 00:00:01.585123905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSBMORONICTRADER</td>\n",
       "      <td>[spy, fuck, around, want, long, 220, put, prin...</td>\n",
       "      <td>1970-01-01 00:00:01.585123901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1970-01-01 00:00:01.585123897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Jujubewise</td>\n",
       "      <td>[haha]</td>\n",
       "      <td>1970-01-01 00:00:01.607198916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1970-01-01 00:00:01.607198913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The_Ron_Swansonson</td>\n",
       "      <td>[]</td>\n",
       "      <td>1970-01-01 00:00:01.607198913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>steve_pops_01</td>\n",
       "      <td>[real]</td>\n",
       "      <td>1970-01-01 00:00:01.607198913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>k1tch3nMitts</td>\n",
       "      <td>[lol]</td>\n",
       "      <td>1970-01-01 00:00:01.607198911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                               body  \\\n",
       "0              LazyMeal               [retarded, claim, listen, doe, make]   \n",
       "1            math_salts                                              [yes]   \n",
       "2    Legendary_Squirrel                                 [market, open, 13]   \n",
       "3      WSBMORONICTRADER  [spy, fuck, around, want, long, 220, put, prin...   \n",
       "4             [deleted]                                                 []   \n",
       "..                  ...                                                ...   \n",
       "995          Jujubewise                                             [haha]   \n",
       "996           [deleted]                                                 []   \n",
       "997  The_Ron_Swansonson                                                 []   \n",
       "998       steve_pops_01                                             [real]   \n",
       "999        k1tch3nMitts                                              [lol]   \n",
       "\n",
       "                      created_utc  \n",
       "0   1970-01-01 00:00:01.585123910  \n",
       "1   1970-01-01 00:00:01.585123909  \n",
       "2   1970-01-01 00:00:01.585123905  \n",
       "3   1970-01-01 00:00:01.585123901  \n",
       "4   1970-01-01 00:00:01.585123897  \n",
       "..                            ...  \n",
       "995 1970-01-01 00:00:01.607198916  \n",
       "996 1970-01-01 00:00:01.607198913  \n",
       "997 1970-01-01 00:00:01.607198913  \n",
       "998 1970-01-01 00:00:01.607198913  \n",
       "999 1970-01-01 00:00:01.607198911  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPreProcessing = PreProcessing(wsb_df, lemmatize=True, lower_case=True, rem_stopwords=True, rem_punctuation=True, tokenize=True)\n",
    "testPreProcessing.clean_textual_data('body')\n",
    "useful_columns = ['author','body','created_utc']\n",
    "testPreProcessing.output_data()[useful_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
